<?xml version="1.0" encoding="utf-8"?>
<search>
  
  
  
  <entry>
    <title>旅行商问题</title>
    <link href="/posts/11411.html"/>
    <url>/posts/11411.html</url>
    
    <content type="html"><![CDATA[<hr><div class="note note-success">            <p>数学建模 图论 Python</p>          </div><h3 id="旅行商问题tsp问题">旅行商问题(TSP)问题</h3><p>定义:各顶点相异的道路称为轨道.起点和终点重合的道路称为圈.图中含有所有顶点轨道称为Hamilton轨,闭合的Hamilton轨称为Hamilton圈,含有Hamilton圈的图称为Hamilton图.</p><p>一名推销员准备前往若干城市推销产品,然后回到驻地.如何为他设计一条最短的旅行路线(从驻地出发,经过每个城市恰好一次,最后返回驻地)?这个问题称为旅行商问题.用图论的术语,就是在一个赋权完全图中,找出一个有最小权的Hamilton圈.称这种圈为最优圈.目前还没有求解旅行商问题的有效算法.所以希望有一个方法以获得相当好的解.</p><p>例:从北京(Pe)乘飞机到东京(T),纽约(N),墨西哥城(M),伦敦(L),巴黎(Pa)五城市旅游,每城市恰好去一次再回北京,应如何安排旅游线,使旅程最短?用修改圈算法,求一个近似解.各城市之间的航线距离如下表:</p><table><thead><tr class="header"><th></th><th>L</th><th>M</th><th>N</th><th>Pa</th><th>Pe</th><th>T</th></tr></thead><tbody><tr class="odd"><td>L</td><td></td><td>56</td><td>35</td><td>21</td><td>51</td><td>60</td></tr><tr class="even"><td>M</td><td>56</td><td></td><td>21</td><td>57</td><td>78</td><td>70</td></tr><tr class="odd"><td>N</td><td>35</td><td>21</td><td></td><td>36</td><td>68</td><td>68</td></tr><tr class="even"><td>Pa</td><td>21</td><td>57</td><td>36</td><td></td><td>51</td><td>61</td></tr><tr class="odd"><td>Pe</td><td>51</td><td>78</td><td>68</td><td>51</td><td></td><td>13</td></tr><tr class="even"><td>T</td><td>60</td><td>70</td><td>68</td><td>61</td><td>13</td><td></td></tr></tbody></table><h3 id="旅行商问题的数学规划模型">旅行商问题的数学规划模型</h3><p>设城市的个数为<span class="math inline">\(n,d_{ij}\)</span>是两个城市<span class="math inline">\(i\)</span>与<span class="math inline">\(j\)</span>之间的距离,<span class="math inline">\(x_{ij}=0\)</span>或<span class="math inline">\(1\)</span>(1表示走过城市<span class="math inline">\(i\)</span>到城市<span class="math inline">\(j\)</span>的路,0表示没有选择走这条路),则有: <span class="math display">\[\min \sum_{i\ne j}d_{ij}x_{ij},\\s.t.\begin{cases}\sum\limits_{j=1}^{n}x_{ij}=1,i=1,2,\dots,n,\text{(每个点只有一条边出去)}\\\sum\limits_{i=1}^{n}x_{ij}=1,j=1,2,\dots,n,\text{(每个点只有一条边进去)}\\\sum\limits_{i,j\inE}\le \vert s\vert-1,2\le\vert s\vert \len-1,s\subset\{1,2,\dots,n\},\text{(除起点和终点外,各边不构成圈)}\\x_{ij}\in\{0,1\},i,j=1,2,\dots,n,i\ne j\end{cases}\]</span></p><blockquote><p>下面为遗传算法寻找边权最小Hamilto圈的代码</p></blockquote><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">import</span> numpy <span class="hljs-keyword">as</span> np<br><span class="hljs-comment"># 初始化种群</span><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">init</span>(<span class="hljs-params">NP</span>):<br>    res = []<br>    <span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(NP):<br>        x = np.random.uniform(size=<span class="hljs-number">5</span>)<br>        temp_0 = np.array([<span class="hljs-number">0</span>])<br>        temp_1 = np.array([<span class="hljs-number">1</span>])<br>        temp_arr = np.concatenate((temp_0,x,temp_1))<br>        res.append(temp_arr)<br>    <span class="hljs-keyword">return</span> np.array(res)<br><span class="hljs-comment">#解码</span><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">decoding</span>(<span class="hljs-params">code_arr</span>):<br>    index = np.argsort(code_arr)<br>    <span class="hljs-keyword">return</span> index<br><span class="hljs-comment">#适值函数</span><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">fitness_function</span>(<span class="hljs-params">index_arr,W</span>):<br>    x = index_arr[::-<span class="hljs-number">1</span>]<br>    x[<span class="hljs-number">0</span>] = <span class="hljs-number">0</span><br>    i = <span class="hljs-number">0</span><br>    res = <span class="hljs-number">0</span><br>    <span class="hljs-keyword">while</span> i&lt;<span class="hljs-built_in">len</span>(x)-<span class="hljs-number">1</span>:<br>        res += W[x[i],x[i+<span class="hljs-number">1</span>]]<br>        i += <span class="hljs-number">1</span><br>    <span class="hljs-keyword">return</span> res <span class="hljs-comment">#适应值</span><br><span class="hljs-keyword">import</span> random<br><span class="hljs-keyword">def</span> <span class="hljs-title function_">crossover</span>(<span class="hljs-params">gene_f,gene_m,p_c</span>):<span class="hljs-comment">#交叉</span><br>    seed = np.random.uniform()<br>    <span class="hljs-keyword">if</span> seed&lt;p_c:<br>        cross_p = random.randint(<span class="hljs-number">1</span>,<span class="hljs-built_in">len</span>(gene_f)-<span class="hljs-number">1</span>)<br>        gene_1 = np.concatenate((gene_f[<span class="hljs-number">0</span>:cross_p],gene_m[cross_p:]))<br>        gene_2 = np.concatenate((gene_m[<span class="hljs-number">0</span>:cross_p],gene_f[cross_p:]))<br>        <span class="hljs-keyword">return</span> gene_1,gene_2<br>    <span class="hljs-keyword">else</span>:<br>        <span class="hljs-keyword">return</span> gene_f,gene_m<br><span class="hljs-keyword">def</span> <span class="hljs-title function_">mutation</span>(<span class="hljs-params">gene,p_m</span>):<span class="hljs-comment">#突变</span><br>    seed = np.random.uniform()<br>    <span class="hljs-keyword">if</span> seed&lt;p_m:<br>        mutation_p = np.sort(np.random.randint(<span class="hljs-number">1</span>,<span class="hljs-built_in">len</span>(gene)-<span class="hljs-number">2</span>,size=<span class="hljs-number">3</span>))<br>        gene_new = np.concatenate((gene[<span class="hljs-number">0</span>:mutation_p[<span class="hljs-number">0</span>]],gene[mutation_p[<span class="hljs-number">1</span>]+<span class="hljs-number">1</span>:mutation_p[<span class="hljs-number">2</span>]+<span class="hljs-number">1</span>],gene[mutation_p[<span class="hljs-number">0</span>]:mutation_p[<span class="hljs-number">1</span>]+<span class="hljs-number">1</span>],gene[mutation_p[<span class="hljs-number">2</span>]+<span class="hljs-number">1</span>:]))<br>        <span class="hljs-keyword">return</span> gene_new<br>    <span class="hljs-keyword">else</span>:<br>        <span class="hljs-keyword">return</span> gene_new<br><span class="hljs-keyword">def</span> <span class="hljs-title function_">selection</span>(<span class="hljs-params">population,W,NP</span>):<br>    fit_value = []<br>    <span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> population:<br>        fit_value.append(fitness_function(decoding(i),W))<br>    fit_arr = np.array(fit_value)<br>    index = np.argsort(fit_arr)<br>    res = []<br>    <span class="hljs-keyword">for</span> j <span class="hljs-keyword">in</span> index:<br>        res.append(population[j,:])<br>    <span class="hljs-keyword">return</span> np.array(res[<span class="hljs-number">0</span>:NP+<span class="hljs-number">1</span>])<br><span class="hljs-keyword">def</span> <span class="hljs-title function_">genetic_algo</span>(<span class="hljs-params">W,N,NP,p_m,p_c</span>):<br>    popu = init(NP)<br>    i = <span class="hljs-number">1</span><br>    <span class="hljs-keyword">while</span> i&lt;=N:<br>        <span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(NP*<span class="hljs-number">2</span>):<br>            num_1,num_2=np.random.randint(<span class="hljs-number">0</span>,NP-<span class="hljs-number">1</span>,size=<span class="hljs-number">2</span>)<br>            gene_1,gene_2=crossover(popu[num_1],popu[num_2],p_c)<br>            popu[num_1] = gene_1<br>            popu[num_2] = gene_2 <span class="hljs-comment">#没有留父代</span><br>        <span class="hljs-keyword">for</span> j <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(NP):<br>            num = np.random.randint(<span class="hljs-number">0</span>,NP-<span class="hljs-number">1</span>)<br>            gene_new = mutation(popu[num],p_m)<br>            popu[num] = gene_new<br>        popu = selection(popu,W,NP)<br>        i += <span class="hljs-number">1</span><br>    res = decoding(selection(popu,W,NP)[<span class="hljs-number">0</span>])[::-<span class="hljs-number">1</span>]<br>    <span class="hljs-keyword">return</span> res<br>W = np.array([[<span class="hljs-number">0</span>,<span class="hljs-number">56</span>,<span class="hljs-number">35</span>,<span class="hljs-number">21</span>,<span class="hljs-number">51</span>,<span class="hljs-number">60</span>]<br>            ,[<span class="hljs-number">56</span>,<span class="hljs-number">0</span>,<span class="hljs-number">21</span>,<span class="hljs-number">57</span>,<span class="hljs-number">78</span>,<span class="hljs-number">70</span>]<br>            ,[<span class="hljs-number">35</span>,<span class="hljs-number">21</span>,<span class="hljs-number">0</span>,<span class="hljs-number">36</span>,<span class="hljs-number">68</span>,<span class="hljs-number">68</span>]<br>            ,[<span class="hljs-number">21</span>,<span class="hljs-number">57</span>,<span class="hljs-number">36</span>,<span class="hljs-number">0</span>,<span class="hljs-number">51</span>,<span class="hljs-number">61</span>]<br>            ,[<span class="hljs-number">51</span>,<span class="hljs-number">78</span>,<span class="hljs-number">68</span>,<span class="hljs-number">51</span>,<span class="hljs-number">0</span>,<span class="hljs-number">13</span>]<br>            ,[<span class="hljs-number">60</span>,<span class="hljs-number">70</span>,<span class="hljs-number">68</span>,<span class="hljs-number">61</span>,<span class="hljs-number">13</span>,<span class="hljs-number">0</span>]])<br>res = genetic_algo(W,<span class="hljs-number">100</span>,<span class="hljs-number">100</span>,<span class="hljs-number">1</span>,<span class="hljs-number">0.05</span>)<br>fitness_function(res[::-<span class="hljs-number">1</span>],W)<br></code></pre></td></tr></table></figure><figure class="highlight apache"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs apache"><span class="hljs-attribute">array</span>([<span class="hljs-number">6</span>, <span class="hljs-number">2</span>, <span class="hljs-number">1</span>, <span class="hljs-number">5</span>, <span class="hljs-number">4</span>, <span class="hljs-number">3</span>, <span class="hljs-number">0</span>], dtype=int64)<br></code></pre></td></tr></table></figure><figure class="highlight"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs">211<br></code></pre></td></tr></table></figure>]]></content>
    
    
    <categories>
      
      <category>数学建模</category>
      
      <category>图论</category>
      
    </categories>
    
    
    <tags>
      
      <tag>数学建模</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>马尔科夫预测</title>
    <link href="/posts/30115.html"/>
    <url>/posts/30115.html</url>
    
    <content type="html"><![CDATA[<hr><div class="note note-success">            <p>数学建模 预测 Python</p>          </div><h3 id="马尔科夫预测">马尔科夫预测</h3><h4 id="马尔科夫链的定义">马尔科夫链的定义</h4><p>现实世界中有很多这样的现象,某一系统在已知现在情况的条件下系统未来时刻的情况只与现在有关,而与过去的历史无直接关系.比如研究一个商店的累计销售额.如果现在时刻的累计销售额已知,则未来某一时刻的累计销售额与现在时刻以前的任一时刻累计销售额无关.描述这类随机现象的数学模型称为马尔科夫模型,简称马氏模型.</p><p>定义:设<span class="math inline">\(\{X_n,n=1,2,\dots\}\)</span>是一个随机序列,状态空间<span class="math inline">\(E\)</span>为有限或者可列,对于任意的正整数<span class="math inline">\(m,n\)</span>,若<span class="math inline">\(i,j,i_k\in E(k=1,\dots,n-1),\)</span>有<span class="math inline">\(P\{X_{n+m}=j\vertX_n=i,X_{n-1}=i_{n-1},\cdots,X_{1}=i_1\}=P\{X_{n+m}=j\vertX_n=i\}\)</span>,则称<span class="math inline">\(\{X_n,n=1,2,\dots\}\)</span>为一个马尔科夫链.事实上,可以证明若上述等式对于<span class="math inline">\(m=1\)</span>成立,则它对于任意的正整数<span class="math inline">\(m\)</span>也成立.因此,只要当<span class="math inline">\(m=1\)</span>时上述等式成立,就可以称随机序列<span class="math inline">\(\{X_n,n=1,2,\dots\}\)</span>具有马氏性</p><p>定义:设<span class="math inline">\(\{X_n,n=1,2,\dots\}\)</span>是一个马氏链.如果上述等式右边的条件概率与<span class="math inline">\(n\)</span>无关,即 <span class="math display">\[P\{X_{n+m}=j\vert X_n=i\} = p_{ij}(m)\]</span> 则称<span class="math inline">\(\{X_n,n=1,2,\dots\}\)</span>为时齐的马氏链.称<span class="math inline">\(p_{ij}(m)\)</span>为系统由状态<span class="math inline">\(i\)</span>经过<span class="math inline">\(m\)</span>个时间间隔转移到状态<span class="math inline">\(j\)</span>的转移概率.式<span class="math inline">\((1)\)</span>称为时齐性,它的含义是系统由状态<span class="math inline">\(i\)</span>到状态<span class="math inline">\(j\)</span>的转移概率只依赖于时间间隔的长短,与起始的时刻无关.下面介绍的马氏链假定都是时齐的,为了行文方便省略"时齐"二字.</p><h4 id="转移状态矩阵及柯尔莫哥洛夫定理">转移状态矩阵及柯尔莫哥洛夫定理</h4><p>对于一个马尔科夫链<span class="math inline">\(\{X_n,n=1,2,\dots\}\)</span>,称以<span class="math inline">\(m\)</span>步转移概率<span class="math inline">\(p_{ij}(m)\)</span>为元素的矩阵<span class="math inline">\(P(m)=(p_{ij}(m))\)</span>为马尔科夫链的<span class="math inline">\(m\)</span>步转移矩阵.当<span class="math inline">\(m=1\)</span>时,记<span class="math inline">\(P(1)=P\)</span>称为马尔科夫链的一步状态转移矩阵,或简称转移矩阵.它们具有以下三个基本性质:</p><p><span class="math inline">\((1)\)</span>对一切<span class="math inline">\(i,j\in E,0\le p_{ij}(m)\le1\)</span></p><p><span class="math inline">\((2)\)</span>对一切<span class="math inline">\(i\in E,\sum\limits_{j\inE}P_{ij}(m)=1\)</span></p><p><span class="math inline">\((3)\)</span>对一切<span class="math inline">\(i,j\inE,p_{ij}(0)=\delta_{ij}=\begin{cases}1&amp;,\text{当}i=j\\0,&amp;,\text{当}i\nej\end{cases}\)</span></p><p>当实际问题可以用马尔科夫链来描述时,首先需要确定它的状态空间集参数集合,然后确定它的一步转移概率.关于这一概率的确定,可以由问题的内在规律得到,也可以由过去的经验给出,还可以根据观测数据来估计.</p><p>定理(柯尔莫哥洛夫-----开普曼定理):设<span class="math inline">\(\{X_n,n=1,2,\dots\}\)</span>是一个马尔科夫链,其状态空间<span class="math inline">\(E=\{1,2,\dots\},\)</span>则对任意的正整数<span class="math inline">\(m,n\)</span>,有 <span class="math display">\[p_{ij}(n+m)=\sum\limits_{k\in E}p_{ik}(n)p_{kj}(m),\quad where\,i,j\in E\]</span> 定理:设<span class="math inline">\(P\)</span>是一步马氏链转移矩阵(<span class="math inline">\(P\)</span>的行向量是概率向量),<span class="math inline">\(P^{(0)}\)</span>是初始分布行向量,则第<span class="math inline">\(n\)</span>步的概率分布为 <span class="math display">\[P^{(n)}=P^{(0)}P^{n}\]</span></p><h4 id="转移概率的渐进性质----极限概率分布">转移概率的渐进性质----极限概率分布</h4><p>定义:一个马氏链的转移矩阵<span class="math inline">\(P\)</span>是正则的,当且仅当存在正整数<span class="math inline">\(k\)</span>,使<span class="math inline">\(P^{k}\)</span>的每一个元素都是正数.</p><p>定理:若<span class="math inline">\(P\)</span>是一个马氏链的正则阵,则:</p><p>(1)<span class="math inline">\(P\)</span>有唯一的不动点向量<span class="math inline">\(W\)</span>,<span class="math inline">\(W\)</span>的每一个分量为正.</p><p><span class="math inline">\((2)P\)</span>的<span class="math inline">\(n\)</span>次幂(n为正整数)随<span class="math inline">\(n\)</span>的增加趋近于矩阵<span class="math inline">\(\overline{W}\)</span>,<span class="math inline">\(\overline{W}\)</span>的每一行向量均等于不动点向量<span class="math inline">\(W\)</span></p><p>一般地,设马氏链的状态空间为<span class="math inline">\(E\)</span>,如果对于所有的<span class="math inline">\(i,j\in E\)</span>,状态概率<span class="math inline">\(p_{ij}(n)\)</span>存在极限 <span class="math display">\[\lim\limits_{n\to\infty}p_{ij}(n)=\pi_j\]</span> 或 <span class="math display">\[P(n)=P^{n}\longrightarrow\begin{bmatrix}\pi_1&amp;\pi_2&amp;\cdots&amp;\pi_j&amp;\cdots\\\pi_1&amp;\pi_2&amp;\cdots&amp;\pi_j&amp;\cdots\\\cdots&amp;\cdots&amp;\cdots&amp;\cdots&amp;\cdots\\\pi_1&amp;\pi_2&amp;\cdots&amp;\pi_j&amp;\cdots\\\cdots&amp;\cdots&amp;\cdots&amp;\cdots&amp;\cdots\\\end{bmatrix},\quadn\to\infty\]</span> 则称此链具有遍历性.又若<span class="math inline">\(\sum\limits_{j}\pi_{j}=1\)</span>,则同时称<span class="math inline">\(\pi=[\pi_1,\pi_2,\dots]\)</span>为链的极限分布</p><p>定理:设马氏链<span class="math inline">\(\{X_n,n=1,2,\dots\}\)</span>的状态空间为<span class="math inline">\(E=\{a_1,\dots,a_N\},P=(p_{ij})\)</span>是它的一步转移概率矩阵,如果存在正整数<span class="math inline">\(m\)</span>,使得对任意的<span class="math inline">\(a_i,a_j\in E\)</span>,都有 <span class="math display">\[p_{ij}(m)&gt;0,\,i,j=1,2,\dots,N\]</span> 则此链具有遍历性;且有极限分布<span class="math inline">\(\pi=[\pi_1,\dots,\pi_N],\)</span>它是方程组 <span class="math display">\[\pi = \piP\,\text{或者}\,\pi_j=\sum_{i=1}^{N}\pi_ip_{ij},\quad,j=1,\dots,N\]</span> 的满足条件<span class="math inline">\(\pi_j&gt;0,\sum\limits_{j=1}^{N}\pi_{j}=1\)</span>的唯一解</p><p>例:为适应日益扩大的旅游事业的需要,某城市的甲,乙,丙三个照相馆组成一个联营部,联合经营出租相机的业务.游客可由甲,乙,丙三处任何一处租出相机,用完后,还在三处中任意一处即可.估计其转移概率如下所示.今欲选择其中之一附近设置相机维修点,问该点设在哪一个照相馆为最好?<span class="math display">\[\begin{bmatrix}0.2&amp;0.8&amp;0\\0.8&amp;0&amp;0.2\\0.1&amp;0.3&amp;0.6\end{bmatrix},\quadwhere\quad p_{ij}\text{表示在}i\text{处租,在}j\text{处还的概率}\]</span> 解:设<span class="math inline">\(\{X_n,n=1,2,\dots\}\)</span>是一个马尔科夫链,表示相机第<span class="math inline">\(n\)</span>次租时在甲,乙,丙馆.已知它是一个马尔科夫链,其转移矩阵为<span class="math inline">\((8)\)</span>.考虑维修点的设置地点问题,实际上要计算这一马尔科夫链的极限概率分布.</p><p>已知状态转移矩阵是正则的,极限概率存在,解方程组 <span class="math display">\[\begin{cases}&amp;p_1=0.2p_1+0.8p_2+0.1p_3,\\&amp;p_2=0.8p_1+0.3p_3,\\&amp;p_3=0.2p_2+0.6p_3,\\&amp;p_1+p_2+p_3=1\end{cases}\]</span> 得极限概率<span class="math inline">\(p_1=0.4146,p_2=0.3902,p_3=0.1951\)</span></p><p>由计算可看出,经过长期经营后,该联营部的每驾照相机还到甲,乙,丙照相馆的概率分别是0.4146,0.3902,0.1951.由于还到甲馆的照相机较多,因此维修点设在甲馆较好.但由于还到乙馆的相机与还到甲馆的相差不多,若是乙的其他因素更为有利的话,比如,交通较甲方便,便于零件的运输,电力供应稳定等等,也可以考虑设在乙馆.</p>]]></content>
    
    
    <categories>
      
      <category>数学建模</category>
      
      <category>预测</category>
      
    </categories>
    
    
    <tags>
      
      <tag>数学建模</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>最小费用流问题</title>
    <link href="/posts/26295.html"/>
    <url>/posts/26295.html</url>
    
    <content type="html"><![CDATA[<hr><div class="note note-success">            <p>数学建模 图论 Python</p>          </div><h3 id="最小费用流问题">最小费用流问题</h3><p>在许多实际问题中,往往还要考虑网络流上流的费用问题.例如,在运输问题中,人们总是希望在完成运输任务的同时,寻求一个能使总费用最小的运输方案.</p><p>设<span class="math inline">\(f_{ij}\)</span>为弧<span class="math inline">\((v_i,v_j)\)</span>上的流量,<span class="math inline">\(b_{ij}\)</span>为弧<span class="math inline">\((v_i,v_j)\)</span>上的单位费用,<span class="math inline">\(c_{ij}\)</span>为弧<span class="math inline">\((v_I,v_j)\)</span>上的容量,则最小费用流问题可以用如下数学模型描述:<span class="math display">\[\min\quad\sum_{(v_i,v_j)\in A}b_{ij}f_{ij},\\s.t. \begin{cases}\sum\limits_{j:(v_i,v_j)\inA}f_{ij}-\sum\limits_{j:(v_j,v_i)\inA}f_{ji}=\begin{cases}v&amp;,i=s\\-v&amp;,i=t\\0&amp;,i\nes,t,\end{cases} \\0\le f_{ij}\le c_{ij},\forall(v_i,v_j)\in A\end{cases}\]</span> 当<span class="math inline">\(v=\)</span>最大流<span class="math inline">\(v_{max}\)</span>时,本问题就是最小费用最大流问题;如果<span class="math inline">\(v&gt;v_{max}\)</span>,本问题无解.</p><p>例:如下图带有运费的网络,求从<span class="math inline">\(v_1\)</span>到<span class="math inline">\(v_6\)</span>的最小费用最大流,其中弧上权重的第一个数字是网络的容量,第二个数字是网络的单位运费.</p><p><img src="https://pjs-1312672154.cos.ap-shanghai.myqcloud.com/figure8.png"></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">import</span> numpy <span class="hljs-keyword">as</span> np<br><span class="hljs-keyword">import</span> networkx <span class="hljs-keyword">as</span> nx<br><span class="hljs-keyword">from</span> networkx.algorithms.matching <span class="hljs-keyword">import</span> max_weight_matching<br><span class="hljs-keyword">import</span> seaborn <span class="hljs-keyword">as</span> sns<br><span class="hljs-keyword">import</span> matplotlib.pyplot <span class="hljs-keyword">as</span> plt<br><span class="hljs-keyword">import</span> pandas <span class="hljs-keyword">as</span> pd<br>sns.set_theme(style=<span class="hljs-string">&quot;dark&quot;</span>)<span class="hljs-comment">#用来设置主题背景</span><br>plt.rcParams[<span class="hljs-string">&quot;font.sans-serif&quot;</span>] = [<span class="hljs-string">&quot;SimHei&quot;</span>] <span class="hljs-comment">#用来正常显示中文标签</span><br>plt.rcParams[<span class="hljs-string">&quot;axes.unicode_minus&quot;</span>] = <span class="hljs-literal">False</span> <span class="hljs-comment">#用来正常显示负号</span><br>L = [(<span class="hljs-number">1</span>,<span class="hljs-number">2</span>,<span class="hljs-number">5</span>,<span class="hljs-number">3</span>),(<span class="hljs-number">1</span>,<span class="hljs-number">3</span>,<span class="hljs-number">3</span>,<span class="hljs-number">6</span>),(<span class="hljs-number">2</span>,<span class="hljs-number">4</span>,<span class="hljs-number">2</span>,<span class="hljs-number">8</span>),(<span class="hljs-number">3</span>,<span class="hljs-number">2</span>,<span class="hljs-number">1</span>,<span class="hljs-number">2</span>),(<span class="hljs-number">3</span>,<span class="hljs-number">5</span>,<span class="hljs-number">4</span>,<span class="hljs-number">2</span>),(<span class="hljs-number">4</span>,<span class="hljs-number">3</span>,<span class="hljs-number">1</span>,<span class="hljs-number">1</span>),(<span class="hljs-number">4</span>,<span class="hljs-number">5</span>,<span class="hljs-number">3</span>,<span class="hljs-number">4</span>),(<span class="hljs-number">4</span>,<span class="hljs-number">6</span>,<span class="hljs-number">2</span>,<span class="hljs-number">10</span>),(<span class="hljs-number">5</span>,<span class="hljs-number">6</span>,<span class="hljs-number">5</span>,<span class="hljs-number">2</span>)] <span class="hljs-comment">#注意此处不能直接由邻接矩阵生成图</span><br>G = nx.DiGraph()<br><span class="hljs-keyword">for</span> k <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(<span class="hljs-built_in">len</span>(L)):<br>    G.add_edge(L[k][<span class="hljs-number">0</span>]-<span class="hljs-number">1</span>,L[k][<span class="hljs-number">1</span>]-<span class="hljs-number">1</span>,capacity=L[k][<span class="hljs-number">2</span>],weight=L[k][<span class="hljs-number">3</span>])<br>mincostFlow = nx.max_flow_min_cost(G,<span class="hljs-number">0</span>,<span class="hljs-number">5</span>)<span class="hljs-comment">#求解网络最小费用最大流问题</span><br>dict_temp = &#123;&#125;<br><span class="hljs-keyword">for</span> i,item <span class="hljs-keyword">in</span> mincostFlow.items():<br>    <span class="hljs-keyword">for</span> j,weight <span class="hljs-keyword">in</span> item.items():<br>        dict_temp[(i,j)] = weight <span class="hljs-comment">#改变字典结构</span><br>plt.figure(dpi=<span class="hljs-number">500</span>)<br>node_labels=<span class="hljs-built_in">dict</span>(<span class="hljs-built_in">zip</span>(<span class="hljs-built_in">range</span>(<span class="hljs-number">6</span>),[<span class="hljs-string">&quot;V&quot;</span>+<span class="hljs-built_in">str</span>(i) <span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(<span class="hljs-number">1</span>,<span class="hljs-number">7</span>)])) <span class="hljs-comment">#构造用于顶点标记的字典</span><br>pos = nx.circular_layout(G)<span class="hljs-comment">#设置布局</span><br>path_edges = [key <span class="hljs-keyword">for</span> key,item <span class="hljs-keyword">in</span> dict_temp.items() <span class="hljs-keyword">if</span> item !=<span class="hljs-number">0</span>]<br>nx.draw_networkx(G,pos,node_size=<span class="hljs-number">270</span>,labels=node_labels) <span class="hljs-comment">#绘制图</span><br>nx.draw_networkx_edge_labels(G,pos,font_size=<span class="hljs-number">10</span>,edge_labels=dict_temp)<span class="hljs-comment">#标记权重</span><br>nx.draw_networkx_edges(G,pos,edgelist=path_edges,edge_color=<span class="hljs-string">&quot;r&quot;</span>,width=<span class="hljs-number">3</span>)<span class="hljs-comment">#标记路径</span><br>plt.savefig(<span class="hljs-string">&quot;figure9.png&quot;</span>)<br>plt.show()<br>mincost = nx.cost_of_flow(G,mincostFlow)<br><span class="hljs-built_in">print</span>(<span class="hljs-string">&quot;最小费用为&#123;&#125;&quot;</span>.<span class="hljs-built_in">format</span>(mincost))<br></code></pre></td></tr></table></figure><figure class="highlight"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs">最小费用为63<br></code></pre></td></tr></table></figure>]]></content>
    
    
    <categories>
      
      <category>数学建模</category>
      
      <category>图论</category>
      
    </categories>
    
    
    <tags>
      
      <tag>数学建模</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>最大流问题</title>
    <link href="/posts/26900.html"/>
    <url>/posts/26900.html</url>
    
    <content type="html"><![CDATA[<hr><div class="note note-success">            <p>数学建模 图论 Python</p>          </div><h3 id="最大流问题">最大流问题</h3><p>许多系统包含了流量问题,如公里系统中有车辆流,金融系统中有现金流等.这些流问题都可归结为网络流问题,且都存在如何安排使流量最大的问题,即最大流问题.</p><p>定义:给定一个有向图<span class="math inline">\(D=(V,A)\)</span>,其中<span class="math inline">\(A\)</span>为弧集,在<span class="math inline">\(V\)</span>中指定一点,称为源(记为<span class="math inline">\(v_S\)</span>),该点只有发出的弧;同时指定一个点为汇(记为<span class="math inline">\(v_t\)</span>),该点只有进入的弧;其余的点叫做中间点,对于每一条弧<span class="math inline">\((v_i,v_j)\in A\)</span>,对应有一个<span class="math inline">\(c(v_i,v_j)\ge0\)</span>称为弧的容量.通常就把这样的有向图<span class="math inline">\(D\)</span>叫做一个网络,记作<span class="math inline">\(D=(V,A,C),where C=\{c_{ij}\}\)</span></p><p>所谓网路上的流,是指定义在弧集合<span class="math inline">\(A\)</span>上的v一个函数<span class="math inline">\(f=\{f_{ij}\}=\{f(v_i,v_j)\},\)</span>并称<span class="math inline">\(f_{ij}\)</span>为弧<span class="math inline">\((v_I,v_j)\)</span>的流量.</p><p>定义 满足下列条件的流称为==可行流==</p><p>(1)容量限制条件:对每一弧<span class="math inline">\((v_i,v_j)\inA,0\le f_{ij}\le c_{ij};\)</span></p><p>(2)平衡条件:对于中间点,流出量<span class="math inline">\(=\)</span>流入量,即对每一个<span class="math inline">\(i(i\ne s,t)\)</span>有 <span class="math display">\[\sum_{j:(v_i,v_j)\in A}f_{ij}-\sum_{j:(v_i,v_j)\in A}f_{ji} = 0\]</span> 对于出发点<span class="math inline">\(v_s\)</span>,记 <span class="math display">\[\sum_{(v_s,v_j)\in A}f_{sj}-\sum_{(v_j,v_s)}f_{js} = v\]</span> 对于收点<span class="math inline">\(v_t\)</span> <span class="math display">\[\sum_{(v_j,v_t)}f_{jt}-\sum_{(v_t,v_j)}f_{tj}=v\]</span> 其中<span class="math inline">\(v\)</span>称为这个可行流的流量,即出发点的净输出量.</p>最大流问题可以写成如下的线性规划模型 $$<span class="math display">\[\begin{split}&amp;max\quad v\\&amp;s.t. \begin{cases}        \sum\limits_{j:(v_i,v_j)\in A}f_{ij}-\sum\limits_{j:(v_j,v_i)\inA}f_{ji} = \begin{cases}                                                                                                                                                        v,\quadi=s,\\                                                                        -v,\quadi=t\\                                                                        0,\quadi\ne s,t                                                                            \end{cases}\\                                                                            0\lef_{ij}\le c_{ij},\quad \forall (v_i,v_j)\in A      \end{cases}\end{split}\]</span><p>$$</p><h4 id="用networkx求网络最大流问题">用networkx求网络最大流问题</h4><p>例:求下图所示网络从<span class="math inline">\(v_1\)</span>到<span class="math inline">\(v_6\)</span>的最大流(图中边上所标数字不代表权重,代表容量capacity)</p><p><img src="https://drive.imgod.me/api/v3/file/get/62004/figure6.png?sign=Jzqi9WPHio0NM7cfX8hN-xPrY4cIN7l_dy2061tZEIU%3D%3A0"></p><figure class="highlight"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs">最大流量为5<br></code></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">import</span> numpy <span class="hljs-keyword">as</span> np<br><span class="hljs-keyword">import</span> networkx <span class="hljs-keyword">as</span> nx<br><span class="hljs-keyword">from</span> networkx.algorithms.matching <span class="hljs-keyword">import</span> max_weight_matching<br><span class="hljs-keyword">import</span> seaborn <span class="hljs-keyword">as</span> sns<br><span class="hljs-keyword">import</span> matplotlib.pyplot <span class="hljs-keyword">as</span> plt<br><span class="hljs-keyword">import</span> pandas <span class="hljs-keyword">as</span> pd<br>sns.set_theme(style=<span class="hljs-string">&quot;dark&quot;</span>)<span class="hljs-comment">#用来设置主题背景</span><br>plt.rcParams[<span class="hljs-string">&quot;font.sans-serif&quot;</span>] = [<span class="hljs-string">&quot;SimHei&quot;</span>] <span class="hljs-comment">#用来正常显示中文标签</span><br>plt.rcParams[<span class="hljs-string">&quot;axes.unicode_minus&quot;</span>] = <span class="hljs-literal">False</span> <span class="hljs-comment">#用来正常显示负号</span><br>L = [(<span class="hljs-number">1</span>,<span class="hljs-number">2</span>,<span class="hljs-number">5</span>),(<span class="hljs-number">1</span>,<span class="hljs-number">3</span>,<span class="hljs-number">3</span>),(<span class="hljs-number">2</span>,<span class="hljs-number">4</span>,<span class="hljs-number">2</span>),(<span class="hljs-number">3</span>,<span class="hljs-number">2</span>,<span class="hljs-number">1</span>),(<span class="hljs-number">3</span>,<span class="hljs-number">5</span>,<span class="hljs-number">4</span>),(<span class="hljs-number">4</span>,<span class="hljs-number">3</span>,<span class="hljs-number">1</span>),(<span class="hljs-number">4</span>,<span class="hljs-number">5</span>,<span class="hljs-number">3</span>),(<span class="hljs-number">4</span>,<span class="hljs-number">6</span>,<span class="hljs-number">2</span>),(<span class="hljs-number">5</span>,<span class="hljs-number">6</span>,<span class="hljs-number">5</span>)] <span class="hljs-comment">#注意此处不能直接由邻接矩阵生成图</span><br>G = nx.DiGraph()<br><span class="hljs-keyword">for</span> k <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(<span class="hljs-built_in">len</span>(L)):<br>    G.add_edge(L[k][<span class="hljs-number">0</span>]-<span class="hljs-number">1</span>,L[k][<span class="hljs-number">1</span>]-<span class="hljs-number">1</span>,capacity=L[k][<span class="hljs-number">2</span>])<br>value,flow_dict = nx.maximum_flow(G,<span class="hljs-number">0</span>,<span class="hljs-number">5</span>)<span class="hljs-comment">#求解网络最大流问题</span><br>dict_temp = &#123;&#125;<br><span class="hljs-keyword">for</span> i,item <span class="hljs-keyword">in</span> flow_dict.items():<br>    <span class="hljs-keyword">for</span> j,weight <span class="hljs-keyword">in</span> item.items():<br>        dict_temp[(i,j)] = weight <span class="hljs-comment">#改变字典结构</span><br>plt.figure(dpi=<span class="hljs-number">500</span>)<br>node_labels=<span class="hljs-built_in">dict</span>(<span class="hljs-built_in">zip</span>(<span class="hljs-built_in">range</span>(<span class="hljs-number">6</span>),[<span class="hljs-string">&quot;V&quot;</span>+<span class="hljs-built_in">str</span>(i) <span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(<span class="hljs-number">1</span>,<span class="hljs-number">7</span>)])) <span class="hljs-comment">#构造用于顶点标记的字典</span><br>pos = nx.circular_layout(G)<span class="hljs-comment">#设置布局</span><br>path_edges = [key <span class="hljs-keyword">for</span> key,item <span class="hljs-keyword">in</span> dict_temp.items() <span class="hljs-keyword">if</span> item !=<span class="hljs-number">0</span>]<br>nx.draw_networkx(G,pos,node_size=<span class="hljs-number">270</span>,labels=node_labels) <span class="hljs-comment">#绘制图</span><br>nx.draw_networkx_edge_labels(G,pos,font_size=<span class="hljs-number">10</span>,edge_labels=dict_temp)<span class="hljs-comment">#标记权重</span><br>nx.draw_networkx_edges(G,pos,edgelist=path_edges,edge_color=<span class="hljs-string">&quot;r&quot;</span>,width=<span class="hljs-number">3</span>)<span class="hljs-comment">#标记路径</span><br>plt.savefig(<span class="hljs-string">&quot;figure7.png&quot;</span>)<br>plt.show()<br><span class="hljs-built_in">print</span>(<span class="hljs-string">&quot;最大流量为&#123;&#125;&quot;</span>.<span class="hljs-built_in">format</span>(value))<br></code></pre></td></tr></table></figure><p><img src="https://drive.imgod.me/api/v3/file/get/62006/figure7.png?sign=tSIBnFIF9FXdB31V-_-PGIFYern-ojPIvahjcvD_LQk%3D%3A0"></p>]]></content>
    
    
    <categories>
      
      <category>数学建模</category>
      
      <category>图论</category>
      
    </categories>
    
    
    <tags>
      
      <tag>数学建模</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>匹配问题</title>
    <link href="/posts/26899.html"/>
    <url>/posts/26899.html</url>
    
    <content type="html"><![CDATA[<hr><div class="note note-success">            <p>数学建模 图论 Python</p>          </div><h3 id="匹配问题">匹配问题</h3><p>定义：在图<span class="math inline">\(G=(V,E)\)</span>中，若<span class="math inline">\(M\subset E,\forall e_i,e_j\inM,e_i,e_j\)</span>无公共端点<span class="math inline">\((i\nej)\)</span>，则称<span class="math inline">\(M\)</span>为图<span class="math inline">\(G\)</span>中的一个对集；<span class="math inline">\(M\)</span>中一条边的两个端点叫做在对集<span class="math inline">\(M\)</span>中相配；<span class="math inline">\(M\)</span>中的端点称为被<span class="math inline">\(M\)</span>许配；<span class="math inline">\(G\)</span>中每一个端点都被<span class="math inline">\(M\)</span>许配则称<span class="math inline">\(M\)</span>为完美对集。<span class="math inline">\(G\)</span>中已经没有<span class="math inline">\(\vert M^\prime\vert&gt;\vertM\vert\)</span>的对集<span class="math inline">\(M^\prime\)</span>，则称<span class="math inline">\(M\)</span>为最大对集；</p><p>定理：若图<span class="math inline">\(G\)</span>是<span class="math inline">\(k\)</span>次正则二分图（每个顶点皆为<span class="math inline">\(k\)</span>度的二分图），则<span class="math inline">\(G\)</span>有完美对集。</p><p>人员分配问题：工作人员<span class="math inline">\(x_1,x_2,\cdots,x_n\)</span>去做<span class="math inline">\(n\)</span>件工作<span class="math inline">\(y_1,y_2,\cdots,y_n\)</span>,每个人适合做其中一件或几件，问能否每人都有一份适合的工作？如果不能，最多几人可以有适合的工作？</p><p>这个问题的模型是:<span class="math inline">\(G=(V,E)\)</span>是二分图，顶点集<span class="math inline">\(V=X\bigcupY,X=\{x_1,x_2,\dots,x_n\}，Y=\{y_1,y_2,\dots,y_n\}\)</span>,当且仅当<span class="math inline">\(x_i\)</span>适合做工作<span class="math inline">\(y_i\)</span>时，<span class="math inline">\(x_iy_i\in E\)</span>,求<span class="math inline">\(G\)</span>中最大对集。</p><p>最优分配问题：在人员分配问题中，工作人员适合做的各项工作效益未必一致，需要制定一个分配方案，使公司总效益最大。</p><p>这个问题的数学模型是：在人员分配问题的模型中，图<span class="math inline">\(G=(V,E,W)\)</span>为赋权图，每条边加了权<span class="math inline">\(w(x_iy_j)\ge0\)</span>,表示<span class="math inline">\(x_i\)</span>干<span class="math inline">\(y_i\)</span>工作的效益，求赋权图<span class="math inline">\(G\)</span>的权最大的完美对集</p><p>例：假设分配5个人做5项工作，每个人做不同工作的效益由邻接矩阵 <span class="math display">\[W = (W_{ij})_{5\times5}=\begin{bmatrix}        3 &amp;5&amp;5&amp;4&amp;1 \\         2&amp;2&amp;0&amp;2&amp;2\\         2&amp;4&amp;4&amp;1&amp;0\\         0&amp;2&amp;2&amp;1&amp;0\\         1&amp;2&amp;1&amp;3&amp;3    \end{bmatrix}\]</span> 表示，即<span class="math inline">\(w_{ij}(i,j=1,2,3,4,5)\)</span>表示第<span class="math inline">\(i\)</span>个人做第<span class="math inline">\(j\)</span>项工作的效益，试求使效益达到最大的分配方案。</p><p>解 构造赋权图<span class="math inline">\(G=(V,E,\widetilde{W})\)</span>,顶点集<span class="math inline">\(V=\{v_1,v_2,\cdots,v_{10}\}\)</span>，<span class="math inline">\(v_1,v_2,\dots,v_5\)</span>表示5个人，<span class="math inline">\(v_6,v_7,\dots,v_{10}\)</span>表示5项工作，邻接矩阵为<span class="math display">\[\widetilde{W} = \begin{bmatrix}                    O&amp;W\\                    O&amp;O                 \end{bmatrix}_{10\times10}\]</span> 则问题归结为求赋权图的权最大的完美对集。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">import</span> numpy <span class="hljs-keyword">as</span> np<br><span class="hljs-keyword">import</span> networkx <span class="hljs-keyword">as</span> nx<br><span class="hljs-keyword">from</span> networkx.algorithms.matching <span class="hljs-keyword">import</span> max_weight_matching<br><span class="hljs-keyword">import</span> seaborn <span class="hljs-keyword">as</span> sns<br><span class="hljs-keyword">import</span> matplotlib.pyplot <span class="hljs-keyword">as</span> plt<br><span class="hljs-keyword">import</span> pandas <span class="hljs-keyword">as</span> pd<br>sns.set_theme(style=<span class="hljs-string">&quot;dark&quot;</span>)<span class="hljs-comment">#用来设置主题背景</span><br>plt.rcParams[<span class="hljs-string">&quot;font.sans-serif&quot;</span>] = [<span class="hljs-string">&quot;SimHei&quot;</span>] <span class="hljs-comment">#用来正常显示中文标签</span><br>plt.rcParams[<span class="hljs-string">&quot;axes.unicode_minus&quot;</span>] = <span class="hljs-literal">False</span> <span class="hljs-comment">#用来正常显示负号</span><br>A = np.array([[<span class="hljs-number">3</span>,<span class="hljs-number">5</span>,<span class="hljs-number">5</span>,<span class="hljs-number">4</span>,<span class="hljs-number">1</span>]<br>             ,[<span class="hljs-number">2</span>,<span class="hljs-number">2</span>,<span class="hljs-number">0</span>,<span class="hljs-number">2</span>,<span class="hljs-number">2</span>]<br>             ,[<span class="hljs-number">2</span>,<span class="hljs-number">4</span>,<span class="hljs-number">4</span>,<span class="hljs-number">1</span>,<span class="hljs-number">0</span>]<br>             ,[<span class="hljs-number">0</span>,<span class="hljs-number">2</span>,<span class="hljs-number">2</span>,<span class="hljs-number">1</span>,<span class="hljs-number">0</span>]<br>             ,[<span class="hljs-number">1</span>,<span class="hljs-number">2</span>,<span class="hljs-number">1</span>,<span class="hljs-number">3</span>,<span class="hljs-number">3</span>]])<br>W = np.zeros((<span class="hljs-number">10</span>,<span class="hljs-number">10</span>))<br>W[<span class="hljs-number">0</span>:<span class="hljs-number">5</span>,<span class="hljs-number">5</span>:] = A<span class="hljs-comment">#创建邻接矩阵</span><br>G = nx.Graph(W)<span class="hljs-comment">#创建无向图</span><br>s = max_weight_matching(G)<br>p = <span class="hljs-built_in">list</span>(s)<br>plt.figure(dpi=<span class="hljs-number">500</span>)<br>node_labels=<span class="hljs-built_in">dict</span>(<span class="hljs-built_in">zip</span>(<span class="hljs-built_in">range</span>(<span class="hljs-number">10</span>),[<span class="hljs-string">&quot;V&quot;</span>+<span class="hljs-built_in">str</span>(i) <span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(<span class="hljs-number">1</span>,<span class="hljs-number">11</span>)])) <span class="hljs-comment">#构造用于顶点标记的字典</span><br>pos = nx.circular_layout(G)<span class="hljs-comment">#设置布局</span><br>w = nx.get_edge_attributes(G,<span class="hljs-string">&quot;weight&quot;</span>) <span class="hljs-comment">#获取边的权重</span><br>nx.draw_networkx(G,pos,node_size=<span class="hljs-number">270</span>,labels=node_labels) <span class="hljs-comment">#绘制图</span><br>nx.draw_networkx_edge_labels(G,pos,font_size=<span class="hljs-number">10</span>,edge_labels=w)<span class="hljs-comment">#标记权重</span><br>path_edges=p<span class="hljs-comment">#标记路径的元组组成的列表</span><br>nx.draw_networkx_edges(G,pos,edgelist=path_edges,edge_color=<span class="hljs-string">&quot;r&quot;</span>,width=<span class="hljs-number">3</span>)<span class="hljs-comment">#标记路径</span><br>plt.savefig(<span class="hljs-string">&quot;figure5.png&quot;</span>)<br>plt.show()<br>x = [<span class="hljs-built_in">sorted</span>([i[<span class="hljs-number">0</span>],i[<span class="hljs-number">1</span>]]) <span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> s] <br>df = pd.DataFrame(np.array(x),columns=[<span class="hljs-string">&quot;worker&quot;</span>,<span class="hljs-string">&quot;task&quot;</span>])<br>temp = [W[df.loc[i,<span class="hljs-string">&quot;worker&quot;</span>],df.loc[i,<span class="hljs-string">&quot;task&quot;</span>]] <span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(df.shape[<span class="hljs-number">0</span>])]<br>benefit = [W[df.loc[i,<span class="hljs-string">&quot;worker&quot;</span>],df.loc[i,<span class="hljs-string">&quot;task&quot;</span>]] <span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(df.shape[<span class="hljs-number">0</span>])]<br>df[<span class="hljs-string">&quot;benefit&quot;</span>]  = benefit<br>df[<span class="hljs-string">&quot;worker&quot;</span>] = df[<span class="hljs-string">&quot;worker&quot;</span>]+<span class="hljs-number">1</span><br>df[<span class="hljs-string">&quot;task&quot;</span>] = df[<span class="hljs-string">&quot;task&quot;</span>]-<span class="hljs-number">4</span><br><span class="hljs-built_in">print</span>(<span class="hljs-string">&quot;总的效益&#123;&#125;&quot;</span>.<span class="hljs-built_in">format</span>(df[<span class="hljs-string">&quot;benefit&quot;</span>].<span class="hljs-built_in">sum</span>()))<br>df.head(<span class="hljs-number">10</span>)<br></code></pre></td></tr></table></figure><figure class="highlight"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs">总的效益15.0<br></code></pre></td></tr></table></figure><p><img src="https://drive.imgod.me/api/v3/file/get/62001/figure5.png?sign=BtppWO4epWUcHze3yRDxGKDs13KhKvHIVFZ1O-QS4-Y%3D%3A0"></p><p><img src="https://drive.imgod.me/api/v3/file/get/62002/QQ%E6%88%AA%E5%9B%BE20220628101703.png?sign=vPKfZD_0WYJsdwvRUcNLQPr2MyTvtjtOU1TIQgxRXjo%3D%3A0"></p>]]></content>
    
    
    <categories>
      
      <category>数学建模</category>
      
      <category>图论</category>
      
    </categories>
    
    
    <tags>
      
      <tag>数学建模</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>最小生成树</title>
    <link href="/posts/57313.html"/>
    <url>/posts/57313.html</url>
    
    <content type="html"><![CDATA[<hr><div class="note note-success">            <p>数学建模 图论 Python</p>          </div><h3 id="最小生成树算法及其networkx实现">最小生成树算法及其networkx实现</h3><p>树是图论中非常重要的一类图，它非常类似于自然界的树，结构简单、应用广泛，最小生成树问题则是其中经典的问题之一。在实际应用中，许多问题的图论模型都是最小生成树，如通信网络建设、有线电缆铺设、加工设备分组等。关键词：连通，无圈，最短。</p><h3 id="基本概念">基本概念</h3><p>定义：连通的无圈图称为树。</p><p>定理：设<span class="math inline">\(G\)</span>是具有<span class="math inline">\(n\)</span>个顶点<span class="math inline">\(m\)</span>条边的图，则下列命题等价：</p><p>（1）图<span class="math inline">\(G\)</span>是树；</p><p>（2）图<span class="math inline">\(G\)</span>中任意两个不同顶点之间存在唯一的路；</p><p>（3）图<span class="math inline">\(G\)</span>连通，删除任一条边均不连通；</p><p>（4）图<span class="math inline">\(G\)</span>连通，且<span class="math inline">\(n=m+1\)</span>；</p><p>（5）图<span class="math inline">\(G\)</span>无圈，添加任一条边可得唯一的圈；</p><p>（6）图<span class="math inline">\(G\)</span>无圈，且<span class="math inline">\(n=m+1\)</span>.</p><p>定义：若图<span class="math inline">\(G\)</span>的生成子图<span class="math inline">\(H\)</span>是树，则称<span class="math inline">\(H\)</span>为<span class="math inline">\(G\)</span>的生成树。一个图的生成树往往不唯一。</p><p>定理：连通图的生成树一定存在。</p><p>定义：在赋权图<span class="math inline">\(G\)</span>中，边权之和最小的生成树称为<span class="math inline">\(G\)</span>的最小生成树。</p><h3 id="最小生成树算法">最小生成树算法</h3><p>构造连通图最小生成树的算法有Kruskal算法和Prim算法。均可以在networkx中实现。</p><p>例：已知8口井，相互之间的距离如下表，已知1号油井离海岸线最近，为5nmil。问从海岸经一号油井铺设管道将各油井连接起来，应如何铺设使油管长度最短。</p><p><img src="https://drive.imgod.me/api/v3/file/get/61997/QQ%E6%88%AA%E5%9B%BE20220627191701.png?sign=NwhSbk0-PlOFJlM5PfxCTKCgD-TQs53UdwnVkUffd4A%3D%3A0"></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">import</span> numpy <span class="hljs-keyword">as</span> np<br><span class="hljs-keyword">import</span> networkx <span class="hljs-keyword">as</span> nx<br><span class="hljs-keyword">import</span> seaborn <span class="hljs-keyword">as</span> sns<br><span class="hljs-keyword">import</span> matplotlib.pyplot <span class="hljs-keyword">as</span> plt<br>sns.set_theme(style=<span class="hljs-string">&quot;dark&quot;</span>)<span class="hljs-comment">#用来设置主题背景</span><br>plt.rcParams[<span class="hljs-string">&quot;font.sans-serif&quot;</span>] = [<span class="hljs-string">&quot;SimHei&quot;</span>] <span class="hljs-comment">#用来正常显示中文标签</span><br>plt.rcParams[<span class="hljs-string">&quot;axes.unicode_minus&quot;</span>] = <span class="hljs-literal">False</span> <span class="hljs-comment">#用来正常显示负号</span><br>W_input = np.array([[<span class="hljs-number">0</span>,<span class="hljs-number">1.3</span>,<span class="hljs-number">2.1</span>,<span class="hljs-number">0.9</span>,<span class="hljs-number">0.7</span>,<span class="hljs-number">1.8</span>,<span class="hljs-number">2.0</span>,<span class="hljs-number">1.5</span>]<br>            ,[<span class="hljs-number">0</span>,<span class="hljs-number">0</span>,<span class="hljs-number">0.9</span>,<span class="hljs-number">1.8</span>,<span class="hljs-number">1.2</span>,<span class="hljs-number">2.6</span>,<span class="hljs-number">2.3</span>,<span class="hljs-number">1.1</span>]<br>            ,[<span class="hljs-number">0</span>,<span class="hljs-number">0</span>,<span class="hljs-number">0</span>,<span class="hljs-number">2.6</span>,<span class="hljs-number">1.7</span>,<span class="hljs-number">2.5</span>,<span class="hljs-number">1.9</span>,<span class="hljs-number">1.0</span>]<br>            ,[<span class="hljs-number">0</span>,<span class="hljs-number">0</span>,<span class="hljs-number">0</span>,<span class="hljs-number">0</span>,<span class="hljs-number">0.7</span>,<span class="hljs-number">1.6</span>,<span class="hljs-number">1.5</span>,<span class="hljs-number">0.9</span>]<br>            ,[<span class="hljs-number">0</span>,<span class="hljs-number">0</span>,<span class="hljs-number">0</span>,<span class="hljs-number">0</span>,<span class="hljs-number">0</span>,<span class="hljs-number">0.9</span>,<span class="hljs-number">1.1</span>,<span class="hljs-number">0.8</span>]<br>            ,[<span class="hljs-number">0</span>,<span class="hljs-number">0</span>,<span class="hljs-number">0</span>,<span class="hljs-number">0</span>,<span class="hljs-number">0</span>,<span class="hljs-number">0</span>,<span class="hljs-number">0.6</span>,<span class="hljs-number">1.0</span>]<br>            ,[<span class="hljs-number">0</span>,<span class="hljs-number">0</span>,<span class="hljs-number">0</span>,<span class="hljs-number">0</span>,<span class="hljs-number">0</span>,<span class="hljs-number">0</span>,<span class="hljs-number">0</span>,<span class="hljs-number">0.5</span>]<br>             ,[<span class="hljs-number">0</span>,<span class="hljs-number">0</span>,<span class="hljs-number">0</span>,<span class="hljs-number">0</span>,<span class="hljs-number">0</span>,<span class="hljs-number">0</span>,<span class="hljs-number">0</span>,<span class="hljs-number">0</span>]])<br>W = W_input.T+W_input <span class="hljs-comment">#生成邻接矩阵</span><br>G  = nx.Graph(W) <span class="hljs-comment">#创建无向图</span><br>T = nx.minimum_spanning_tree(G) <span class="hljs-comment">#根据图G生成最小生成树</span><br>D = nx.to_numpy_matrix(T) <span class="hljs-comment">#获取最小生成树的邻接矩阵</span><br>plt.figure(dpi=<span class="hljs-number">500</span>)<br>node_labels = <span class="hljs-built_in">dict</span>(<span class="hljs-built_in">zip</span>(<span class="hljs-built_in">range</span>(<span class="hljs-number">8</span>),<span class="hljs-built_in">range</span>(<span class="hljs-number">1</span>,<span class="hljs-number">9</span>))) <span class="hljs-comment">#顶点标签</span><br>pos = nx.shell_layout(T)<span class="hljs-comment">#设置布局</span><br>w = nx.get_edge_attributes(T,<span class="hljs-string">&quot;weight&quot;</span>) <span class="hljs-comment">#获取边的权重</span><br>nx.draw_networkx(T,pos,node_size=<span class="hljs-number">270</span>,labels=node_labels) <span class="hljs-comment">#绘制图</span><br>nx.draw_networkx_edge_labels(T,pos,font_size=<span class="hljs-number">10</span>,edge_labels=w)<span class="hljs-comment">#标记权重</span><br>plt.savefig(<span class="hljs-string">&quot;figure4.png&quot;</span>)<br>plt.show()<br></code></pre></td></tr></table></figure><p>结果如下：</p><p><img src="https://drive.imgod.me/api/v3/file/get/61998/figure4.png?sign=pznKdZ39N6Ar0fpWKSJM5NXvt2t6ZvjY-SviJfb3S4c%3D%3A0"></p>]]></content>
    
    
    <categories>
      
      <category>数学建模</category>
      
      <category>图论</category>
      
    </categories>
    
    
    <tags>
      
      <tag>数学建模</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>最短路径及其应用</title>
    <link href="/posts/24890.html"/>
    <url>/posts/24890.html</url>
    
    <content type="html"><![CDATA[<hr><div class="note note-success">            <p>数学建模 图论 Python</p>          </div><h2 id="最短路算法及其python实现">最短路算法及其Python实现</h2><p>最短路径问题是图论中非常经典的问题之一，旨在寻找图中两顶点之间的最短路径。作为一个基本工具，实际应用中许多优化问题，如管道铺设、线路安排、工区布局、设备更新等。都可被归结为最短路径问题来解决。</p><p>定义1：设图<span class="math inline">\(G\)</span>是赋权图，<span class="math inline">\(\Gamma\)</span>为<span class="math inline">\(G\)</span>中的一条路，则称<span class="math inline">\(\Gamma\)</span>的各边权之和为路<span class="math inline">\(\Gamma\)</span>的长度。</p><p>对于<span class="math inline">\(G\)</span>的两个顶点<span class="math inline">\(u_0\)</span>和<span class="math inline">\(v_0\)</span>，从<span class="math inline">\(u_0\)</span>到<span class="math inline">\(v_0\)</span>的路不止一条，其中最短的一条称为从<span class="math inline">\(u_0\)</span>到<span class="math inline">\(v_0\)</span>的最短路；最短路的长称为从<span class="math inline">\(u_0\)</span>到<span class="math inline">\(v_0\)</span>的距离，记为<span class="math inline">\(d(u_0,v_0)\)</span>。</p><p>求最短路的算法有Dijkstra标号算法和Floyd算法，但Dijkstra标号算法只适应于边权为非负的情形，最短路径的问题也可以归结到<span class="math inline">\(0-1\)</span>规划问题。</p><h3 id="设备更新问题">设备更新问题</h3><p>某种工程设备的役龄为4年，每年年初都面临着是否更新的问题；若卖旧买新，就需要支付一定的购置费用；若继续使用，则要支付更多的维护费用，且使用年限越长维护费用就越多。若役龄期间每年的年初购置价格，当年维护费用及其年末剩余净值如下表所示。请为该设备制定一个4年役龄期内的更新计划，使总的支付费用最少。</p><table><thead><tr class="header"><th style="text-align: center;">年份</th><th>1</th><th>2</th><th>3</th><th>4</th></tr></thead><tbody><tr class="odd"><td style="text-align: center;">年初购置价格/万元</td><td>25</td><td>26</td><td>28</td><td>31</td></tr><tr class="even"><td style="text-align: center;">当年维护费用/万元</td><td>10</td><td>14</td><td>18</td><td>26</td></tr><tr class="odd"><td style="text-align: center;">年末剩余净值/万元</td><td>20</td><td>16</td><td>13</td><td>11</td></tr></tbody></table><p>解： 可以把该问题进行数学抽象</p><p>构造赋权有向图<span class="math inline">\(D=(V,A,W)\)</span>，其中顶点集<span class="math inline">\(V=\{v_1,v_2,v_3,v_4,v_5\},where\quadv_i(i=1,2,3,4)\text{表示第i年初},v_5\text{表示第5年初(第4年末)}.\)</span>,<span class="math inline">\(A\)</span>表示弧集，邻接矩阵<span class="math inline">\(W=(w_{ij})_{5\times5}\)</span>，这里<span class="math inline">\(w_{ij}\)</span>表示第<span class="math inline">\(i\)</span>年初购进机器第<span class="math inline">\(j\)</span>年初卖掉这个过程一共支付的费用，计算公式为<span class="math display">\[w_{ij}=p_i+\sum_{k=1}^{j-i}a_k-r_{j-i}\]</span> 其中<span class="math inline">\(p_i\)</span>为第<span class="math inline">\(i\)</span>年年初的购置价格,<span class="math inline">\(a_k\)</span>表示从购入开始计算使用到第k年的费用，<span class="math inline">\(r_i\)</span>表示使用<span class="math inline">\(i\)</span>年旧设备的出售价格。则邻接矩阵为： <span class="math display">\[W = \begin{bmatrix}            0&amp;15&amp;33&amp;54&amp;82\\            \infty&amp;0&amp;16&amp;34&amp;55\\            \infty&amp;\infty&amp;0&amp;18&amp;36\\            \infty&amp;\infty&amp;\infty&amp;0&amp;21\\            \infty&amp;\infty&amp;\infty&amp;\infty&amp;0            \end{bmatrix}\nonumber\]</span> 经计算得：</p><figure class="highlight clean"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs clean">最短路径为：<br><span class="hljs-number">1</span>-&gt;<span class="hljs-number">2</span>-&gt;<span class="hljs-number">3</span>-&gt;<span class="hljs-number">5</span><br>最短距离为<span class="hljs-number">67</span><br></code></pre></td></tr></table></figure><p><img src="https://s2.loli.net/2022/06/26/l4HTiCy5cR62zW8.png" style="zoom: 50%;"></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br></pre></td><td class="code"><pre><code class="hljs python">W = np.array([[<span class="hljs-number">0</span>,<span class="hljs-number">15</span>,<span class="hljs-number">33</span>,<span class="hljs-number">54</span>,<span class="hljs-number">82</span>]<br>              ,[<span class="hljs-number">0</span>,<span class="hljs-number">0</span>,<span class="hljs-number">16</span>,<span class="hljs-number">34</span>,<span class="hljs-number">55</span>]<br>              ,[<span class="hljs-number">0</span>,<span class="hljs-number">0</span>,<span class="hljs-number">0</span> ,<span class="hljs-number">18</span>,<span class="hljs-number">36</span>]<br>              ,[<span class="hljs-number">0</span>,<span class="hljs-number">0</span>,<span class="hljs-number">0</span> ,<span class="hljs-number">0</span> , <span class="hljs-number">21</span> ]<br>              ,[<span class="hljs-number">0</span>,<span class="hljs-number">0</span>,<span class="hljs-number">0</span> ,<span class="hljs-number">0</span> , <span class="hljs-number">0</span> ]])<br><span class="hljs-string">&#x27;&#x27;&#x27;注意：在利用networkx库函数计算时，如果两个顶点之间没有边，对应的邻接矩阵元素为0，而不是np.inf&#x27;&#x27;&#x27;</span><br>G=nx.DiGraph(W)<span class="hljs-comment">#创建有向图</span><br>p = nx.dijkstra_path(G,source=<span class="hljs-number">0</span>,target=<span class="hljs-number">4</span>,weight=<span class="hljs-string">&quot;weight&quot;</span>)<span class="hljs-comment">#求最短路径</span><br><span class="hljs-string">&quot;&quot;&quot;param G:图</span><br><span class="hljs-string">   param source:起点</span><br><span class="hljs-string">   param target:终点</span><br><span class="hljs-string">   param weight:用边权作为路长&quot;&quot;&quot;</span><br><span class="hljs-built_in">print</span>(<span class="hljs-string">&quot;最短路径为：&quot;</span>)<br><span class="hljs-built_in">print</span>(<span class="hljs-string">&quot;-&gt;&quot;</span>.join([<span class="hljs-built_in">str</span>(i+<span class="hljs-number">1</span>) <span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> p]))<br>d = nx.dijkstra_path_length(G,source=<span class="hljs-number">0</span>,target=<span class="hljs-number">4</span>,weight=<span class="hljs-string">&quot;weight&quot;</span>)<span class="hljs-comment">#求最短距离</span><br><span class="hljs-built_in">print</span>(<span class="hljs-string">&quot;最短距离为&#123;&#125;&quot;</span>.<span class="hljs-built_in">format</span>(d))<br>plt.figure(dpi=<span class="hljs-number">500</span>)<br>node_labels=<span class="hljs-built_in">dict</span>(<span class="hljs-built_in">zip</span>(<span class="hljs-built_in">range</span>(<span class="hljs-number">5</span>),[<span class="hljs-string">&quot;V&quot;</span>+<span class="hljs-built_in">str</span>(i) <span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(<span class="hljs-number">1</span>,<span class="hljs-number">6</span>)])) <span class="hljs-comment">#构造用于顶点标记的字典</span><br>pos = nx.shell_layout(G)<span class="hljs-comment">#设置布局</span><br>w = nx.get_edge_attributes(G,<span class="hljs-string">&quot;weight&quot;</span>) <span class="hljs-comment">#获取边的权重</span><br>nx.draw_networkx(G,pos,node_size=<span class="hljs-number">270</span>,labels=node_labels) <span class="hljs-comment">#绘制图</span><br>nx.draw_networkx_edge_labels(G,pos,font_size=<span class="hljs-number">10</span>,edge_labels=w)<span class="hljs-comment">#标记权重</span><br>path_edges=<span class="hljs-built_in">list</span>(<span class="hljs-built_in">zip</span>(p,p[<span class="hljs-number">1</span>:]))<span class="hljs-comment">#标记路径的元组组成的列表</span><br>nx.draw_networkx_edges(G,pos,edgelist=path_edges,edge_color=<span class="hljs-string">&quot;r&quot;</span>,width=<span class="hljs-number">3</span>)<span class="hljs-comment">#标记路径</span><br>plt.savefig(<span class="hljs-string">&quot;figure2.png&quot;</span>)<br>plt.show()<br></code></pre></td></tr></table></figure><h3 id="重心问题">重心问题</h3><p>有些公共服务设施（例如邮局，学校等）的选址，要求设施到所有服务对象点的距离总和最小。一般要考虑人口密度问题，或者全体被服务对象来往的总路程最短。</p><p>某矿区有六个矿点，如下图所示，已知各产矿点每天的产煤量为<span class="math inline">\(q_i(i=1,2,3,4,5,6)t,\)</span>,现在要从这六个矿点选一个作为矿场。问在那个产矿点，才能使各矿点所产的矿石运到选矿厂所在地的总运力<span class="math inline">\((t\cdot km)\)</span>最小。</p><p><img src="https://drive.imgod.me/api/v3/file/get/61808/figure3.png?sign=4h_GOqbwtj4VVuzNQR-NVKtZ2LoCeR7rOVKRgHyJZds%3D%3A0" style="zoom:50%;"></p><p>解：令<span class="math inline">\(d_{ij}(i,j=1,2,\cdots,6)\)</span>表示顶点<span class="math inline">\(v_i\)</span>和顶点<span class="math inline">\(v_j\)</span>之间的距离。若选矿厂设在<span class="math inline">\(m_i\)</span>，并且各产矿点到选矿厂的总运力为<span class="math inline">\(m_i\)</span>,则确定选矿厂的位置就转化为求<span class="math inline">\(m_k\)</span>，使得 <span class="math display">\[m_k = \min_{1\le i \le6} m_i\]</span>由于各产矿点到选矿厂的总运力依赖于任意两顶点之间的距离，即任意两顶点之间的最短距离，先用Floyd计算出所有顶点对之间的最短距离，然后计算出顶点<span class="math inline">\(v_i\)</span>作为设立选矿厂时各自到<span class="math inline">\(v_i\)</span>的总运力 <span class="math display">\[m_i = \sum_{j=1}^{6}q_jd_{ij},\quad i = 1,2,\cdots,6\]</span></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br></pre></td><td class="code"><pre><code class="hljs python">W = np.array([[<span class="hljs-number">0</span>,<span class="hljs-number">20</span>,<span class="hljs-number">0</span>,<span class="hljs-number">0</span>,<span class="hljs-number">15</span>,<span class="hljs-number">0</span>]<br>            ,[<span class="hljs-number">20</span>,<span class="hljs-number">0</span>,<span class="hljs-number">20</span>,<span class="hljs-number">40</span>,<span class="hljs-number">25</span>,<span class="hljs-number">0</span>]<br>            ,[<span class="hljs-number">0</span>,<span class="hljs-number">20</span>,<span class="hljs-number">0</span>,<span class="hljs-number">30</span>,<span class="hljs-number">10</span>,<span class="hljs-number">0</span>]<br>            ,[<span class="hljs-number">0</span>,<span class="hljs-number">40</span>,<span class="hljs-number">30</span>,<span class="hljs-number">0</span>,<span class="hljs-number">0</span>,<span class="hljs-number">0</span>]<br>            ,[<span class="hljs-number">15</span>,<span class="hljs-number">25</span>,<span class="hljs-number">10</span>,<span class="hljs-number">0</span>,<span class="hljs-number">0</span>,<span class="hljs-number">15</span>]<br>            ,[<span class="hljs-number">0</span>,<span class="hljs-number">0</span>,<span class="hljs-number">0</span>,<span class="hljs-number">0</span>,<span class="hljs-number">15</span>,<span class="hljs-number">0</span>]])<br><span class="hljs-comment">#绘制无向加权图</span><br><span class="hljs-keyword">import</span> numpy <span class="hljs-keyword">as</span> np<br><span class="hljs-keyword">import</span> networkx <span class="hljs-keyword">as</span> nx<br><span class="hljs-keyword">import</span> seaborn <span class="hljs-keyword">as</span> sns<br><span class="hljs-keyword">import</span> matplotlib.pyplot <span class="hljs-keyword">as</span> plt<br><span class="hljs-keyword">import</span> pandas <span class="hljs-keyword">as</span> pd<br>sns.set_theme(style=<span class="hljs-string">&quot;dark&quot;</span>)<span class="hljs-comment">#用来设置主题背景</span><br>plt.rcParams[<span class="hljs-string">&quot;font.sans-serif&quot;</span>] = [<span class="hljs-string">&quot;SimHei&quot;</span>] <span class="hljs-comment">#用来正常显示中文标签</span><br>plt.rcParams[<span class="hljs-string">&quot;axes.unicode_minus&quot;</span>] = <span class="hljs-literal">False</span> <span class="hljs-comment">#用来正常显示负号</span><br>G = nx.Graph(W)<span class="hljs-comment">#创建无向图类</span><br>plt.figure(dpi=<span class="hljs-number">500</span>)<br>node_labels=<span class="hljs-built_in">dict</span>(<span class="hljs-built_in">zip</span>(<span class="hljs-built_in">range</span>(<span class="hljs-number">6</span>),[<span class="hljs-string">&quot;v1(80)&quot;</span>,<span class="hljs-string">&quot;v2(90)&quot;</span>,<span class="hljs-string">&quot;v3(30)&quot;</span>,<span class="hljs-string">&quot;v4(20)&quot;</span>,<span class="hljs-string">&quot;v5(60)&quot;</span>,<span class="hljs-string">&quot;v6(10)&quot;</span>])) <span class="hljs-comment">#构造用于顶点标记的字典</span><br>pos = nx.shell_layout(G)<span class="hljs-comment">#设置布局</span><br>w = nx.get_edge_attributes(G,<span class="hljs-string">&quot;weight&quot;</span>) <span class="hljs-comment">#获取边的权重</span><br>nx.draw_networkx(G,pos,node_size=<span class="hljs-number">270</span>,labels=node_labels,font_size=<span class="hljs-number">5</span>) <span class="hljs-comment">#绘制图</span><br>nx.draw_networkx_edge_labels(G,pos,font_size=<span class="hljs-number">10</span>,edge_labels=w)<span class="hljs-comment">#标记权重</span><br>plt.savefig(<span class="hljs-string">&quot;figure3.png&quot;</span>)<br>plt.show()<br>d = nx.shortest_path_length(G,weight=<span class="hljs-string">&quot;weight&quot;</span>) <span class="hljs-comment">#计算各个点之间的最短路径</span><br>s = <span class="hljs-built_in">dict</span>(d) <span class="hljs-comment">#将其转化为字典</span><br>res = np.zeros((<span class="hljs-number">6</span>,<span class="hljs-number">6</span>))<br><span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(<span class="hljs-number">6</span>):<br>    <span class="hljs-keyword">for</span> j <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(<span class="hljs-number">6</span>):<br>        res[i][j] = s[i][j]<span class="hljs-comment">#构建最短路径矩阵</span><br>df = pd.DataFrame(res,columns=[<span class="hljs-number">1</span>,<span class="hljs-number">2</span>,<span class="hljs-number">3</span>,<span class="hljs-number">4</span>,<span class="hljs-number">5</span>,<span class="hljs-number">6</span>],index=[<span class="hljs-number">1</span>,<span class="hljs-number">2</span>,<span class="hljs-number">3</span>,<span class="hljs-number">4</span>,<span class="hljs-number">5</span>,<span class="hljs-number">6</span>])<br>df.head(<span class="hljs-number">10</span>)<br></code></pre></td></tr></table></figure><p>结果如下：</p><p><img src="https://drive.imgod.me/api/v3/file/get/61809/dsafasdfasdf.png?sign=_QGe0dW7S17pNT5pPBQKAehOaIoBxn-pkOQ5epMQYAg%3D%3A0"></p>]]></content>
    
    
    <categories>
      
      <category>数学建模</category>
      
      <category>图论</category>
      
    </categories>
    
    
    <tags>
      
      <tag>数学建模</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>图论基础及绘制(python)</title>
    <link href="/posts/18665.html"/>
    <url>/posts/18665.html</url>
    
    <content type="html"><![CDATA[<div class="note note-success">            <p>数学建模 图论 Python</p>          </div><h2 id="图的基础理论">图的基础理论</h2><h3 id="图的基本概念">图的基本概念</h3><p>定义1：图是一些点和这些点之间的连线组成的。定义为<span class="math inline">\(G=(V,E)\)</span>,<span class="math inline">\(V\)</span>是顶点(vertex)的非空有限集合，称为顶点集,<span class="math inline">\(E\)</span>是边(edge)的集合，称为边集。边一般用<span class="math inline">\((v_i,v_j)\)</span>表示，其中<span class="math inline">\(v_i,v_j\in V\)</span>,用<span class="math inline">\(\vert V \vert\)</span>表示图中顶点的个数，<span class="math inline">\(\vert E\vert\)</span>表示边的条数。</p><h3 id="有向图和无向图">有向图和无向图</h3><p>定义2：图的边有方向称为有向图，没有方向称为弧。有向图的弧的起点称为弧头，弧的终点称为弧尾。有向图一般记为<span class="math inline">\(D=(V,A)\)</span>,其中<span class="math inline">\(V\)</span>为顶点集,<span class="math inline">\(A\)</span>为弧集。</p><h3 id="简单图和完全图">简单图和完全图</h3><p>定义3：设<span class="math inline">\(e=(u,v)\)</span>是图<span class="math inline">\(G\)</span>的一条边,则称<span class="math inline">\(u,v\)</span>是<span class="math inline">\(e\)</span>的端点，并称<span class="math inline">\(u,v\)</span>相邻，边<span class="math inline">\(e\)</span>与顶点<span class="math inline">\(u或(v)\)</span>相关联。若两条边<span class="math inline">\(e_i,e_j\)</span>有共同的端点，则称<span class="math inline">\(e_i,e_j\)</span>相邻，称有相同端点的两条边为重边。称两端点相同的边为环。称不与任何边相关联的顶点为孤立点。</p><p>定义4：无环且无重边的图称为简单图</p><p>定义5：任意两顶点均相邻的简单图称为完全图，含有<span class="math inline">\(n\)</span>个顶点的完全图记为<span class="math inline">\(K_n\)</span></p><h3 id="赋权图">赋权图</h3><p>定义6：如果图<span class="math inline">\(G\)</span>的每一条边<span class="math inline">\(e\)</span>都附有一个实数<span class="math inline">\(w(e)\)</span>，则称图<span class="math inline">\(G\)</span>为赋权图,实数<span class="math inline">\(w(e)\)</span>称为边<span class="math inline">\(e\)</span>的权</p><h3 id="顶点的度">顶点的度</h3><p>定义7：（1）在无向图中与顶点<span class="math inline">\(v\)</span>相关联的边(环算两次)的数目称为<span class="math inline">\(v\)</span>的度,记作<span class="math inline">\(d(v)\)</span></p><p>​ （2）在有向图中，从顶点<span class="math inline">\(v\)</span>引出的弧的数目称为<span class="math inline">\(v\)</span>的出度，记作<span class="math inline">\(d^{+}(v)\)</span>,从顶点<span class="math inline">\(v\)</span>引入弧的数目称为弧的入度，记作<span class="math inline">\(d^{-}(v)\)</span>， <span class="math inline">\(d(v)=d^{+}(v)+d^{-}(v)\)</span>称为<span class="math inline">\(v\)</span>的度</p><pre><code class="hljs">                度为奇数的顶点称为奇顶点，度为偶数的顶点称为偶顶点。</code></pre><p>定理1：给定图<span class="math inline">\(G=(V,E)\)</span>,所有顶点的度数之和是边数的2倍，即<span class="math display">\[\sum_{v\in V}d(v) = 2\vert E\vert\]</span> 推论：任何图中奇顶点的数目总为偶数</p><h3 id="子图">子图</h3><p>定义8：设<span class="math inline">\(G_1=(V_1,E_1)\)</span>v与<span class="math inline">\(G_2=(V_2,E_2)\)</span>是两个图,并且满足<span class="math inline">\(V_1\subset V_2,E_1\subset E_2\)</span>，则称<span class="math inline">\(G_1\)</span>是<span class="math inline">\(G_2\)</span>的子图。如果<span class="math inline">\(G_1\)</span>是<span class="math inline">\(G_2\)</span>的子图，且<span class="math inline">\(V_1=V_2\)</span>，则称<span class="math inline">\(G_1\)</span>是<span class="math inline">\(G_2\)</span>的生成子图。</p><h3 id="道路与回路">道路与回路</h3><p>设<span class="math inline">\(W=v_0e_1v_1e_2\cdotse_kv_k,\,where\quad e_i\in E,v_j\in V\)</span>，<span class="math inline">\(e_i\)</span>与<span class="math inline">\(v_{i-1}\)</span>和<span class="math inline">\(v_i\)</span>相关联，称<span class="math inline">\(W\)</span>是图<span class="math inline">\(G\)</span>的一条道路，简称路，<span class="math inline">\(k\)</span>为路长，<span class="math inline">\(v_0\)</span>为起点,<span class="math inline">\(v_k\)</span>为终点；各边相异的道路称为迹(trail);各顶点相异的道路称为轨道(path),记为<span class="math inline">\(P(v_0,v_k)\)</span>；起点和终点相同的道路称为回路；起点和终点重合的轨道称为圈。称以两顶点<span class="math inline">\(u,v\)</span>分别为起点和终点的最短轨道之长为顶点<span class="math inline">\(u,v\)</span>的距离。</p><h3 id="连通图和非连通图">连通图和非连通图</h3><p>在无向图<span class="math inline">\(G\)</span>中，如果从顶点<span class="math inline">\(u\)</span>到顶点<span class="math inline">\(v\)</span>存在道路，则称顶点<span class="math inline">\(u\)</span>和顶点<span class="math inline">\(v\)</span>是连通的。如果图<span class="math inline">\(G\)</span>中任意两个顶点都是连通的，则称图<span class="math inline">\(G\)</span>是联通图，否则称为非连通图。</p><h2 id="图的表示">图的表示</h2><p>以下均假设图<span class="math inline">\(G=(V,E)\)</span>为简单图，其中<span class="math inline">\(V=\{v_1,v_2,\cdots,v_n\},E=\{e_1,e_2,\cdots,e_m\}\)</span></p><ul><li>关联矩阵</li></ul><p>对于无向图<span class="math inline">\(G\)</span>，其关联矩阵<span class="math inline">\(M=(M_{ij})_{n\times m}\)</span>,其中 <span class="math display">\[m_{ij} = \begin{cases}1,\quad &amp;v_i\text{与}e_j\text{相关联}\\                    0，\quad &amp;v_i\text{与}e_j\text{不关联}          \end{cases}\]</span> 对有向图<span class="math inline">\(G\)</span>,其关联矩阵<span class="math inline">\(M=(M_{ij})_{n\times m}\)</span>，其中 <span class="math display">\[m_{ij} = \begin{cases}1,\quad &amp;v_i\text{是}e_j\text{起点}\\                    -1，\quad &amp;v_i\text{是}e_j\text{终点}\\                    0,\quad &amp;v_i\text{与}e_j\text{不关联}          \end{cases}\]</span></p><ul><li>邻接矩阵</li></ul><p>对于无向非赋权图<span class="math inline">\(G\)</span>，其邻接矩阵<span class="math inline">\(W=(w_{ij})_{n\times n}\)</span>其中 <span class="math display">\[w_{ij} = \begin{cases}1,\quad &amp;v_i\text{与}v_j\text{相邻}\\                    0，\quad &amp;v_i\text{与}v_j\text{不相邻}          \end{cases}\]</span> 对于有向非赋权图<span class="math inline">\(G\)</span>,其邻接矩阵<span class="math inline">\(W=(w_{ij})_{n\times n}\)</span>其中 <span class="math display">\[w_{ij} = \begin{cases}1,\quad &amp;(v_i,v_j)\in A\\                    0，\quad &amp;(v_i,v_j)\notin A          \end{cases}\]</span> 对于无向赋权图，其邻接矩阵<span class="math inline">\(W=(w_{ij})_{n\times n}\)</span>其中 <span class="math display">\[w_{ij} =\begin{cases}\text{顶点}v_i\text{顶点}v_j\text{之间边的权},\quad&amp;(v_i,v_j)\in E\\                    0(\text{或}\infty)，\quad&amp;v_i,v_j\text{之间无边}          \end{cases}\]</span></p><h2 id="绘制图">绘制图</h2><h3 id="绘制无向加权图">绘制无向加权图</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-comment">#绘制无向加权图</span><br><span class="hljs-keyword">import</span> numpy <span class="hljs-keyword">as</span> np<br><span class="hljs-keyword">import</span> networkx <span class="hljs-keyword">as</span> nx<br><span class="hljs-keyword">import</span> seaborn <span class="hljs-keyword">as</span> sns<br>sns.set_theme(style=<span class="hljs-string">&quot;dark&quot;</span>)<span class="hljs-comment">#用来设置主题背景</span><br>plt.rcParams[<span class="hljs-string">&quot;font.sans-serif&quot;</span>] = [<span class="hljs-string">&quot;SimHei&quot;</span>] <span class="hljs-comment">#用来正常显示中文标签</span><br>plt.rcParams[<span class="hljs-string">&quot;axes.unicode_minus&quot;</span>] = <span class="hljs-literal">False</span> <span class="hljs-comment">#用来正常显示负号</span><br>A = np.array([[<span class="hljs-number">0</span>,<span class="hljs-number">9</span>,<span class="hljs-number">2</span>,<span class="hljs-number">4</span>,<span class="hljs-number">7</span>]<br>             ,[<span class="hljs-number">9</span>,<span class="hljs-number">0</span>,<span class="hljs-number">3</span>,<span class="hljs-number">4</span>,<span class="hljs-number">0</span>]<br>             ,[<span class="hljs-number">2</span>,<span class="hljs-number">3</span>,<span class="hljs-number">0</span>,<span class="hljs-number">8</span>,<span class="hljs-number">4</span>]<br>             ,[<span class="hljs-number">4</span>,<span class="hljs-number">4</span>,<span class="hljs-number">8</span>,<span class="hljs-number">0</span>,<span class="hljs-number">6</span>]<br>             ,[<span class="hljs-number">7</span>,<span class="hljs-number">0</span>,<span class="hljs-number">4</span>,<span class="hljs-number">6</span>,<span class="hljs-number">0</span>]]) <span class="hljs-comment">#输入邻接矩阵</span><br>i,j = np.nonzero(A) <span class="hljs-comment">#提取顶点编号</span><br>w = A[i,j] <span class="hljs-comment">#提取A非零元素</span><br>edges = <span class="hljs-built_in">list</span>(<span class="hljs-built_in">zip</span>(i,j,w)) <span class="hljs-comment">#构建边list</span><br>G = nx.Graph()<span class="hljs-comment">#创建无向图类</span><br>G.add_weighted_edges_from(edges) <span class="hljs-comment">#添加带权边</span><br>node_labels = <span class="hljs-built_in">dict</span>(<span class="hljs-built_in">zip</span>(<span class="hljs-built_in">range</span>(<span class="hljs-number">5</span>),[<span class="hljs-built_in">str</span>(i+<span class="hljs-number">1</span>) <span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(<span class="hljs-number">5</span>)]))<span class="hljs-comment">#顶点标签</span><br>pos = nx.shell_layout(G) <span class="hljs-comment">#图形布局</span><br>nx.draw_networkx(G,pos,node_size=<span class="hljs-number">260</span>,labels=node_labels) <span class="hljs-comment">#绘制图</span><br>w = nx.get_edge_attributes(G,<span class="hljs-string">&quot;weight&quot;</span>)<span class="hljs-comment">#获取边的权重字典</span><br>nx.draw_networkx_edge_labels(G,pos,font_size=<span class="hljs-number">12</span>,edge_labels=w)<span class="hljs-comment">#标记权重</span><br>plt.show()<br></code></pre></td></tr></table></figure><p><img src="https://s2.loli.net/2022/06/26/IOyV2s3AqZ6pXrW.png"></p>]]></content>
    
    
    <categories>
      
      <category>数学建模</category>
      
      <category>图论</category>
      
    </categories>
    
    
  </entry>
  
  
  
  <entry>
    <title>逻辑回归</title>
    <link href="/posts/60504.html"/>
    <url>/posts/60504.html</url>
    
    <content type="html"><![CDATA[<div class="note note-success">            <p>机器学习 逻辑回归</p>          </div><h2 id="广义线性模型generalized-linear-model">广义线性模型（Generalizedlinear model）</h2><p>设<span class="math inline">\(y=\hat{w}^{T}\cdot\hat{x},where\,\hat{w}=(w_1,w_2,\dots,w_n,b)^{T}\,\hat{x}=(x_1,x_2,\dots,x_n,1)^{T}\)</span>,令<span class="math inline">\(g(y)=\hat{w}^{T}\cdot\hat{x}\)</span>，其中<span class="math inline">\(y=g(x)\)</span>为连续可微函数。则该模型为广义线性模型，该模型的提出是为了解决线性模型由于简单而带有的局限性。若令<span class="math inline">\(y=g(x)=ln(x)\)</span>，则该模型可表示为<span class="math inline">\(ln(y)=\hat{w}^{T}\cdot\hat{x} \iffy=\exp(\hat{w}^{T}\cdot\hat{x})\)</span>，该模型被称为对数线性模型(logistlinear model).</p><h2 id="对数几率模型与逻辑回归">对数几率模型与逻辑回归</h2><ul><li>几率(odd)</li></ul><p>几率不是概率，而是一个事件发生与不发生的概率的比值。假设某事件A发生的概率为p，则该事件不发生的概率为1-p，该事件的几率为：<span class="math inline">\(odd(A)=\frac{p}{1-p}\)</span>.在几率的基础上取（自然底数的）对数，则构成该事件的对数几率（logit）：<span class="math inline">\(logit(A)=\ln\frac{p}{1-p}\)</span></p><ul><li>对数几率模型</li></ul><p>如果我们将对数几率看成是一个函数，并将其作为联系函数，即<span class="math inline">\(g(y)=\ln\frac{y}{1-y}\)</span>.则该广义线性模型为：<span class="math display">\[\ln\frac{y}{1-y}=\hat{w}^{T}\cdot\hat{x} \iffy=\frac{1}{1+\exp(-\hat{w}^{T}\cdot\hat{x})}\quad where\quady=\frac{1}{1+exp(-z)}被称为Sigmoid函数\]</span></p><ul><li>Sigmoid函数及其导数</li></ul><p><span class="math inline">\(Sigmoid(x)=\frac{1}{1+\exp(-x)},Sigmoid^{\prime}(x)=(1-Sigmoid(x))Sigmoid(x)\)</span>，其图像如下：</p><p><img src="https://s2.loli.net/2022/06/26/NOwe82Qgz5tlvPj.png"></p><h2 id="逻辑回归模型输出结果与模型可解释性">逻辑回归模型输出结果与模型可解释性</h2><ul><li>连续型输出结果转化为分类预测结果</li></ul><p>对于逻辑回归输出的(0,1)之间的连续型数值，我们只需要确定一个“阈值”，就可以将其转化为二分类的类别判别结果。通常来说，这个阈值是0.5，即以0.5为界，调整模型输出结果：</p><p><span class="math display">\[\begin{equation}y_{cla}=\left\{\begin{aligned}0, y&lt;0.5 \\1, y≥0.5\end{aligned}\right.\end{equation}\]</span></p><p>而有时候逻辑回归当<span class="math inline">\(f1\_score\)</span>等作为分类评价指标可以将阈值进行调整。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-comment">#借助sklearn中的Logisticregression来构建带有阈值移动的评估器</span><br><span class="hljs-keyword">from</span> sklearn.linear_model <span class="hljs-keyword">import</span> LogisticRegression<br><span class="hljs-keyword">from</span> sklearn.base <span class="hljs-keyword">import</span> BaseEstimator,TransformerMixin<br><span class="hljs-keyword">class</span> <span class="hljs-title class_">logistic_threshold</span>(BaseEstimator,TransformerMixin):<br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">__init__</span>(<span class="hljs-params">self,penalty=<span class="hljs-string">&quot;l2&quot;</span>,C=<span class="hljs-number">1.0</span>,solver=<span class="hljs-string">&quot;lbfgs&quot;</span>,max_iter=<span class="hljs-built_in">int</span>(<span class="hljs-params"><span class="hljs-number">1e8</span></span>),l1_ratio=<span class="hljs-literal">None</span>,class_weight=<span class="hljs-literal">None</span>,thr=<span class="hljs-number">0.5</span></span>):<br>        self.penalty = penalty<br>        self.C = C<br>        self.solver = solver<br>        self.max_iter = max_iter<br>        self.l1_ratio = l1_ratio<br>        self.class_weight = class_weight<br>        self.thr = thr<br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">fit</span>(<span class="hljs-params">self,X,y</span>):<br>        clf =      LogisticRegression(slef.penalty,self.C,self.solver,self.max_iter,self.l1_ratio,self.class_weight).fit(X,y)<br>        self.coef_ = clf.coef_<br>        self.clf = clf<br>        <span class="hljs-keyword">return</span> self<br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">predict</span>(<span class="hljs-params">self,X</span>):<br>        res = (self.clf.predict_proba(X)[:,<span class="hljs-number">1</span>]&gt;self.thr)*<span class="hljs-number">1</span><br>        <span class="hljs-keyword">return</span> res<br></code></pre></td></tr></table></figure><ul><li>逻辑回归输出结果(y)是否是概率</li></ul><p>决定y是否是概率的核心因素，不是模型本身，而是建模流程。  逻辑斯蒂本身也有对应的概率分布，因此输入的自变量其实是可以视作随机变量的，但前提是需要满足一定的分布要求。如果逻辑回归的建模流程遵照数理统计方法的一般建模流程，即自变量的分布（或者转化之后的分布）满足一定要求（通过检验），则最终模型输出结果就是严格意义上的概率取值。而如果是遵照机器学习建模流程进行建模，在为对自变量进行假设检验下进行模型构建，则由于自变量分布不一定满足条件，因此输出结果不一定为严格意义上的概率。</p><p>而我们基本都采用机器学习建模流程进行逻辑回归的构建，因此对于模型输出结果y，其实并不一定是严格意义上的概率。不过在目前大多数使用场景中，由于大家希望能够用到模型本身的可解释性，因此还是会将模型结果解读为1发生的概率。尽管这并不是一个严谨的做法，但在机器学习整体的“实证”倾向下，只要业务方接受这种做法、并且能够一定程度指导业务，我们就可以将其解读为概率。我们将逻辑回归输出结果看成近似概率值。</p><h2 id="sklearn中的逻辑回归">sklearn中的逻辑回归</h2><ul><li>正则化(Regularization)</li></ul><p><img src="https://s2.loli.net/2022/06/26/oq5lQmuFOhEkDZP.png"></p><p>上述为sklearn官方解释可以看出sklearn中是默认进行正则化，每个式子的前面部分为结构风险项（正则化项）,后面部分为损失函数经验风险项。当我们不想进行正则化的时候可以控制C很大。</p><table><thead><tr class="header"><th>参数</th><th>解释</th></tr></thead><tbody><tr class="odd"><td>penalty</td><td>正则化项</td></tr><tr class="even"><td>dual</td><td>是否求解对偶问题*</td></tr><tr class="odd"><td>tol</td><td>迭代停止条件：两轮迭代损失值差值小于tol时，停止迭代</td></tr><tr class="even"><td>C</td><td>经验风险和结构风险在损失函数中的权重</td></tr><tr class="odd"><td>fit_intercept</td><td>线性方程中是否包含截距项</td></tr><tr class="even"><td>intercept_scaling</td><td>相当于此前讨论的特征最后一列全为1的列，当使用liblinear求解参数时用于捕获截距</td></tr><tr class="odd"><td>class_weight</td><td>各类样本权重*</td></tr><tr class="even"><td>random_state</td><td>随机数种子</td></tr><tr class="odd"><td>solver</td><td>损失函数求解方法*</td></tr><tr class="even"><td>max_iter</td><td>求解参数时最大迭代次数，迭代过程满足max_iter或tol其一即停止迭代</td></tr><tr class="odd"><td>multi_class</td><td>多分类问题时求解方法*</td></tr><tr class="even"><td>verbose</td><td>是否输出任务进程</td></tr><tr class="odd"><td>warm_start</td><td>是否使用上次训练结果作为本次运行初始参数</td></tr><tr class="even"><td>l1_ratio</td><td>当采用弹性网正则化时，<span class="math inline">\(l1\)</span>正则项权重，就是损失函数中的<span class="math inline">\(\rho\)</span></td></tr></tbody></table><ul><li>dual：是否求解对偶问题</li></ul><p>  对偶问题是约束条件相反、求解方向也相反的问题，当数据集过小而特征较多时，求解对偶问题能一定程度降低运算复杂度，其他情况建议保留默认参数取值。</p><ul><li>class_weight:各类样本权重</li></ul><p>  class_weight其实代表各类样本在进行损失函数计算时的数值权重，例如假设一个二分类问题，0、1两类的样本比例是2:1，此时可以输入一个字典类型对象用于说明两类样本在进行损失值计算时的权重，例如输入:{0:1,1:3}，则代表1类样本的每一条数据在进行损失函数值的计算时都会在原始数值上*3。而当我们将该参数选为<code>balanced</code>时，则会自动将这个比例调整为真实样本比例的反比，以达到平衡的效果。</p><ul><li>solver：损失函数求解方法</li></ul><p>  其实除了最小二乘法和梯度下降以外，还有非常多的关于损失函数的求解方法，而选择损失函数的参数，就是solver参数。</p><p>  而当前损失函数到底采用何种优化方法进行求解，其实最终目的是希望能够更快（计算效率更高）更好（准确性更高）的来进行求解，而硬性的约束条件是损失函数的形态，此外则是用户自行选择的空间。下面为官方给出的solver列表</p><p><img src="https://s2.loli.net/2022/06/26/gAFjBUWPho7C8nG.png"></p><ul><li>multi_class：选用何种方法进行多分类问题求解</li></ul><p>可选OVR和MVM，当然默认情况是auto，此时模型会优先根据惩罚项和solver选择OVR还是MVM，但一般来说，MVM效果会好于OVR。</p><h2 id="利用极大似然估计进行参数估计">利用极大似然估计进行参数估计</h2><p>逻辑回归模型如下： <span class="math display">\[y = \frac{1}{1+\exp(-\hat{w}^{T}\cdot\hat{x})}\quad\hat{w}^{T}=(w_1,w_2,\dots,w_n,b)^{T}\,,\hat{x}=(x_1,x_2,\dots,x_n,1)^{T}\\\]</span> 固定一组<span class="math inline">\(\hat{w}^{T}\)</span>和<span class="math inline">\(\hat{x}\)</span>得:</p><p><span class="math display">\[p(y=1\vert\hat{w}^{T},\hat{x}) =\frac{1}{1+\exp(-\hat{w}^{T}\cdot\hat{x})} \quadp(y=1\vert\hat{w}^{T},\hat{x}) =\frac{1}{1+\exp(-\hat{w}^{T}\cdot\hat{x})}\\\]</span></p><p>令<span class="math inline">\(p_1(\hat{w}^{T},\hat{x})=p(y=1\vert\hat{w}^{T},\hat{x}),p_0(\hat{w}^{T},\hat{x})=p(y=0\vert\hat{w}^{T},\hat{x})\)</span></p><p>得：<span class="math inline">\(p(y=y_i)=p_1^{y_i}(\hat{w}^{T},\hat{x})\cdotp_0^{1-y_i}(\hat{w}^{T},\hat{x})\)</span></p><p>则似然函数为<span class="math inline">\(L(y_i;\hat{w}^{T},\hat{x})=\prod_{i=1}^{n}p(y=y_i)=\prod_{i=1}^{n}p_1^{y_i}(\hat{w}^{T},\hat{x})\cdotp_0^{1-y_i}(\hat{w}^{T},\hat{x})\)</span></p><p>进而<span class="math inline">\(\ln L=\sum_{i=1}^{n}(\lnp_1^{y_i}(\hat{w}^{T},\hat{x})+\lnp_0^{1-y_i}(\hat{w}^{T},\hat{x}))=\sum_{i=1}^{n}(y_i\lnp_1(\hat{w}^{T},\hat{x})+(1-y_i)\lnp_0(\hat{w}^{T},\hat{x}))\)</span></p><p>通过一系列数学过程可以证明，通过极大似然估计构建的损失函数是凸函数，此时我们可以采用导数为0联立方程组的方式进行求解，这也是极大似然估计对参数求解的一般方法。但这种方法会涉及大量的导数运算、方程组求解等，并不适用于大规模甚至是超大规模数值运算，因此，在机器学习领域，我们通常会采用一些更加通用的优化方法对逻辑回归的损失函数进行求解，通常来说是牛顿法或者梯度下降算法，其中，梯度下降算法是机器学习中最为通用的求解损失函数的优化算法.</p><p>为了方便求最小值将其转化为: <span class="math display">\[\ln L=-\sum_{i=1}^{n}(y_i\ln p_1(\hat{w}^{T},\hat{x})+(1-y_i)\lnp_0(\hat{w}^{T},\hat{x}))\]</span></p><h2 id="熵相对熵与交叉熵">熵、相对熵与交叉熵</h2><p>###熵</p><p>通常我们用熵（entropy）来表示随机变量不确定性的度量，或者说系统混乱程度、信息混乱程度。熵的计算公式如下：<span class="math display">\[entrop(X) = -\sum_{i=1}^{n}p(x_i)log(x_i)\]</span>可以证明，熵的计算结果在[0,1]之间，并且熵值越大，系统越混乱、信息越混乱。</p><h3 id="相对熵和交叉熵">相对熵和交叉熵</h3><p>相对熵也被称为Kullback-Leibler散度（KL散度）或者信息散度（informationdivergence）。通常用来衡量两个随机变量分布的差异性。假设对同一个随机变量X，有两个单独的概率分布P(x)和Q(x)，当X是离散变量时，我们可以通过如下相对熵计算公式来衡量二者差异：<span class="math display">\[D_{KL}(P\vert\vert Q) = \sum_{i=1}^{n}P(x_i)log(\frac{P(x_i)}{Q(x_i)})\]</span> 和信息熵类似，相对熵越小，代表Q(x)和P(x)越接近。</p><p>从交叉熵的计算公式不难看出，这其实是一种非对称性度量，也就是<span class="math inline">\(D_{KL}(P\vert\vert Q)\ne D_{KL}(Q\vert\vertP)\)</span>。从本质上来说，相对熵刻画的是用概率分布Q来刻画概率分布P的困难程度，而在机器学习领域，我们一般令Q为模型输出结果，而P为数据集标签真实结果，以此来判断模型输出结果是否足够接近真实情况。</p><ul><li>Q为拟合分布P为真实分布，也被称为前向KL散度（forward KLdivergence）。</li></ul><p><span class="math display">\[\begin{split}D_{KL}(P\vert\vert Q) &amp;=\sum_{i=1}^{n}P(x_i)log(\frac{P(x_i)}{Q(x_i)})\\&amp;=\sum_{i=1}^{n}P(x_i)log(P(x_i))-\sum_{i=1}^{n}P(x_i)log(Q(x_i))\\&amp;=-entropy(P(X))+cross\_entropy(P,Q)\end{split}\]</span></p><p>对于给定数据集，其信息熵是确定的。因此，如果我们希望P、Q二者分布尽可能接近，我们就需要尽可能减少相对熵，但由于相对熵=交叉熵-信息熵，因此我们只能力求减少交叉熵。当然，也正因如此，交叉熵可以作为衡量模型输出分布是否接近真实分布的重要度量方法。</p><p>简单总结上述过程要点：</p><ul><li>我们用相对熵<span class="math inline">\(𝐷_{𝐾𝐿}(𝑃||𝑄)\,D_{KL}(P||Q)\)</span>来表示模型拟合分布Q和数据真实分布P之间的差距，相对熵越小拟合效果越好；</li><li>根据计算公式(6),相对熵=交叉熵-信息熵；</li><li>对于给定数据集，信息熵是确定的，因此我们只能通过尽可能减小交叉熵来降低相对熵；</li></ul><p>根据吉布斯不等式，相对熵的取值恒大于等于零，当预测分布和真实分布完全一致时相对熵取值为0，此时交叉熵等于数据信息熵，此外只要二者分布不一致，交叉熵的取值都将大于信息熵。</p><h3 id="二分类交叉熵损失函数">二分类交叉熵损失函数</h3><p><span class="math display">\[binaryCE(\hat{w}) =-\sum_{i=1}^{n}(y_ilog(p_1(\hat{w}^{T},\hat{x}))+(1-y_i)log(p_0(\hat{w}^{T},\hat{x})))\]</span></p><h2 id="逻辑回归应用">逻辑回归应用</h2><p>该数据集为Telco Customer Churn 电信用户流失预测案例</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">import</span> pandas <span class="hljs-keyword">as</span> pd<br><span class="hljs-keyword">import</span> numpy <span class="hljs-keyword">as</span> np<br><span class="hljs-keyword">import</span> matplotlib.pyplot <span class="hljs-keyword">as</span> plt<br><span class="hljs-keyword">import</span> seaborn <span class="hljs-keyword">as</span> sns<br>sns.set_theme(style=<span class="hljs-string">&quot;darkgrid&quot;</span>)<span class="hljs-comment">#用来设置主题背景</span><br>plt.rcParams[<span class="hljs-string">&quot;font.sans-serif&quot;</span>] = [<span class="hljs-string">&quot;SimHei&quot;</span>] <span class="hljs-comment">#用来正常显示中文标签</span><br>plt.rcParams[<span class="hljs-string">&quot;axes.unicode_minus&quot;</span>] = <span class="hljs-literal">False</span> <span class="hljs-comment">#用来正常显示负号</span><br><span class="hljs-comment"># Read data</span><br>tcc = pd.read_csv(<span class="hljs-string">&#x27;WA_Fn-UseC_-Telco-Customer-Churn.csv&#x27;</span>)<br><span class="hljs-comment"># 标注连续/离散字段</span><br><span class="hljs-comment"># 离散字段</span><br>category_cols = [<span class="hljs-string">&#x27;gender&#x27;</span>, <span class="hljs-string">&#x27;SeniorCitizen&#x27;</span>, <span class="hljs-string">&#x27;Partner&#x27;</span>, <span class="hljs-string">&#x27;Dependents&#x27;</span>,<br>               <span class="hljs-string">&#x27;PhoneService&#x27;</span>, <span class="hljs-string">&#x27;MultipleLines&#x27;</span>, <span class="hljs-string">&#x27;InternetService&#x27;</span>, <span class="hljs-string">&#x27;OnlineSecurity&#x27;</span>, <span class="hljs-string">&#x27;OnlineBackup&#x27;</span>, <br>                <span class="hljs-string">&#x27;DeviceProtection&#x27;</span>, <span class="hljs-string">&#x27;TechSupport&#x27;</span>, <span class="hljs-string">&#x27;StreamingTV&#x27;</span>, <span class="hljs-string">&#x27;StreamingMovies&#x27;</span>, <span class="hljs-string">&#x27;Contract&#x27;</span>, <span class="hljs-string">&#x27;PaperlessBilling&#x27;</span>,<br>                <span class="hljs-string">&#x27;PaymentMethod&#x27;</span>]<br><br><span class="hljs-comment"># 连续字段</span><br>numeric_cols = [<span class="hljs-string">&#x27;tenure&#x27;</span>, <span class="hljs-string">&#x27;MonthlyCharges&#x27;</span>, <span class="hljs-string">&#x27;TotalCharges&#x27;</span>]<br><br><span class="hljs-comment"># 标签</span><br>target = <span class="hljs-string">&#x27;Churn&#x27;</span><br><br><span class="hljs-comment"># ID列</span><br>ID_col = <span class="hljs-string">&#x27;customerID&#x27;</span><br><br><span class="hljs-comment"># 验证是否划分能完全</span><br><span class="hljs-keyword">assert</span> <span class="hljs-built_in">len</span>(category_cols) + <span class="hljs-built_in">len</span>(numeric_cols) + <span class="hljs-number">2</span> == tcc.shape[<span class="hljs-number">1</span>]<br><span class="hljs-comment">#Verify whether the ID column is duplicate</span><br>tcc[ID_col].nunique() == tcc.shape[<span class="hljs-number">0</span>]<br><span class="hljs-comment">#Verify whether have the explict missing values</span><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">missing</span>(<span class="hljs-params">df</span>):<br>    <span class="hljs-string">&#x27;&#x27;&#x27;</span><br><span class="hljs-string">    Caculate the proportion of the missing value</span><br><span class="hljs-string">    </span><br><span class="hljs-string">    &#x27;&#x27;&#x27;</span><br>    missing_number = df.isnull().<span class="hljs-built_in">sum</span>().sort_values(ascending=<span class="hljs-literal">False</span>) <span class="hljs-comment">#decending</span><br>    missing_per = (df.isnull().<span class="hljs-built_in">sum</span>()/df.count()).sort_values(ascending=<span class="hljs-literal">False</span>) <span class="hljs-comment">#decending</span><br>    missing_df = pd.concat([missing_number,missing_per],axis=<span class="hljs-number">1</span>,keys=[<span class="hljs-string">&quot;Missing_number&quot;</span>,<span class="hljs-string">&quot;Missing_per&quot;</span>])<br>    <span class="hljs-keyword">return</span> missing_df<br><span class="hljs-comment">#Verify whether have the discrete explict missing values</span><br><span class="hljs-keyword">for</span> feature <span class="hljs-keyword">in</span> category_cols:<br>    <span class="hljs-built_in">print</span>(<span class="hljs-string">&quot;&#123;&#125;:&#123;&#125;&quot;</span>.<span class="hljs-built_in">format</span>(feature,tcc[feature].unique()))<br> <span class="hljs-comment">#Verify whether have the continuous explict missing values</span><br>tcc[numeric_cols].astype(<span class="hljs-built_in">float</span>)<br><span class="hljs-keyword">def</span> <span class="hljs-title function_">find_index</span>(<span class="hljs-params">data_col,value</span>):<br>    <span class="hljs-string">&quot;&quot;&quot;</span><br><span class="hljs-string">    Verify the first occurance of the given value in the given column,return -1 if there is none.</span><br><span class="hljs-string">    param data_col:given column</span><br><span class="hljs-string">    param value:given value</span><br><span class="hljs-string">    &quot;&quot;&quot;</span><br>    val_lst = [value]<br>    <span class="hljs-keyword">if</span> data_col.isin(val_lst).<span class="hljs-built_in">sum</span>() == <span class="hljs-number">0</span>:<br>        <span class="hljs-keyword">return</span> -<span class="hljs-number">1</span><br>    <span class="hljs-keyword">else</span>:<br>        res = data_col.isin(val_lst).idxmax()<br>    <span class="hljs-keyword">return</span> res<br><span class="hljs-keyword">for</span> feature <span class="hljs-keyword">in</span> numeric_cols:<br>    <span class="hljs-built_in">print</span>(find_index(tcc[feature],<span class="hljs-string">&quot; &quot;</span>))<br>tcc[<span class="hljs-string">&quot;TotalCharges&quot;</span>] = tcc[<span class="hljs-string">&quot;TotalCharges&quot;</span>].apply(<span class="hljs-keyword">lambda</span> x:x <span class="hljs-keyword">if</span> x!=<span class="hljs-string">&quot; &quot;</span><span class="hljs-keyword">else</span> np.nan).astype(<span class="hljs-built_in">float</span>)<br>tcc[<span class="hljs-string">&quot;MonthlyCharges&quot;</span>] = tcc[<span class="hljs-string">&quot;MonthlyCharges&quot;</span>].astype(<span class="hljs-built_in">float</span>)<br>tcc[<span class="hljs-string">&quot;TotalCharges&quot;</span>]=tcc[<span class="hljs-string">&quot;TotalCharges&quot;</span>].fillna(<span class="hljs-number">0</span>)<br><span class="hljs-comment">#Outlier detection</span><br>plt.figure(figsize=(<span class="hljs-number">16</span>, <span class="hljs-number">6</span>), dpi=<span class="hljs-number">200</span>)<br>plt.subplot(<span class="hljs-number">121</span>)<br>plt.boxplot(tcc[<span class="hljs-string">&#x27;MonthlyCharges&#x27;</span>])<br>plt.xlabel(<span class="hljs-string">&#x27;MonthlyCharges&#x27;</span>)<br>plt.subplot(<span class="hljs-number">122</span>)<br>plt.boxplot(tcc[<span class="hljs-string">&#x27;TotalCharges&#x27;</span>])<br>plt.xlabel(<span class="hljs-string">&#x27;TotalCharges&#x27;</span>)<br>tcc[target].replace(to_replace=<span class="hljs-string">&quot;Yes&quot;</span>,value=<span class="hljs-number">1</span>,inplace=<span class="hljs-literal">True</span>)<br>tcc[target].replace(to_replace=<span class="hljs-string">&quot;No&quot;</span>,value=<span class="hljs-number">0</span>,inplace=<span class="hljs-literal">True</span>)<br><span class="hljs-keyword">from</span> sklearn.model_selection <span class="hljs-keyword">import</span> train_test_split<br>train,test = train_test_split(tcc,random_state=<span class="hljs-number">666</span>,test_size=<span class="hljs-number">0.3</span>)<br>X_train = train.drop(columns=[ID_col,target]).copy()<br>y_train = train[target].copy()<br>X_test = test.drop(columns=[ID_col,target]).copy()<br>y_test = test[target].copy()<br><span class="hljs-keyword">from</span> sklearn.preprocessing <span class="hljs-keyword">import</span> OneHotEncoder,KBinsDiscretizer,StandardScaler<br><span class="hljs-keyword">from</span> sklearn.compose <span class="hljs-keyword">import</span> ColumnTransformer<br><span class="hljs-keyword">from</span> sklearn.pipeline <span class="hljs-keyword">import</span> make_pipeline<br><span class="hljs-keyword">from</span> sklearn.linear_model <span class="hljs-keyword">import</span> LogisticRegression<br><span class="hljs-keyword">from</span> sklearn.model_selection <span class="hljs-keyword">import</span> GridSearchCV<br>logistic_pre = ColumnTransformer([(<span class="hljs-string">&quot;cat&quot;</span>,OneHotEncoder(drop=<span class="hljs-string">&quot;if_binary&quot;</span>),category_cols),(<span class="hljs-string">&quot;num&quot;</span>,<span class="hljs-string">&quot;passthrough&quot;</span>,numeric_cols)])<br>logistic_model = LogisticRegression(max_iter=<span class="hljs-built_in">int</span>(<span class="hljs-number">1e8</span>))<br>logistic_pipe = make_pipeline(logistic_pre,logistic_model)<br>num_sel = [<span class="hljs-string">&quot;passthrough&quot;</span>,StandardScaler(),KBinsDiscretizer(n_bins=<span class="hljs-number">3</span>,encode=<span class="hljs-string">&quot;ordinal&quot;</span>,strategy=<span class="hljs-string">&quot;kmeans&quot;</span>)]<br>logistic_param = [&#123;<span class="hljs-string">&quot;columntransformer__num&quot;</span>:num_sel<br>                   ,<span class="hljs-string">&quot;logisticregression__penalty&quot;</span>:[<span class="hljs-string">&quot;l1&quot;</span>]<br>                   ,<span class="hljs-string">&quot;logisticregression__C&quot;</span>:np.arange(<span class="hljs-number">0.1</span>,<span class="hljs-number">2.1</span>,<span class="hljs-number">0.1</span>).tolist()<br>                   ,<span class="hljs-string">&quot;logisticregression__solver&quot;</span>:[<span class="hljs-string">&quot;saga&quot;</span>]&#125;<br>                 ,&#123;<span class="hljs-string">&quot;columntransformer__num&quot;</span>:num_sel<br>                   ,<span class="hljs-string">&quot;logisticregression__penalty&quot;</span>:[<span class="hljs-string">&quot;l2&quot;</span>]<br>                   ,<span class="hljs-string">&quot;logisticregression__C&quot;</span>:np.arange(<span class="hljs-number">0.1</span>,<span class="hljs-number">2.1</span>,<span class="hljs-number">0.1</span>).tolist()<br>                   ,<span class="hljs-string">&quot;logisticregression__solver&quot;</span>:[<span class="hljs-string">&#x27;lbfgs&#x27;</span>, <span class="hljs-string">&#x27;newton-cg&#x27;</span>, <span class="hljs-string">&#x27;sag&#x27;</span>, <span class="hljs-string">&#x27;saga&#x27;</span>]&#125;]<br>logistic_search = GridSearchCV(estimator=logistic_pipe,param_grid=logistic_param,n_jobs=-<span class="hljs-number">1</span>)<br><span class="hljs-keyword">import</span> time<br>s = time.time()<br>logistic_search.fit(X_train,y_train)<br><span class="hljs-built_in">print</span>(<span class="hljs-string">&quot;&#123;&#125;&quot;</span>.<span class="hljs-built_in">format</span>(time.time()-s))<br></code></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">class</span> <span class="hljs-title class_">logit_threshold</span>(BaseEstimator, TransformerMixin):<br>    <br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">__init__</span>(<span class="hljs-params">self, penalty=<span class="hljs-string">&#x27;l2&#x27;</span>, C=<span class="hljs-number">1.0</span>, max_iter=<span class="hljs-number">1e8</span>, solver=<span class="hljs-string">&#x27;lbfgs&#x27;</span>, l1_ratio=<span class="hljs-literal">None</span>, class_weight=<span class="hljs-literal">None</span>, thr=<span class="hljs-number">0.5</span></span>):<br>        self.penalty = penalty<br>        self.C = C<br>        self.max_iter = max_iter<br>        self.solver = solver<br>        self.l1_ratio = l1_ratio<br>        self.thr = thr<br>        self.class_weight = class_weight<br>        <br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">fit</span>(<span class="hljs-params">self, X, y</span>):<br>        clf = LogisticRegression(penalty = self.penalty, <br>                                 C = self.C, <br>                                 solver = self.solver, <br>                                 l1_ratio = self.l1_ratio,<br>                                 class_weight=self.class_weight, <br>                                 max_iter=self.max_iter)<br>        clf.fit(X, y)<br>        self.coef_ = clf.coef_<br>        self.clf = clf<br>        <span class="hljs-keyword">return</span> self<br>        <br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">predict</span>(<span class="hljs-params">self, X</span>):<br>        res = (self.clf.predict_proba(X)[:, <span class="hljs-number">1</span>]&gt;=self.thr) * <span class="hljs-number">1</span><br>        <span class="hljs-keyword">return</span> res<br> <span class="hljs-comment"># 设置转化器流</span><br>logistic_pre = ColumnTransformer([<br>    (<span class="hljs-string">&#x27;cat&#x27;</span>, preprocessing.OneHotEncoder(drop=<span class="hljs-string">&#x27;if_binary&#x27;</span>), category_cols), <br>    (<span class="hljs-string">&#x27;num&#x27;</span>, <span class="hljs-string">&#x27;passthrough&#x27;</span>, numeric_cols)<br>])<br><br>num_pre = [<span class="hljs-string">&#x27;passthrough&#x27;</span>, preprocessing.StandardScaler(), preprocessing.KBinsDiscretizer(n_bins=<span class="hljs-number">3</span>, encode=<span class="hljs-string">&#x27;ordinal&#x27;</span>, strategy=<span class="hljs-string">&#x27;kmeans&#x27;</span>)]<br><br><span class="hljs-comment"># 实例化逻辑回归评估器</span><br>logistic_model = logit_threshold(max_iter=<span class="hljs-built_in">int</span>(<span class="hljs-number">1e8</span>))<br><br><span class="hljs-comment"># 设置机器学习流</span><br>logistic_pipe = make_pipeline(logistic_pre, logistic_model)<br><br><span class="hljs-comment"># 设置超参数空间</span><br>logistic_param = [<br>    &#123;<span class="hljs-string">&#x27;columntransformer__num&#x27;</span>:num_pre, <span class="hljs-string">&#x27;logit_threshold__thr&#x27;</span>: np.arange(<span class="hljs-number">0.1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">0.1</span>).tolist(), <span class="hljs-string">&#x27;logit_threshold__penalty&#x27;</span>: [<span class="hljs-string">&#x27;l1&#x27;</span>], <span class="hljs-string">&#x27;logit_threshold__C&#x27;</span>: np.arange(<span class="hljs-number">0.1</span>, <span class="hljs-number">1.1</span>, <span class="hljs-number">0.1</span>).tolist(), <span class="hljs-string">&#x27;logit_threshold__solver&#x27;</span>: [<span class="hljs-string">&#x27;saga&#x27;</span>]&#125;, <br>    &#123;<span class="hljs-string">&#x27;columntransformer__num&#x27;</span>:num_pre, <span class="hljs-string">&#x27;logit_threshold__thr&#x27;</span>: np.arange(<span class="hljs-number">0.1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">0.1</span>).tolist(), <span class="hljs-string">&#x27;logit_threshold__penalty&#x27;</span>: [<span class="hljs-string">&#x27;l2&#x27;</span>], <span class="hljs-string">&#x27;logit_threshold__C&#x27;</span>: np.arange(<span class="hljs-number">0.1</span>, <span class="hljs-number">1.1</span>, <span class="hljs-number">0.1</span>).tolist(), <span class="hljs-string">&#x27;logit_threshold__solver&#x27;</span>: [<span class="hljs-string">&#x27;lbfgs&#x27;</span>, <span class="hljs-string">&#x27;newton-cg&#x27;</span>, <span class="hljs-string">&#x27;sag&#x27;</span>, <span class="hljs-string">&#x27;saga&#x27;</span>]&#125;, <br>]<br><br><span class="hljs-comment"># 实例化网格搜索评估器</span><br>logistic_search_f1 = GridSearchCV(estimator = logistic_pipe,<br>                                  param_grid = logistic_param,<br>                                  scoring=<span class="hljs-string">&#x27;f1&#x27;</span>,<br>                                  n_jobs = <span class="hljs-number">12</span>)<br><br>s = time.time()<br>logistic_search_f1.fit(X_train, y_train)<br><span class="hljs-built_in">print</span>(time.time()-s, <span class="hljs-string">&quot;s&quot;</span>)<br></code></pre></td></tr></table></figure><h2 id="逻辑回归模型解释">逻辑回归模型解释</h2><p>对于逻辑回归的模型解释，核心是需要观察线性方程中自变量的系数，通过系数大小可以判断特征重要性，并且系数的具体数值也能表示因变量如何伴随自变量变化而变化。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-comment">#查看逻辑回归系数</span><br>coe = logistic_search.best_estimator_.named_steps[<span class="hljs-string">&#x27;logit_threshold&#x27;</span>].coef_<br>coe = coe.flatten()<br>coe<br><span class="hljs-comment"># 定位独热编码转化器</span><br>tf = logistic_search.best_estimator_.named_steps[<span class="hljs-string">&#x27;columntransformer&#x27;</span>].named_transformers_[<span class="hljs-string">&#x27;cat&#x27;</span>]<br>tf<br><span class="hljs-keyword">def</span> <span class="hljs-title function_">cate_colName</span>(<span class="hljs-params">Transformer, category_cols, drop=<span class="hljs-string">&#x27;if_binary&#x27;</span></span>):<br>    <span class="hljs-string">&quot;&quot;&quot;</span><br><span class="hljs-string">    离散字段独热编码后字段名创建函数</span><br><span class="hljs-string">    </span><br><span class="hljs-string">    :param Transformer: 独热编码转化器</span><br><span class="hljs-string">    :param category_cols: 输入转化器的离散变量</span><br><span class="hljs-string">    :param drop: 独热编码转化器的drop参数</span><br><span class="hljs-string">    &quot;&quot;&quot;</span><br>    <br>    cate_cols_new = []<br>    col_value = Transformer.categories_<br>    <br>    <span class="hljs-keyword">for</span> i, j <span class="hljs-keyword">in</span> <span class="hljs-built_in">enumerate</span>(category_cols):<br>        <span class="hljs-keyword">if</span> (drop == <span class="hljs-string">&#x27;if_binary&#x27;</span>) &amp; (<span class="hljs-built_in">len</span>(col_value[i]) == <span class="hljs-number">2</span>):<br>            cate_cols_new.append(j)<br>        <span class="hljs-keyword">else</span>:<br>            <span class="hljs-keyword">for</span> f <span class="hljs-keyword">in</span> col_value[i]:<br>                feature_name = j + <span class="hljs-string">&#x27;_&#x27;</span> + f<br>                cate_cols_new.append(feature_name)<br>    <span class="hljs-keyword">return</span>(cate_cols_new)<br><span class="hljs-comment"># 转化后离散变量列名称</span><br>category_cols_new = cate_colName(tf, category_cols)<br><br><span class="hljs-comment"># 所有字段名称</span><br>cols_new = category_cols_new + numeric_cols<br><br><span class="hljs-comment"># 查看特征名称数量和特征系数数量是否一致</span><br><span class="hljs-keyword">assert</span> <span class="hljs-built_in">len</span>(cols_new) == <span class="hljs-built_in">len</span>(coe)<br></code></pre></td></tr></table></figure><p>对于<span class="math inline">\(\ln\frac{y}{1-y}=\hat{w}^{T}\cdot\hat{x}=w_1x_1+w_2x_2+\dots+w_nx_n+b\)</span>而言每个<span class="math inline">\(x_i\)</span>的变化会不同程度的影响对数几率的变化。</p><p>以<span class="math inline">\(\ln\frac{y}{1-y}=2x_1-x_2\)</span>为例<span class="math inline">\(x_1\)</span>每增长1,<span class="math inline">\(y\)</span>判别为正例的对数几率就增加2，概率就增加0.4</p><p>此外，还可以根据系数来判别特征重要性。</p>]]></content>
    
    
    <categories>
      
      <category>machine learning</category>
      
    </categories>
    
    
    <tags>
      
      <tag>machine learning</tag>
      
    </tags>
    
  </entry>
  
  
  
  
</search>
