<?xml version="1.0" encoding="utf-8"?>
<search>
  
  
  
  <entry>
    <title>特征筛选方法(假设检验)</title>
    <link href="/posts/31595.html"/>
    <url>/posts/31595.html</url>
    
    <content type="html"><![CDATA[<hr><div class="note note-success">            <p>机器学习 特征工程</p>          </div><h1 id="假设检验">假设检验</h1><p>假设检验是统计推断的一个重要内容，它利用样本信息对总体的某种假设进行检验。假设检验可分为参数假设检验和非参数假设检验，对总体分布中未知参数的假设检验称为参数假设检验，对总体分布函数形式或者总体分布性质的假设检验称为非参数假设检验。</p><h2 id="假设检验的基本思想">假设检验的基本思想</h2><p>想办法构造出在某种假设成立的条件下的一个小概率事件，看此小概率事件在一次抽样试验中是否出现，由此作出统计推断。</p><h2 id="假设检验的主要步骤">假设检验的主要步骤</h2><ul><li>设立统计假设</li></ul><p>统计假设是关于总体状态的一种陈述，一般包含两个假设，原假设<span class="math inline">\(H_{0}\)</span>和备择假设<span class="math inline">\(H_1\)</span>.从形式上看原假设和备择假设可以互换。但是通常将不易加以否定的假设作为原假设，与之互斥的假设就是备择假设。</p><ul><li>选择检验统计量</li></ul><p>对原假设进行判断总是通过一个统计量<span class="math inline">\(W=W(X_1,X_2,\cdots,X_n)\)</span>来完成的，该统计量称为检验统计量.还需要确定在原假设成立的条件下统计量<span class="math inline">\(W\)</span>的精确分布或者极限分布,以便能根据显著性水平<span class="math inline">\(\alpha\)</span>来确定<span class="math inline">\(H_0\)</span>的拒绝域。</p><ul><li>确定拒绝域形式和拒绝域</li></ul><p>通常由假设检验<span class="math inline">\(H_1\)</span>来确定拒绝域形式。如果<span class="math inline">\(H_1:\mu \ne \mu_0\)</span>表示样本均值<span class="math inline">\(\mu\)</span>和<span class="math inline">\(\mu_0\)</span>有显著性差异，则拒绝域形式为<span class="math inline">\(\mathscr{F}_0=\{(x_1,x_2,\cdots,x_n):\vert\overline{X}-\mu_0\vert&gt;c\}\)</span>，称为双侧假设检验问题。又如<span class="math inline">\(H_1:\mu&gt;\mu_0\)</span>，则选择拒绝域<span class="math inline">\(\mathscr{F}_0=\{(x_1,x_2,\cdots,x_n):\overline{X}-\mu_0&gt;c\}\)</span>,称为单侧假设检验问题。</p><p>由显著性水平<span class="math inline">\(\alpha\)</span>,拒绝域<span class="math inline">\(\mathscr{F}_0\)</span>的形式，检验统计量及分布和<span class="math display">\[P\{(X_1,X_2,\cdots,X_n)\in\mathscr{F}_0\vert H_0\text{成立}\}\le \alpha\]</span> 可确定待定常数c，这就确定了拒绝域<span class="math inline">\(\mathscr{F}_0\)</span></p><ul><li>作出判断和决策</li></ul><p>根据抽样信息，计算统计量样本值<span class="math inline">\(w=W(x_1,x_2,\cdots,x_n)\)</span>.若<span class="math inline">\((x_1,x_2,\cdots,x_n)\in\mathscr{F}_0\)</span>，则拒绝<span class="math inline">\(H_0\)</span>，接受<span class="math inline">\(H_1\)</span></p><h3 id="假设检验的两类错误">假设检验的两类错误</h3><p>由于抽样的随机性和小概率原理，假设检验所作出的判断可能与事实不符，出现推断错误。将把拒绝<span class="math inline">\(H_0\)</span>所犯的错误称为弃真错误，把接受<span class="math inline">\(H_0\)</span>所犯的错误称为纳伪错误。如下表所示</p><table><thead><tr class="header"><th></th><th></th><th>真实情况</th><th></th></tr></thead><tbody><tr class="odd"><td></td><td></td><td><span class="math inline">\(H_0\)</span>成立</td><td><span class="math inline">\(H_0\)</span>不成立</td></tr><tr class="even"><td>假设检验结果</td><td>拒绝<span class="math inline">\(H_0\)</span></td><td>弃真错误</td><td>推断错误</td></tr><tr class="odd"><td></td><td>接受<span class="math inline">\(H_0\)</span></td><td>推断错误</td><td>纳伪错误</td></tr></tbody></table><p>设 <span class="math display">\[\alpha = p\{\text{拒绝}H_0\vertH_0\text{成立}\}=P\{(X_1,X_2,\cdots,X_n)\in \mathscr{F}_0 \vertH_0\text{成立}\}\\\beta = p\{\text{接受}H_0\vertH_0\text{不成立}\}=P\{(X_1,X_2,\cdots,X_n)\notin \mathscr{F}_0 \vertH_0\text{不成立}\}\]</span>在样本容量固定的条件下，要使犯两类错误的概率都达到很小是不可能的。在一般场合下，减少犯一类错误的概率，就会增加另一类错误的概率。</p>]]></content>
    
    
    <categories>
      
      <category>machine learning</category>
      
      <category>特征工程</category>
      
    </categories>
    
    
    <tags>
      
      <tag>machine learning</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>特征筛选方法(方差分析)</title>
    <link href="/posts/849.html"/>
    <url>/posts/849.html</url>
    
    <content type="html"><![CDATA[<hr><div class="note note-success">            <p>机器学习 特征工程</p>          </div><h2 id="方差分析">方差分析</h2><p>方差分析用于两个及两个以上总体均值差别的显著性检验。例如，生产某种产品，为了使生产过程稳定，达到优质，高产，需要对影响产品质量的因素进行分析，找出有显著影响的因素，方差分析就是鉴别各因素效应的一种有效的统计方法。</p><h3 id="单因素方差分析">单因素方差分析</h3><p>若在一项试验中只考虑一个因素A的变化，其他因素保持不变，称这种试验为单因素试验。具体做法为：A取几个水平，在每个水平上作若干试验，试验过程中除A外其他影响指标的因素都保持不变（只有随机因素存在），我们的任务是从试验结果推断，因素A对指标有无显著影响，即当A取不同水平时指标有无显著差别。A取某个水平下的指标可视为随机变量，判断A取不同水平时指标有无显著差异，相当于检验若干总体的均值是否相等。</p><p>例：用4种工艺A1,A2,A3,A4生产灯泡，从各种工艺制成的灯泡中各抽出了若干个测量其寿命，结果如下表所示，试推断这几种工艺制成灯泡寿命是否有显著差异。</p><table><thead><tr class="header"><th>A1</th><th>A2</th><th>A3</th><th>A4</th></tr></thead><tbody><tr class="odd"><td>1620</td><td>1580</td><td>1460</td><td>1500</td></tr><tr class="even"><td>1670</td><td>1600</td><td>1540</td><td>1550</td></tr><tr class="odd"><td>1700</td><td>1640</td><td>1620</td><td>1610</td></tr><tr class="even"><td>1750</td><td>1720</td><td>1680</td><td></td></tr><tr class="odd"><td>1800</td><td></td><td></td><td></td></tr></tbody></table><p>该例中不同生产的工艺称为因素，属于单因素的试验，该因素一共有4种取值水平，分别是A1,A2,A3,A4。设每一种工艺生产的灯泡寿命为<span class="math inline">\(X_i,i=1,2,3,4\)</span>。假设每一随机变量<span class="math inline">\(X_i\)</span>都服从正态分布。判断这几种工艺制成灯泡寿命是否有显著差异，即判断随机变量<span class="math inline">\(X_i,i=1,2,3,4\)</span>的均值是否相等。我们对<span class="math inline">\(4\)</span>个总体作出如下假设： <span class="math display">\[H_0:\mu_1=\mu_2=\mu_3=\mu_4\]</span> 记各组内的样本均值为： <span class="math display">\[\hat{X}_i = \frac{1}{n_i}\sum\limits_{j=1}^{n_i}X_{ij},\qquad i=1,2,3,4\]</span> 样本的总均值为 <span class="math display">\[\hat{X} = \frac{1}{n}\sum\limits_{i=1}^{4}\sum\limits_{j=1}^{n_i}X_{ij}= \frac{1}{n}\sum\limits_{i=1}^4n_i\hat{X}_{i},\qquad n=\sum_{i=1}^4n_i\]</span> 计算各样本值与总的平均值之间的离差平方和： <span class="math display">\[\begin{split}S_{T} =&amp;\sum_{i=1}^4\sum_{j=1}^{n_i}(X_{ij}-\hat{X})^2\\                   =&amp;\sum_{i=1}^4\sum_{j=1}^{n_i}(X_{ij}-\hat{X}_i+\hat{X}_i-\hat{X})^2\\                   =&amp;\sum_{i=1}^4\sum_{j=1}^{n_i}(X_{ij}-\hat{X}_i)^2+2\sum_{i=1}^4\sum_{j=1}^{n_i}(X_{ij}-\hat{X}_i)(\hat{X_i}-\hat{X})+\sum_{i=1}^{4}\sum_{j=1}^{n_i}(\hat{X}_i-\hat{X})^2\\                   =&amp;\sum_{i=1}^4\sum_{j=1}^{n_i}(X_{ij}-\hat{X}_i)^2+\sum_{i=1}^4n_i(\hat{X}_i-\hat{X})^2\\       =&amp;S_E+S_A  \end{split}\]</span> 该式称为离差平方和分解式，其中<span class="math inline">\(S_E\)</span>反映各组内部<span class="math inline">\(X_{ij}\)</span>之间的差异（即同一组内随机抽样产生的误差），称为组内离差平方和；<span class="math inline">\(S_A\)</span>反映各组之间由于因素水平不同而引起的差异（不同水平下的差异即条件误差），称为组间离差平方和。方差分析就是通过对组内，组间离差平方和的比较来检验假设的。</p><ul><li>SST（sum of squares for total）</li><li>SSE（sum of squares for error）</li><li>SSA（sum of squares for factor A）</li></ul><p>在实际中，为了简化计算步骤，常按下卖弄的一组公式去计算<span class="math inline">\(SST,SSE,SSA\)</span> <span class="math display">\[SST =\sum_{i=1}^r\sum_{j=1}^{n_i}X_{ij}^2-\frac{1}{n}(\sum_{i=1}^{r}\sum_{j=1}^{n_i}X_{ij})^2\\SSE =\sum_{i=1}^r\sum_{j=1}^{n_i}X_{ij}^2-\sum_{i=1}^r\frac{1}{n_i}(\sum_{j=1}^{n_i}X_{ij})^2\\SSA = SST-SSE\]</span> 定理： <span class="math display">\[\begin{split}&amp;(1) E(S_A) = (r-1)\sigma^2+\sum_{i=1}^{r}n_i(\mu_i-\mu)^2\notag\\&amp;(2) E(S_E)=(n-r)\sigma^2\notag\\&amp;(3) \frac{S_E}{\sigma^2}\sim\chi^2(n-r)\end{split},\qquad where\quad\mu=\frac{1}{n}\sum_{i=1}^{r}n_i\mu_i\]</span> 定理：当<span class="math inline">\(H_0:\mu_1=\mu_2=\cdots=\mu_r\)</span>成立时，有<span class="math display">\[\begin{split}&amp;(1) \frac{S_A}{\sigma^2}\sim\chi^2(r-1)\\&amp;(2)S_E\text{与}S_A\text{相互独立且}F=\frac{S_A/(r-1)}{S_E/(n-r)}\simF(r-1,n-r)\end{split}\]</span> 于是我们根据上述定理构造检验统计量 <span class="math display">\[F=\frac{S_A/(r-1)}{S_E/(n-r)}\]</span> 当<span class="math inline">\(H_0\)</span>成立时，<span class="math inline">\(F\simF(r-1,n-r)\)</span>。于是，在给定显著性水平<span class="math inline">\(\alpha\)</span>下,检验假设 <span class="math display">\[H_0:\mu_1=\mu_2=\cdots=\mu_r\]</span> 若由试验数据算出结果<span class="math inline">\(F&gt;F_{\alpha}(r-1,n-r)\)</span>，则拒绝<span class="math inline">\(H_0\)</span>,即认为因素A对试验结果有显著影响；若<span class="math inline">\(F&lt;F_{\alpha}(r-1,n-r)\)</span>，则接受<span class="math inline">\(H_0\)</span>,即认为因素A对试验结果没有显著影响。</p><p>在方差分析中，还作如下规定：</p><p>（1）如果取<span class="math inline">\(\alpha=0.01\)</span>时拒绝<span class="math inline">\(H_0\)</span>，则称因素A的影响高度显著</p><p>（2）如果取<span class="math inline">\(\alpha=0.05\)</span>时拒绝<span class="math inline">\(H_0\)</span>，但取<span class="math inline">\(\alpha=0.01\)</span>时不拒绝<span class="math inline">\(H_0\)</span>,则称因素A的影响显著。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><code class="hljs python">x = np.array([<span class="hljs-number">1620</span>,<span class="hljs-number">1670</span>,<span class="hljs-number">1700</span>,<span class="hljs-number">1750</span>,<span class="hljs-number">1800</span>,<span class="hljs-number">1580</span>,<span class="hljs-number">1600</span>,<span class="hljs-number">1640</span>,<span class="hljs-number">1720</span>,<span class="hljs-number">1460</span>,<span class="hljs-number">1540</span>,<span class="hljs-number">1620</span>,<span class="hljs-number">1680</span>,<span class="hljs-number">1500</span>,<span class="hljs-number">1610</span>])<br>y = np.array([<span class="hljs-number">0</span>,<span class="hljs-number">0</span>,<span class="hljs-number">0</span>,<span class="hljs-number">0</span>,<span class="hljs-number">0</span>,<span class="hljs-number">1</span>,<span class="hljs-number">1</span>,<span class="hljs-number">1</span>,<span class="hljs-number">1</span>,<span class="hljs-number">2</span>,<span class="hljs-number">2</span>,<span class="hljs-number">2</span>,<span class="hljs-number">2</span>,<span class="hljs-number">3</span>,<span class="hljs-number">3</span>,<span class="hljs-number">3</span>])<br>df = pd.DataFrame(x,columns=[<span class="hljs-string">&quot;x&quot;</span>])<br>df[<span class="hljs-string">&quot;y&quot;</span>] = pd.DataFrame(y,columns=[<span class="hljs-string">&quot;y&quot;</span>])<br><span class="hljs-keyword">from</span> scipy.stats <span class="hljs-keyword">import</span> f_oneway<br>f_oneway(df[<span class="hljs-string">&quot;x&quot;</span>],df[<span class="hljs-string">&quot;y&quot;</span>])<br>F_onewayResult(statistic=<span class="hljs-number">4724.493209349733</span>, pvalue=<span class="hljs-number">9.098985853698895e-33</span>)<br></code></pre></td></tr></table></figure><h3 id="单因素方差分析用于特征筛选">单因素方差分析用于特征筛选</h3><p>当标签为离散变量时，特征为连续变量时可以用方差分析来进行特征筛选</p><p>在标签的不同水平下的特征有无显著性差异。作假设<span class="math inline">\(H_0:\)</span>在标签的不同取值水平下特征无显著性差异。通过方差分析作统计推断。若pvalues_&lt;0.01(0.05)，则拒绝原假设，认为在标签的不同水平下特征有显著差异。那么此特征就是可用特征。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">def</span> <span class="hljs-title function_">SelectName</span>(<span class="hljs-params">KB,P=<span class="hljs-number">0.01</span></span>):<br>    <span class="hljs-string">&quot;&quot;&quot;</span><br><span class="hljs-string">    方差分析作特征筛选时挑选列名称函数</span><br><span class="hljs-string">    params KB:训练好的挑选器</span><br><span class="hljs-string">    params P:给定的显著性阈值</span><br><span class="hljs-string">    &quot;&quot;&quot;</span><br>    colNames = []<br>    <span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> <span class="hljs-built_in">zip</span>(KB.feature_names_in_,KB.pvalues_):<br>        <span class="hljs-keyword">if</span> i[<span class="hljs-number">1</span>]&lt;P:<br>            colNames.append(i[<span class="hljs-number">0</span>])<br>    <span class="hljs-keyword">return</span> colNames<br></code></pre></td></tr></table></figure>]]></content>
    
    
    <categories>
      
      <category>machine learning</category>
      
      <category>特征工程</category>
      
    </categories>
    
    
    <tags>
      
      <tag>machine learning</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>特征筛选方法(独立性检验)</title>
    <link href="/posts/48705.html"/>
    <url>/posts/48705.html</url>
    
    <content type="html"><![CDATA[<hr><div class="note note-success">            <p>机器学习 特征工程</p>          </div><h2 id="独立性检验">独立性检验</h2><h3 id="独立性检验原理">独立性检验原理</h3><p>在某些实际问题中常常会遇到两个指标，需要分析两个指标<span class="math inline">\(X,Y\)</span>之间的相互依赖关系。假设<span class="math inline">\(X\)</span>有<span class="math inline">\(r\)</span>个不同可能取值<span class="math inline">\(A_i,i=1,2,\dots,r\)</span>，<span class="math inline">\(Y\)</span>有<span class="math inline">\(s\)</span>个不同可能取值<span class="math inline">\(B_j,j=1,2,\dots,s\)</span>。则属于<span class="math inline">\(A_i\)</span>和<span class="math inline">\(B_j\)</span>的频数记为<span class="math inline">\(n_{ij},(i=1,2,\dots,r,j=1,2,\dots,s)\)</span>，形成如下列联表。</p><p><img src="https://pjs-1312672154.cos.ap-shanghai.myqcloud.com/QQ%E6%88%AA%E5%9B%BE20220711194807.png"></p><p>类似地，对应于上表的多项概率分布如下表所示，其中<span class="math inline">\(p_{ij}\)</span>表示同时属于<span class="math inline">\(A_i\)</span>和<span class="math inline">\(B_j\)</span>类的概率，并且边缘分布律为<span class="math inline">\(p_{.j}\)</span>和<span class="math inline">\(p_{i.}\)</span></p><p><img src="https://pjs-1312672154.cos.ap-shanghai.myqcloud.com/QQ%E6%88%AA%E5%9B%BE20220711194834.png"></p><h4 id="问题描述">问题描述</h4><p>假设<span class="math inline">\((x_i,y_i)(i=1,2,\dots,n)\)</span>是总体<span class="math inline">\((X,Y)\)</span>的样本测试值，将<span class="math inline">\(X\)</span>的可能取值分为<span class="math inline">\(r\)</span>个互不相交的类<span class="math inline">\(A_1,A_2,\dots,A_r\)</span>，<span class="math inline">\(Y\)</span>的可能取值分为<span class="math inline">\(s\)</span>个互不相交的类<span class="math inline">\(B_1,B_2,\dots,B_s\)</span>，欲检验： <span class="math display">\[H_0:X\text{与}Y\text{独立}，H_1:X\text{与}Y\text{不独立} \iffH_0:p_{ij}=p_{i\cdot}p_{\cdot, j}\quad\forall i,j,H_1:p_{ij}\neqp_{i\cdot}p_{\cdot j }\quad \text{对某个}(i,j)\]</span></p><h4 id="chi2检验统计量及拒绝域"><span class="math inline">\(\chi^{2}\)</span>检验统计量及拒绝域</h4><p>针对假设（1），若<span class="math inline">\(H_0\)</span>成立，则对所有的<span class="math inline">\((i,j)\)</span>，实际频数<span class="math inline">\(n_{ij}\)</span>与理论频数<span class="math inline">\(np_{ij}\)</span>的差异应该很小。故构造检验统计量<span class="math display">\[\chi^{2} =\sum\limits_{j=1}^{s}\sum\limits_{i=1}^{r}\frac{(n_{ij}-np_{ij})^{2}}{np_{ij}}\]</span> 由于一般情况下<span class="math inline">\(p_{ij}\)</span>未知，可用<span class="math inline">\(p_{ij}\)</span>的最大似然估计<span class="math inline">\(\hat{p}_{ij}\)</span>代替，在<span class="math inline">\(H_0\)</span>成立的条件下，可退证 <span class="math display">\[\hat{p}_{ij} = \hat{p}_{i\cdot}\cdot\hat{p}_{\cdotj}=\frac{n_{i\cdot}\cdot n_{\cdot j}}{n^2},\forall i,j\]</span> 式（2）可化简为 <span class="math display">\[\chi^{2} =\sum\limits_{j=1}^{s}\sum\limits_{i=1}^{r}\frac{(n_{ij}-np_{ij})^{2}}{np_{ij}}=n\sum\limits_{j=1}^{s}\sum\limits_{i=1}^{r}\frac{n_{ij}^2}{n_{i\cdot}n_{\cdotj}}-n\]</span> 可以证明，在<span class="math inline">\(H_0\)</span>成立下，<span class="math inline">\(\chi^2 \sim\chi^2((r-1)(s-1))\)</span>，且拒绝域为 <span class="math display">\[\mathscr{F}_0 = \{\chi^2&gt;\chi^2_{1-\alpha}((r-1)(s-1))\}\]</span></p><h3 id="独立性检验python实现">独立性检验Python实现</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs python">&gt;&gt;&gt;X = X_train_OE[<span class="hljs-string">&quot;Contract&quot;</span>] <span class="hljs-comment">#某数据集的一列</span><br>&gt;&gt;&gt;y = y_train <span class="hljs-comment">#某数据的标签列</span><br>&gt;&gt;&gt;df_crosstab = pd.crosstab(X,y) <span class="hljs-comment">#创建联合表</span><br></code></pre></td></tr></table></figure><p><img src="https://pjs-1312672154.cos.ap-shanghai.myqcloud.com/QQ%E6%88%AA%E5%9B%BE20220711202002.png"></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">from</span> scipy <span class="hljs-keyword">import</span> stats<br>stats.chi2_contingency(df_crosstab) <span class="hljs-comment">#卡方检验</span><br></code></pre></td></tr></table></figure><p><img src="https://pjs-1312672154.cos.ap-shanghai.myqcloud.com/QQ%E6%88%AA%E5%9B%BE20220711202106.png"></p><p>chi2_contingency函数返回了四个结果，分别是卡方值、显著性水平、自由度以及期望频数表。其中<span class="math inline">\(\alpha\)</span>显著性水平为<span class="math inline">\(P\{(X_1,X_2,\dots,X_n)\in \mathscr{F}_0\vertH_0\text{成立}\}\le\alpha\)</span>.这就说明第一个值越大，第二个值越小，则两个变量越不独立，就越相关。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">import</span> scipy<br>scipy.special.chdtrc(<span class="hljs-number">2</span>, <span class="hljs-number">872.3694073422871</span>)<span class="hljs-comment">#第一个参数为自由度，第二个参数为卡方值。</span><br></code></pre></td></tr></table></figure><p>可以根据以上计算显著性水平。</p><h3 id="独立性检验机器学习应用特征筛选">独立性检验机器学习应用（特征筛选）</h3><p>在机器学习领域，卡方检验主要用于海量特征衍生后的特征筛选。主要是离散变量与离散标签之间的独立性（相关性）。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">def</span> <span class="hljs-title function_">SelectName_P</span>(<span class="hljs-params">P=<span class="hljs-number">0.01</span>,KB</span>):<br>    <span class="hljs-string">&quot;&quot;&quot;</span><br><span class="hljs-string">    根据显著性水平筛选特征 </span><br><span class="hljs-string">    :param P :显著性水平</span><br><span class="hljs-string">    :param KB:已经训练好的评分函数为Chi2的SelectKBest评估器</span><br><span class="hljs-string">    &quot;&quot;&quot;</span><br>    colNames = []<br>    <span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> <span class="hljs-built_in">zip</span>(KB.feature_names_in_,KB.pvalues_):<br>        <span class="hljs-keyword">if</span> i[<span class="hljs-number">1</span>] &lt;= P:<br>            colNames.append(i[<span class="hljs-number">0</span>])<br>    <span class="hljs-keyword">return</span> colNames<br></code></pre></td></tr></table></figure>]]></content>
    
    
    <categories>
      
      <category>machine learning</category>
      
      <category>特征工程</category>
      
    </categories>
    
    
    <tags>
      
      <tag>machine learning</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>关键特征衍生方法</title>
    <link href="/posts/37255.html"/>
    <url>/posts/37255.html</url>
    
    <content type="html"><![CDATA[<hr><div class="note note-success">            <p>机器学习 特征工程</p>          </div><h1 id="关键特征衍生方法">关键特征衍生方法</h1><h2 id="时序字段衍生方法">时序字段衍生方法</h2><h3 id="更细粒度时间信息">更细粒度时间信息</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">import</span> numpy <span class="hljs-keyword">as</span> np<br><span class="hljs-keyword">import</span> pandas <span class="hljs-keyword">as</span> pd<br><span class="hljs-keyword">from</span> datetime <span class="hljs-keyword">import</span> datetime<br>l = pd.date_range(<span class="hljs-string">&quot;1/1/2021 00:00:00&quot;</span>,periods=<span class="hljs-number">100000</span>,freq=<span class="hljs-string">&quot;15min&quot;</span>)<br>tdf = pd.DataFrame(l,columns=[<span class="hljs-string">&quot;time&quot;</span>])<br><span class="hljs-comment">#year</span><br>tdf[<span class="hljs-string">&quot;year&quot;</span>] = tdf[<span class="hljs-string">&quot;time&quot;</span>].dt.year<br><span class="hljs-comment">#month</span><br>tdf[<span class="hljs-string">&quot;month&quot;</span>] = tdf[<span class="hljs-string">&quot;time&quot;</span>].dt.month<br><span class="hljs-comment">#day</span><br>tdf[<span class="hljs-string">&quot;day&quot;</span>] = tdf[<span class="hljs-string">&quot;time&quot;</span>].dt.day<br><span class="hljs-comment">#hour</span><br>tdf[<span class="hljs-string">&quot;hour&quot;</span>] = tdf[<span class="hljs-string">&quot;time&quot;</span>].dt.hour<br><span class="hljs-comment">#minute</span><br>tdf[<span class="hljs-string">&quot;minute&quot;</span>] = tdf[<span class="hljs-string">&quot;time&quot;</span>].dt.minute<br><span class="hljs-comment">#second</span><br>tdf[<span class="hljs-string">&quot;second&quot;</span>] = tdf[<span class="hljs-string">&quot;time&quot;</span>].dt.second<br><span class="hljs-comment">#quarter</span><br>tdf[<span class="hljs-string">&quot;quarter&quot;</span>] = tdf[<span class="hljs-string">&quot;time&quot;</span>].dt.quarter<br><span class="hljs-comment">#week of year</span><br>tdf[<span class="hljs-string">&quot;weekofyear&quot;</span>] = tdf[<span class="hljs-string">&quot;time&quot;</span>].dt.isocalendar().week<br><span class="hljs-comment">#day of week</span><br>tdf[<span class="hljs-string">&quot;dayofweek&quot;</span>] = tdf[<span class="hljs-string">&quot;time&quot;</span>].dt.weekday+<span class="hljs-number">1</span> <span class="hljs-comment">#默认周一为0</span><br><span class="hljs-comment">#weekend</span><br>tdf[<span class="hljs-string">&quot;weekend&quot;</span>] = (tdf[<span class="hljs-string">&quot;dayofweek&quot;</span>]&gt;<span class="hljs-number">5</span>)*<span class="hljs-number">1</span><br><span class="hljs-comment">#hour_section</span><br>tdf[<span class="hljs-string">&quot;hour_section&quot;</span>] = (tdf[<span class="hljs-string">&quot;hour&quot;</span>]//<span class="hljs-number">6</span>).astype(<span class="hljs-built_in">int</span>) <span class="hljs-comment">#将一天划分为凌晨，上午，下午，夜晚.映射为0,1,2,3</span><br><span class="hljs-comment">#given_day</span><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">given_day</span>(<span class="hljs-params">tdf,daylst</span>):<br>    <span class="hljs-string">&quot;&quot;&quot;</span><br><span class="hljs-string">    查询给定日期</span><br><span class="hljs-string">    param tdf:tdf其中有一列(列名称为time)为日期datetime类型</span><br><span class="hljs-string">    param daylst:给定日期列表 格式为&quot;2022-07-08&quot;</span><br><span class="hljs-string">    &quot;&quot;&quot;</span><br>    df_temp = pd.DataFrame(tdf[<span class="hljs-string">&quot;time&quot;</span>].values.astype(<span class="hljs-string">&#x27;datetime64[D]&#x27;</span>),columns=[<span class="hljs-string">&quot;year-month-day&quot;</span>])<br>    <span class="hljs-comment">#不可保存在series中但是可以保存在DataFrame中</span><br>    <span class="hljs-keyword">return</span> df_temp[<span class="hljs-string">&quot;year-month-day&quot;</span>].isin(daylst)*<span class="hljs-number">1</span><br>daylst = [<span class="hljs-string">&quot;2021-04-03&quot;</span>,<span class="hljs-string">&quot;2021-01-01&quot;</span>]<br>tdf[<span class="hljs-string">&quot;given_day&quot;</span>] = given_day(tdf,daylst) <span class="hljs-comment">#将指定日期比如节假日或者特殊的日期标记为1,其他为0</span><br></code></pre></td></tr></table></figure><h3 id="自然周期和业务周期">自然周期和业务周期</h3><p>所谓自然周期，指的是对于时间大家普遍遵照或者约定俗成的一些规定，例如工作日周末、一周七天、一年四个季度等，这也就是此前我们进行的一系列特征衍生工作，此外其实还可以根据一些业务周期来进行时序特征的划分，例如对于部分旅游景点来说，暑假是旅游旺季，并且很多是以家庭为单位进行出游（学生暑假），因此可以考虑单独将8、9月进行标记，期间记录的用户会有许多共性，而组内用户的共性就将成为后续建模效果的保障；再比如6月、11月是打折季，也可以类似的单独设一列对6月、11月进行标记等等，这些需要特征的衍生，则需要结合具体业务情况来进行判断。</p><h3 id="关键时间点时间差值">关键时间点时间差值</h3><p>关键时间点的时间差值特征衍衍生。该方法并不复杂，实际操作过程中需要首先人工设置关键时间点，然后计算每条记录和关键时间点之间的时间差，具体时间差的衡量以天和月为主，当然也可以根据数据集整体的时间跨度为前提进行考虑（例如数据集整体时间记录都是一天当中的不同时间，则时间差的计算可以是小时甚至是分钟）。其中，关键时间点一般来说可以是数据集记录的起始时间、结束时间、距今时间，也可以是根据是根据业务或者数据集本身的数据规律，推导出来的关键时间点。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><code class="hljs python">start_stamp = tdf[<span class="hljs-string">&quot;time&quot;</span>].<span class="hljs-built_in">min</span>()<span class="hljs-comment">#起始时间</span><br>end_stamp = tdf[<span class="hljs-string">&quot;time&quot;</span>].<span class="hljs-built_in">max</span>()<span class="hljs-comment">#截止时间</span><br>current_stamp = pd.Timestamp(datetime.now().strftime(<span class="hljs-string">&quot;%Y-%m-%d&quot;</span>)) <span class="hljs-comment">#当前时间</span><br>tdf[<span class="hljs-string">&quot;start_diff_days&quot;</span>]=(tdf[<span class="hljs-string">&quot;time&quot;</span>]-start_stamp).dt.days<span class="hljs-comment">#相差的天数完全忽略时分秒</span><br><br>tdf[<span class="hljs-string">&quot;start_diff_seconds&quot;</span>]=(tdf[<span class="hljs-string">&quot;time&quot;</span>]-start_stamp).values.astype(<span class="hljs-string">&quot;timedelta64[s]&quot;</span>).astype(<span class="hljs-built_in">int</span>) <span class="hljs-comment">#相差的秒数</span><br>tdf[<span class="hljs-string">&quot;start_diff_hours&quot;</span>] = (tdf[<span class="hljs-string">&quot;time&quot;</span>]-start_stamp).values.astype(<span class="hljs-string">&quot;timedelta64[h]&quot;</span>).astype(<span class="hljs-built_in">int</span>) <span class="hljs-comment">#相差的天数</span><br></code></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">from</span> datetime <span class="hljs-keyword">import</span> datetime<br><span class="hljs-keyword">def</span> <span class="hljs-title function_">timeSeriesCreation</span>(<span class="hljs-params">timeSeries, timeStamp=<span class="hljs-literal">None</span>, precision_high=<span class="hljs-literal">False</span>,given_day=<span class="hljs-literal">None</span></span>):<br>    <span class="hljs-string">&quot;&quot;&quot;</span><br><span class="hljs-string">    时序字段的特征衍生</span><br><span class="hljs-string">    </span><br><span class="hljs-string">    :param timeSeries：时序特征，需要是一个Series</span><br><span class="hljs-string">    :param timeStamp：手动输入的关键时间节点的时间戳，需要组成字典形式，字典的key、value分别是时间戳的名字与字符串</span><br><span class="hljs-string">    :param precision_high：是否精确到时、分、秒</span><br><span class="hljs-string">    :param given_day:一个给定日期的列表（一般为节假日，特殊日期）,格式为&quot;年-月-日&quot;</span><br><span class="hljs-string">    :return features_new, colNames_new：返回创建的新特征矩阵和特征名称</span><br><span class="hljs-string">    &quot;&quot;&quot;</span><br>    <br>    <span class="hljs-comment"># 创建衍生特征df</span><br>    features_new = pd.DataFrame()<br>    <br>    <span class="hljs-comment"># 提取时间字段及时间字段的名称</span><br>    timeSeries = pd.to_datetime(timeSeries)<br>    colNames = timeSeries.name<br>    <br>    <span class="hljs-comment"># 年月日信息提取</span><br>    features_new[colNames+<span class="hljs-string">&#x27;_year&#x27;</span>] = timeSeries.dt.year<br>    features_new[colNames+<span class="hljs-string">&#x27;_month&#x27;</span>] = timeSeries.dt.month<br>    features_new[colNames+<span class="hljs-string">&#x27;_day&#x27;</span>] = timeSeries.dt.day<br>    <br>    <span class="hljs-keyword">if</span> precision_high != <span class="hljs-literal">False</span>:<br>        features_new[colNames+<span class="hljs-string">&#x27;_hour&#x27;</span>] = timeSeries.dt.hour<br>        features_new[colNames+<span class="hljs-string">&#x27;_minute&#x27;</span>] = timeSeries.dt.minute<br>        features_new[colNames+<span class="hljs-string">&#x27;_second&#x27;</span>] = timeSeries.dt.second<br>    <br>    <span class="hljs-comment"># 自然周期提取</span><br>    features_new[colNames+<span class="hljs-string">&#x27;_quarter&#x27;</span>] = timeSeries.dt.quarter<br>    features_new[colNames+<span class="hljs-string">&#x27;_weekofyear&#x27;</span>] = timeSeries.dt.isocalendar().week<br>    features_new[colNames+<span class="hljs-string">&#x27;_dayofweek&#x27;</span>] = timeSeries.dt.dayofweek + <span class="hljs-number">1</span><br>    features_new[colNames+<span class="hljs-string">&#x27;_weekend&#x27;</span>] = (features_new[colNames+<span class="hljs-string">&#x27;_dayofweek&#x27;</span>] &gt; <span class="hljs-number">5</span>).astype(<span class="hljs-built_in">int</span>)<br>    <span class="hljs-comment">#给定日期提取</span><br>    <span class="hljs-keyword">if</span> given_day != <span class="hljs-literal">None</span>:<br>        df_temp = pd.DataFrame(timeSeries.values.astype(<span class="hljs-string">&#x27;datetime64[D]&#x27;</span>),columns=[<span class="hljs-string">&quot;year-month-day&quot;</span>])<br>        features_new[<span class="hljs-string">&quot;given_day&quot;</span>] = df_temp[<span class="hljs-string">&quot;year-month-day&quot;</span>].isin(given_day)*<span class="hljs-number">1</span><br>    <br>    <span class="hljs-keyword">if</span> precision_high != <span class="hljs-literal">False</span>:<br>        features_new[<span class="hljs-string">&#x27;hour_section&#x27;</span>] = (features_new[colNames+<span class="hljs-string">&#x27;_hour&#x27;</span>] // <span class="hljs-number">6</span>).astype(<span class="hljs-built_in">int</span>) <br>    <br>    <span class="hljs-comment"># 关键时间点时间差计算</span><br>    <span class="hljs-comment"># 创建关键时间戳名称的列表和时间戳列表</span><br>    timeStamp_name_l = []<br>    timeStamp_l = []<br>    <br>    <span class="hljs-keyword">if</span> timeStamp != <span class="hljs-literal">None</span>:<br>        timeStamp_name_l = <span class="hljs-built_in">list</span>(timeStamp.keys())<br>        timeStamp_l = [pd.Timestamp(x) <span class="hljs-keyword">for</span> x <span class="hljs-keyword">in</span> <span class="hljs-built_in">list</span>(timeStamp.values())]<br>    <br>    <span class="hljs-comment"># 准备通用关键时间点时间戳</span><br>    time_max = timeSeries.<span class="hljs-built_in">max</span>()<br>    time_min = timeSeries.<span class="hljs-built_in">min</span>()<br>    time_now = pd.to_datetime(datetime.now().strftime(<span class="hljs-string">&#x27;%Y-%m-%d %H:%M:%S&#x27;</span>))<br>    timeStamp_name_l.extend([<span class="hljs-string">&#x27;time_max&#x27;</span>, <span class="hljs-string">&#x27;time_min&#x27;</span>, <span class="hljs-string">&#x27;time_now&#x27;</span>])<br>    timeStamp_l.extend([time_max, time_min, time_now])<br>    <br>    <span class="hljs-comment"># 时间差特征衍生</span><br>    <span class="hljs-keyword">for</span> timeStamp, timeStampName <span class="hljs-keyword">in</span> <span class="hljs-built_in">zip</span>(timeStamp_l, timeStamp_name_l):<br>        time_diff = timeSeries - timeStamp<br>        features_new[<span class="hljs-string">&#x27;time_diff_days&#x27;</span>+<span class="hljs-string">&#x27;_&#x27;</span>+timeStampName] = time_diff.dt.days<br>        features_new[<span class="hljs-string">&#x27;time_diff_months&#x27;</span>+<span class="hljs-string">&#x27;_&#x27;</span>+timeStampName] = np.<span class="hljs-built_in">round</span>(features_new[<span class="hljs-string">&#x27;time_diff_days&#x27;</span>+<span class="hljs-string">&#x27;_&#x27;</span>+timeStampName] / <span class="hljs-number">30</span>).astype(<span class="hljs-string">&#x27;int&#x27;</span>)<br>        <span class="hljs-keyword">if</span> precision_high != <span class="hljs-literal">False</span>:<br>            features_new[<span class="hljs-string">&#x27;time_diff_seconds&#x27;</span>+<span class="hljs-string">&#x27;_&#x27;</span>+timeStampName] = time_diff.dt.seconds<br>            features_new[<span class="hljs-string">&#x27;time_diff_h&#x27;</span>+<span class="hljs-string">&#x27;_&#x27;</span>+timeStampName] = time_diff.values.astype(<span class="hljs-string">&#x27;timedelta64[h]&#x27;</span>).astype(<span class="hljs-string">&#x27;int&#x27;</span>)<br>            features_new[<span class="hljs-string">&#x27;time_diff_s&#x27;</span>+<span class="hljs-string">&#x27;_&#x27;</span>+timeStampName] = time_diff.values.astype(<span class="hljs-string">&#x27;timedelta64[s]&#x27;</span>).astype(<span class="hljs-string">&#x27;int&#x27;</span>)<br>    <br>    colNames_new = <span class="hljs-built_in">list</span>(features_new.columns)<br>    <span class="hljs-keyword">return</span> features_new, colNames_new<br></code></pre></td></tr></table></figure><h2 id="nlp特征衍生方法">NLP特征衍生方法</h2><h3 id="countvectorizer与词向量转化">CountVectorizer与词向量转化</h3><p>在NLP领域中，所有依据分词结果转化为向量的过程都被称为词向量转化，因此CountVectorizer也可以理解为词向量转化方式的一种。同时，我们通过观察不难发现，词向量的转化过程其本质就是一个对序列进行有效信息提取的过程，这里指的有效信息实际上就是指对后续建模有帮助的信息。在很多NLP的情境下，词频其实就代表着语义的倾向，例如出现了“很好”时（“很好”词频为1）时则表示用户对产品的正面肯定，而出现了“一般”时则表示用户对产品并不满意。此外，如果一句话（也就是一段文本）中重复出现了某些单词，则很有可能表示强调的含义。不管怎样，我们对不同单词的词频的统计，其实是希望从一段文本中提取有效信息，或者说提取有效信息，是所有词向量化共同的目标。</p><ul><li>sklearn实现</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><code class="hljs python">corpus = [<span class="hljs-string">&#x27;This is the first document.&#x27;</span>,<br>          <span class="hljs-string">&#x27;This is the second second document.&#x27;</span>,<br>          <span class="hljs-string">&#x27;And the third one.&#x27;</span>,<br>          <span class="hljs-string">&#x27;Is this the first document?&#x27;</span>]<br><span class="hljs-keyword">from</span> sklearn.feature_extraction.text <span class="hljs-keyword">import</span> CountVectorizer<br>vec = CountVectorizer()<br>X = vec.fit_transform(corpus).toarray()<br>vec.get_feature_names() <span class="hljs-comment">#获取array每一列对应的term</span><br>[<span class="hljs-string">&#x27;and&#x27;</span>, <span class="hljs-string">&#x27;document&#x27;</span>, <span class="hljs-string">&#x27;first&#x27;</span>, <span class="hljs-string">&#x27;is&#x27;</span>, <span class="hljs-string">&#x27;one&#x27;</span>, <span class="hljs-string">&#x27;second&#x27;</span>, <span class="hljs-string">&#x27;the&#x27;</span>, <span class="hljs-string">&#x27;third&#x27;</span>, <span class="hljs-string">&#x27;this&#x27;</span>]<br></code></pre></td></tr></table></figure><h3 id="tf-idf-词频-逆向词频统计">TF-IDF 词频-逆向词频统计</h3><p>除了CountVectorizer外，词向量化的常用方法还有IF-IDF，也就是所谓的词频-逆向词频统计。我们知道，CountVectorizer是简单的单词计数，单词出现的次数越高、我们往往就认为该单词对文本的表意就起到了越关键的作用。但有的时候情况恰好相反，例如一些语气助词，“啊、呀”等，再比如中文里面的“的”，这些在文本经常出现的单词，可能恰好对文本表意的识别起不到任何有效作用，也就是说，有的时候简单的词频统计结果无法体现单词对文本表意的重要性。若要降低这些出现频率很高但又没什么用的单词的数值权重，就需要使用另一种词向量转化方法——TF-IDF。</p><p>TF-IDF的计算一共分为两部分，其一是词频（term frequency）用<span class="math inline">\(tf(d,t)\)</span>表示，其二是逆向文件频率（inversedocument frequency）<span class="math inline">\(idf(t)\)</span>。词频计算为上述词频统计。逆向文件频率指的是包含该单词的文本占总文本的比例的逆。而<span class="math display">\[tf-idf(d,t)=tf(d,t)\times idf(t)\]</span></p><p><span class="math display">\[idf(t) = log(\frac{n}{df(t)})\]</span></p><p>其中<span class="math inline">\(df(t)\)</span>表示出现term（t）的总数。取对数是为了压缩数值。需要注意的是sklearn中<span class="math inline">\(idf(t)=\log(\frac{n}{df(t)})+1\)</span>，加一是为了使<span class="math inline">\(idf(t)\)</span>的取值恒大于1</p><ul><li>sklearn实现</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">from</span> sklearn.feature_extraction.text <span class="hljs-keyword">import</span> TfidfVectorizer<br>enc = TfidfVectorizer(smooth_idf=<span class="hljs-literal">True</span>,norm=<span class="hljs-string">&quot;l2&quot;</span>)<br>X = enc.fit_transform(corpus).toarray()<br>enc.get_feature_names()<br></code></pre></td></tr></table></figure><p>其中smooth_idf=True的计算过程如下: <span class="math display">\[idf(t) = log(\frac{n+1}{df(t)+1})+1\]</span></p><p><img src="https://pjs-1312672154.cos.ap-shanghai.myqcloud.com/figa.png"></p><p>由图可以看出分子分母同时加一可以使较大数据平滑减小，其实也可将较小数据平滑增大</p><h3 id="nlp特征衍生简单应用">NLP特征衍生简单应用</h3><ul><li>分组统计，组看成document，特征看成term，如下图所示：</li></ul><p><img src="https://pjs-1312672154.cos.ap-shanghai.myqcloud.com/IWZx31Nnv2utKgR.png"></p><ul><li>分组统计，组看成document，组内取值看为term</li></ul><p><img src="https://pjs-1312672154.cos.ap-shanghai.myqcloud.com/iAaNMqJeRUQb2DK.png"></p><ul><li>单行数据情况，每一行数据作为一个document，该特征下所有取值作为term。</li></ul><p><img src="https://pjs-1312672154.cos.ap-shanghai.myqcloud.com/LhbsCKam5kH7Y8X.png"></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br><span class="line">135</span><br><span class="line">136</span><br><span class="line">137</span><br><span class="line">138</span><br><span class="line">139</span><br><span class="line">140</span><br><span class="line">141</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">from</span> sklearn.preprocessing <span class="hljs-keyword">import</span> normalize<br><span class="hljs-keyword">from</span> sklearn.feature_extraction.text <span class="hljs-keyword">import</span> CountVectorizer<br><span class="hljs-keyword">from</span> sklearn.feature_extraction.text <span class="hljs-keyword">import</span> TfidfTransformer<br><span class="hljs-keyword">def</span> <span class="hljs-title function_">Multi_Cross_Combination</span>(<span class="hljs-params">colNames, features, OneHot=<span class="hljs-literal">True</span></span>):<br>    <span class="hljs-string">&quot;&quot;&quot;</span><br><span class="hljs-string">    多变量组合交叉衍生</span><br><span class="hljs-string">    </span><br><span class="hljs-string">    :param colNames: 参与交叉衍生的列名称</span><br><span class="hljs-string">    :param features: 原始数据集</span><br><span class="hljs-string">    :param OneHot: 是否进行独热编码</span><br><span class="hljs-string">    </span><br><span class="hljs-string">    :return：交叉衍生后的新特征和新列名称</span><br><span class="hljs-string">    &quot;&quot;&quot;</span><br>    <br>    <br>    <span class="hljs-comment"># 创建组合特征</span><br>    colNames_new = <span class="hljs-string">&#x27;&amp;&#x27;</span>.join([<span class="hljs-built_in">str</span>(i) <span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> colNames])<br>    features_new = features[colNames[<span class="hljs-number">0</span>]].astype(<span class="hljs-string">&#x27;str&#x27;</span>)<br><br>    <span class="hljs-keyword">for</span> col <span class="hljs-keyword">in</span> colNames[<span class="hljs-number">1</span>:]:<br>        features_new = features_new + <span class="hljs-string">&#x27;&amp;&#x27;</span> + features[col].astype(<span class="hljs-string">&#x27;str&#x27;</span>) <br>    <br>    <span class="hljs-comment"># 将组合特征转化为DataFrame</span><br>    features_new = pd.DataFrame(features_new, columns=[colNames_new])<br>    <br>    <span class="hljs-comment"># 对新的特征列进行独热编码</span><br>    <span class="hljs-keyword">if</span> OneHot == <span class="hljs-literal">True</span>:<br>        enc = preprocessing.OneHotEncoder()<br>        enc.fit_transform(features_new)<br>        colNames_new = cate_colName(enc, [colNames_new], drop=<span class="hljs-literal">None</span>)<br>        features_new = pd.DataFrame(enc.fit_transform(features_new).toarray(), columns=colNames_new)<br>        <br>    <span class="hljs-keyword">return</span> features_new, colNames_new<br><span class="hljs-keyword">def</span> <span class="hljs-title function_">NLP_Group_Statistics</span>(<span class="hljs-params">features, </span><br><span class="hljs-params">                         col_cat, </span><br><span class="hljs-params">                         keyCol=<span class="hljs-literal">None</span>,</span><br><span class="hljs-params">                         tfidf=<span class="hljs-literal">True</span>, </span><br><span class="hljs-params">                         countVec=<span class="hljs-literal">True</span></span>):<br>    <span class="hljs-string">&quot;&quot;&quot;</span><br><span class="hljs-string">    多变量分组统计特征衍生函数</span><br><span class="hljs-string">    </span><br><span class="hljs-string">    :param features: 原始数据集</span><br><span class="hljs-string">    :param col_cat: 参与衍生的离散型变量，只能带入多个列,list</span><br><span class="hljs-string">    :param keyCol: 分组参考的关键变量，输入字符串时代表按照单独列分组，输入list代表按照多个列进行分组</span><br><span class="hljs-string">    :param tfidf: 是否进行tfidf计算  </span><br><span class="hljs-string">    :param countVec: 是否进行CountVectorizer计算</span><br><span class="hljs-string"></span><br><span class="hljs-string">    :return：NLP特征衍生后的新特征和新特征的名称</span><br><span class="hljs-string">    &quot;&quot;&quot;</span><br>    <br>    <span class="hljs-comment"># 提取所有需要带入计算的特征名称和特征</span><br>    <span class="hljs-keyword">if</span> keyCol != <span class="hljs-literal">None</span>:<br>        <span class="hljs-keyword">if</span> <span class="hljs-built_in">type</span>(keyCol) == <span class="hljs-built_in">str</span>:<br>            keyCol = [keyCol]    <br>        colName_temp = keyCol.copy()<br>        colName_temp.extend(col_cat)<br>        features = features[colName_temp]<br>    <span class="hljs-keyword">else</span>:<br>        features = features[col_cat]<br>    <br>    <span class="hljs-comment"># 定义CountVectorizer计算和TF-IDF计算过程</span><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">NLP_Stat</span>(<span class="hljs-params">features=features, </span><br><span class="hljs-params">                 col_cat=col_cat, </span><br><span class="hljs-params">                 keyCol=keyCol, </span><br><span class="hljs-params">                 countVec=countVec, </span><br><span class="hljs-params">                 tfidf=tfidf</span>):<br>        <span class="hljs-string">&quot;&quot;&quot;</span><br><span class="hljs-string">        CountVectorizer计算和TF-IDF计算函数</span><br><span class="hljs-string">        </span><br><span class="hljs-string">        参数和外层函数参数完全一致</span><br><span class="hljs-string">        返回结果需要注意，此处返回带有keyCol的衍生特征矩阵及特征名称</span><br><span class="hljs-string">        &quot;&quot;&quot;</span><br>        n = <span class="hljs-built_in">len</span>(keyCol)<br>        col_cat = [x +<span class="hljs-string">&#x27;_&#x27;</span> + <span class="hljs-string">&#x27;&amp;&#x27;</span>.join(keyCol) <span class="hljs-keyword">for</span> x <span class="hljs-keyword">in</span> col_cat]<br>        <span class="hljs-keyword">if</span> tfidf == <span class="hljs-literal">True</span>:<br>            <span class="hljs-comment"># 计算CountVectorizer</span><br>            features_new_cntv = features.groupby(keyCol).<span class="hljs-built_in">sum</span>().reset_index()<br>            colNames_new_cntv = keyCol.copy()<br>            colNames_new_cntv.extend([x + <span class="hljs-string">&#x27;_cntv&#x27;</span> <span class="hljs-keyword">for</span> x <span class="hljs-keyword">in</span> col_cat])<br>            features_new_cntv.columns = colNames_new_cntv<br>            <br>            <span class="hljs-comment"># 计算TF-IDF</span><br>            transformer = TfidfTransformer()<br>            tfidf = transformer.fit_transform(features_new_cntv.iloc[:, n: ]).toarray()<br>            colNames_new_tfv = [x + <span class="hljs-string">&#x27;_tfidf&#x27;</span> <span class="hljs-keyword">for</span> x <span class="hljs-keyword">in</span> col_cat]<br>            features_new_tfv = pd.DataFrame(tfidf, columns=colNames_new_tfv)<br>            <br>            <span class="hljs-keyword">if</span> countVec == <span class="hljs-literal">True</span>:<br>                features_new = pd.concat([features_new_cntv, features_new_tfv], axis=<span class="hljs-number">1</span>)<br>                colNames_new_cntv.extend(colNames_new_tfv)<br>                colNames_new = colNames_new_cntv<br>            <span class="hljs-keyword">else</span>:<br>                colNames_new = pd.concat([features_new_cntv[:, :n], features_new_tfv], axis=<span class="hljs-number">1</span>)<br>                features_new = keyCol + features_new_tfv<br>        <br>        <span class="hljs-comment"># 如果只计算CountVectorizer时</span><br>        <span class="hljs-keyword">elif</span> countVec == <span class="hljs-literal">True</span>:<br>            features_new_cntv = features.groupby(keyCol).<span class="hljs-built_in">sum</span>().reset_index()<br>            colNames_new_cntv = keyCol.copy()<br>            colNames_new_cntv.extend([x + <span class="hljs-string">&#x27;_cntv&#x27;</span> <span class="hljs-keyword">for</span> x <span class="hljs-keyword">in</span> col_cat])<br>            features_new_cntv.columns = colNames_new_cntv     <br>            <br>            colNames_new = colNames_new_cntv<br>            features_new = features_new_cntv<br>        <br>        <span class="hljs-keyword">return</span> features_new, colNames_new<br>    <br>    <span class="hljs-comment"># keyCol==None时对原始数据进行NLP特征衍生</span><br>    <span class="hljs-comment"># 此时无需进行CountVectorizer计算</span><br>    <span class="hljs-keyword">if</span> keyCol == <span class="hljs-literal">None</span>:<br>        <span class="hljs-keyword">if</span> tfidf == <span class="hljs-literal">True</span>:<br>            transformer = TfidfTransformer()<br>            tfidf = transformer.fit_transform(features).toarray()<br>            colNames_new = [x + <span class="hljs-string">&#x27;_tfidf&#x27;</span> <span class="hljs-keyword">for</span> x <span class="hljs-keyword">in</span> col_cat]<br>            features_new = pd.DataFrame(tfidf, columns=colNames_new)<br>    <br>    <span class="hljs-comment"># keyCol!=None时对分组汇总后的数据进行NLP特征衍生</span><br>    <span class="hljs-keyword">else</span>:<br>        n = <span class="hljs-built_in">len</span>(keyCol)<br>        <span class="hljs-comment"># 如果是依据单个特征取值进行分组</span><br>        <span class="hljs-keyword">if</span> n == <span class="hljs-number">1</span>:<br>            features_new, colNames_new = NLP_Stat()<br>            <span class="hljs-comment"># 将分组统计结果拼接回原矩阵</span><br>            features_new = pd.merge(features[keyCol[<span class="hljs-number">0</span>]], features_new, how=<span class="hljs-string">&#x27;left&#x27;</span>,on=keyCol[<span class="hljs-number">0</span>])<br>            features_new = features_new.iloc[:, n: ]<br>            colNames_new = features_new.columns<br>            <br>        <span class="hljs-comment"># 如果是多特征交叉分组</span><br>        <span class="hljs-keyword">else</span>:<br>            features_new, colNames_new = NLP_Stat()<br>            <span class="hljs-comment"># 在原数据集中生成合并主键</span><br>            features_key1, col1 = Multi_Cross_Combination(keyCol, features, OneHot=<span class="hljs-literal">False</span>)<br>            <span class="hljs-comment"># 在衍生特征数据集中创建合并主键</span><br>            features_key2, col2 = Multi_Cross_Combination(keyCol, features_new, OneHot=<span class="hljs-literal">False</span>)<br>            features_key2 = pd.concat([features_key2, features_new], axis=<span class="hljs-number">1</span>)<br>            <span class="hljs-comment"># 将分组统计结果拼接回原矩阵</span><br>            features_new = pd.merge(features_key1, features_key2, how=<span class="hljs-string">&#x27;left&#x27;</span>,on=col1)<br>            features_new = features_new.iloc[:, n+<span class="hljs-number">1</span>: ]<br>            colNames_new = features_new.columns<br>            <br>    <span class="hljs-keyword">return</span> features_new, colNames_new<br></code></pre></td></tr></table></figure>]]></content>
    
    
    <categories>
      
      <category>machine learning</category>
      
      <category>特征工程</category>
      
    </categories>
    
    
    <tags>
      
      <tag>machine learning</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>python实用算法</title>
    <link href="/posts/63689.html"/>
    <url>/posts/63689.html</url>
    
    <content type="html"><![CDATA[<hr><div class="note note-success">            <p>Python</p>          </div><h2 id="python实用算法技巧题一">Python实用算法技巧题一</h2><p>题：给定任意数组arr，以及正整数n，生成一个二维列表lst满足 <span class="math display">\[lst=\overbrace{arr\times arr\dots\timesarr}^{\text{共n项}}\]</span></p><p>实例：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-comment">#input </span><br>arr=[<span class="hljs-number">3</span>,<span class="hljs-number">2</span>,<span class="hljs-number">1</span>,<span class="hljs-number">0</span>],n=<span class="hljs-number">3</span><br><span class="hljs-comment">#output</span><br>lst = [[<span class="hljs-number">3</span>, <span class="hljs-number">3</span>, <span class="hljs-number">3</span>],<br> [<span class="hljs-number">3</span>, <span class="hljs-number">3</span>, <span class="hljs-number">2</span>],<br> [<span class="hljs-number">3</span>, <span class="hljs-number">3</span>, <span class="hljs-number">1</span>],<br> [<span class="hljs-number">3</span>, <span class="hljs-number">3</span>, <span class="hljs-number">0</span>],<br> [<span class="hljs-number">3</span>, <span class="hljs-number">2</span>, <span class="hljs-number">3</span>],<br> [<span class="hljs-number">3</span>, <span class="hljs-number">2</span>, <span class="hljs-number">2</span>],<br> [<span class="hljs-number">3</span>, <span class="hljs-number">2</span>, <span class="hljs-number">1</span>],<br> [<span class="hljs-number">3</span>, <span class="hljs-number">2</span>, <span class="hljs-number">0</span>],<br> [<span class="hljs-number">3</span>, <span class="hljs-number">1</span>, <span class="hljs-number">3</span>],<br> [<span class="hljs-number">3</span>, <span class="hljs-number">1</span>, <span class="hljs-number">2</span>],<br> [<span class="hljs-number">3</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>],<br> [<span class="hljs-number">3</span>, <span class="hljs-number">1</span>, <span class="hljs-number">0</span>],<br> [<span class="hljs-number">3</span>, <span class="hljs-number">0</span>, <span class="hljs-number">3</span>],<br> [<span class="hljs-number">3</span>, <span class="hljs-number">0</span>, <span class="hljs-number">2</span>],<br> [<span class="hljs-number">3</span>, <span class="hljs-number">0</span>, <span class="hljs-number">1</span>],<br> [<span class="hljs-number">3</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>],<br> [<span class="hljs-number">2</span>, <span class="hljs-number">3</span>, <span class="hljs-number">3</span>],<br> [<span class="hljs-number">2</span>, <span class="hljs-number">3</span>, <span class="hljs-number">2</span>],<br> [<span class="hljs-number">2</span>, <span class="hljs-number">3</span>, <span class="hljs-number">1</span>],<br> [<span class="hljs-number">2</span>, <span class="hljs-number">3</span>, <span class="hljs-number">0</span>],<br> [<span class="hljs-number">2</span>, <span class="hljs-number">2</span>, <span class="hljs-number">3</span>],<br> [<span class="hljs-number">2</span>, <span class="hljs-number">2</span>, <span class="hljs-number">2</span>],<br> [<span class="hljs-number">2</span>, <span class="hljs-number">2</span>, <span class="hljs-number">1</span>],<br> [<span class="hljs-number">2</span>, <span class="hljs-number">2</span>, <span class="hljs-number">0</span>],<br> [<span class="hljs-number">2</span>, <span class="hljs-number">1</span>, <span class="hljs-number">3</span>],<br> [<span class="hljs-number">2</span>, <span class="hljs-number">1</span>, <span class="hljs-number">2</span>],<br> [<span class="hljs-number">2</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>],<br> [<span class="hljs-number">2</span>, <span class="hljs-number">1</span>, <span class="hljs-number">0</span>],<br> [<span class="hljs-number">2</span>, <span class="hljs-number">0</span>, <span class="hljs-number">3</span>],<br> [<span class="hljs-number">2</span>, <span class="hljs-number">0</span>, <span class="hljs-number">2</span>],<br> [<span class="hljs-number">2</span>, <span class="hljs-number">0</span>, <span class="hljs-number">1</span>],<br> [<span class="hljs-number">2</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>],<br> [<span class="hljs-number">1</span>, <span class="hljs-number">3</span>, <span class="hljs-number">3</span>],<br> [<span class="hljs-number">1</span>, <span class="hljs-number">3</span>, <span class="hljs-number">2</span>],<br> [<span class="hljs-number">1</span>, <span class="hljs-number">3</span>, <span class="hljs-number">1</span>],<br> [<span class="hljs-number">1</span>, <span class="hljs-number">3</span>, <span class="hljs-number">0</span>],<br> [<span class="hljs-number">1</span>, <span class="hljs-number">2</span>, <span class="hljs-number">3</span>],<br> [<span class="hljs-number">1</span>, <span class="hljs-number">2</span>, <span class="hljs-number">2</span>],<br> [<span class="hljs-number">1</span>, <span class="hljs-number">2</span>, <span class="hljs-number">1</span>],<br> [<span class="hljs-number">1</span>, <span class="hljs-number">2</span>, <span class="hljs-number">0</span>],<br> [<span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">3</span>],<br> [<span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">2</span>],<br> [<span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>],<br> [<span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">0</span>],<br> [<span class="hljs-number">1</span>, <span class="hljs-number">0</span>, <span class="hljs-number">3</span>],<br> [<span class="hljs-number">1</span>, <span class="hljs-number">0</span>, <span class="hljs-number">2</span>],<br> [<span class="hljs-number">1</span>, <span class="hljs-number">0</span>, <span class="hljs-number">1</span>],<br> [<span class="hljs-number">1</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>],<br> [<span class="hljs-number">0</span>, <span class="hljs-number">3</span>, <span class="hljs-number">3</span>],<br> [<span class="hljs-number">0</span>, <span class="hljs-number">3</span>, <span class="hljs-number">2</span>],<br> [<span class="hljs-number">0</span>, <span class="hljs-number">3</span>, <span class="hljs-number">1</span>],<br> [<span class="hljs-number">0</span>, <span class="hljs-number">3</span>, <span class="hljs-number">0</span>],<br> [<span class="hljs-number">0</span>, <span class="hljs-number">2</span>, <span class="hljs-number">3</span>],<br> [<span class="hljs-number">0</span>, <span class="hljs-number">2</span>, <span class="hljs-number">2</span>],<br> [<span class="hljs-number">0</span>, <span class="hljs-number">2</span>, <span class="hljs-number">1</span>],<br> [<span class="hljs-number">0</span>, <span class="hljs-number">2</span>, <span class="hljs-number">0</span>],<br> [<span class="hljs-number">0</span>, <span class="hljs-number">1</span>, <span class="hljs-number">3</span>],<br> [<span class="hljs-number">0</span>, <span class="hljs-number">1</span>, <span class="hljs-number">2</span>],<br> [<span class="hljs-number">0</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>],<br> [<span class="hljs-number">0</span>, <span class="hljs-number">1</span>, <span class="hljs-number">0</span>],<br> [<span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">3</span>],<br> [<span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">2</span>],<br> [<span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">1</span>],<br> [<span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>]]<br></code></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">from</span> itertools <span class="hljs-keyword">import</span> product<br><span class="hljs-keyword">def</span> <span class="hljs-title function_">productn</span>(<span class="hljs-params">arr,n</span>):<br>    <span class="hljs-string">&quot;&quot;&quot;</span><br><span class="hljs-string">    任意维数的笛卡尔积</span><br><span class="hljs-string">    param arr:给定数组</span><br><span class="hljs-string">    param n:给定维数</span><br><span class="hljs-string">    return a list</span><br><span class="hljs-string">    &quot;&quot;&quot;</span><br>    m = <span class="hljs-number">1</span><br>    lst_dyn =arr<br>    lst_temp = []<br>    <span class="hljs-keyword">while</span> m&lt;n:<br>        lst_dyn = <span class="hljs-built_in">list</span>(product(lst_dyn,arr))<br>        <span class="hljs-keyword">if</span> m&gt;<span class="hljs-number">1</span>:<br>            <span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> lst_dyn:<br>                i_temp = <span class="hljs-built_in">list</span>(i[<span class="hljs-number">0</span>])<br>                i_temp.append(i[<span class="hljs-number">1</span>])<br>                lst_temp.append(i_temp)<br>            lst_dyn = lst_temp.copy()<br>            lst_temp = []<br>        m += <span class="hljs-number">1</span><br>    <span class="hljs-keyword">return</span> lst_dyn<br></code></pre></td></tr></table></figure>]]></content>
    
    
    <categories>
      
      <category>Python</category>
      
      <category>基础</category>
      
    </categories>
    
    
    <tags>
      
      <tag>Python</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>多变量特征衍生</title>
    <link href="/posts/31284.html"/>
    <url>/posts/31284.html</url>
    
    <content type="html"><![CDATA[<hr><div class="note note-success">            <p>机器学习 特征工程</p>          </div><h2 id="多变量特征衍生">多变量特征衍生</h2><h3 id="多变量交叉组合特征衍生">多变量交叉组合特征衍生</h3><p>所谓多变量的交叉组合，就是将多个特征的不同取值水平进行组合，基本过程如下所示：</p><p><img src="https://pjs-1312672154.cos.ap-shanghai.myqcloud.com/AjeRWLpfOQTwGHF.png"></p><p>该过程并不复杂，但需要注意的是，伴随着交叉组合特征数量的增加、以及每个特征取值水平增加，衍生出来的特征数量将呈指数级上涨趋势，例如3个包含两个分类水平的离散变量进行交叉组合时，将衍生出<span class="math inline">\(2^3=8\)</span>个特征，而如果是10个包含三个分类水平的离散变量进行交叉组合，则将衍生出<span class="math inline">\(3^{10}=59049\)</span>个特征。当然，特征数量的多并没有太大影响，但如果同时特征矩阵过于稀疏（有较多零值），则表示相同规模数据情况下包含了较少信息，而这也将极大程度影响后续建模过程。</p><p>通过上述极简示例不难看出，通过交叉组合衍生出来的新特征矩阵是极度稀疏的（即0值占绝大多数），并且不难发现，每一行在衍生的特征矩阵中其实只有一个值是1，其余值都是0（只有组合出了一种取值）。可以证明，在m个n分类特征的交叉组合过程中，假设总共有k条数据，则0值的占比为：<span class="math display">\[\frac{n^m*k-k}{n^m*k}=1-\frac{1}{n^m}\]</span>即如果是3个2分类水平的特征进行交叉组合衍生，则新的特征矩阵中0值占比为<span class="math inline">\(1-\frac{1}{8}=\frac{7}{8}=87.5\)</span>%；而如果是10个三分类变量进行交叉组合衍生，则新特征矩阵中0值占比为<span class="math inline">\(1-\frac{1}{3^{10}}=99.99831\)</span>%。尽管后续我们将介绍在海量特征中筛选有效特征的方法，但是在如此稀疏的矩阵中提取信息仍然还是一件非常困难的事情，因此往往我们并不会带入过多的特征进行交叉组合特征衍生。一般来说，如果有多个特征要进行交叉组合衍生，我们往往优先考虑两两组合进行交叉组合衍生，只有在人工判断是极为重要的特征情况下，才会考虑对其进行三个甚至更多的特征进行交叉组合衍生。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">def</span> <span class="hljs-title function_">Multi_Cross_Combination</span>(<span class="hljs-params">colNames, features, OneHot=<span class="hljs-literal">True</span></span>):<br>    <span class="hljs-string">&quot;&quot;&quot;</span><br><span class="hljs-string">    多变量组合交叉衍生</span><br><span class="hljs-string">    </span><br><span class="hljs-string">    :param colNames: 参与交叉衍生的列名称</span><br><span class="hljs-string">    :param features: 原始数据集</span><br><span class="hljs-string">    :param OneHot: 是否进行独热编码</span><br><span class="hljs-string">    </span><br><span class="hljs-string">    :return：交叉衍生后的新特征和新列名称</span><br><span class="hljs-string">    &quot;&quot;&quot;</span><br>    <br>    <br>    <span class="hljs-comment"># 创建组合特征</span><br>    colNames_new = <span class="hljs-string">&#x27;&amp;&#x27;</span>.join([<span class="hljs-built_in">str</span>(i) <span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> colNames])<br>    features_new = features[colNames[<span class="hljs-number">0</span>]].astype(<span class="hljs-string">&#x27;str&#x27;</span>)<br><br>    <span class="hljs-keyword">for</span> col <span class="hljs-keyword">in</span> colNames[<span class="hljs-number">1</span>:]:<br>        features_new = features_new + <span class="hljs-string">&#x27;&amp;&#x27;</span> + features[col].astype(<span class="hljs-string">&#x27;str&#x27;</span>) <br>    <br>    <span class="hljs-comment"># 将组合特征转化为DataFrame</span><br>    features_new = pd.DataFrame(features_new, columns=[colNames_new])<br>    <br>    <span class="hljs-comment"># 对新的特征列进行独热编码</span><br>    <span class="hljs-keyword">if</span> OneHot == <span class="hljs-literal">True</span>:<br>        enc = preprocessing.OneHotEncoder()<br>        enc.fit_transform(features_new)<br>        colNames_new = cate_colName(enc, [colNames_new], drop=<span class="hljs-literal">None</span>)<br>        features_new = pd.DataFrame(enc.fit_transform(features_new).toarray(), columns=colNames_new)<br>        <br>    <span class="hljs-keyword">return</span> features_new, colNames_new<br></code></pre></td></tr></table></figure><h3 id="多变量分组统计特征衍生">多变量分组统计特征衍生</h3><p>在双变量分组特征衍生时，我们是选择某个特征为KeyCol（关键特征），然后以KeyCol的不同取值为作为分组依据，计算其他特征的统计量。而在多变量分组特征衍生的过程中，我们将考虑采用不同离散变量的交叉组合后的取值分组依据，再进行分组统计量的计算。在双变量分组统计汇总下，基本计算过程如下：</p><p><img src="https://pjs-1312672154.cos.ap-shanghai.myqcloud.com/6YzMGo9uI1Dm8rc%20(1).png"></p><p>此处是以tenure和SeniorCitizen交叉组合后的结果作为分组依据，对MonthlyCharges进行分组汇总。除了分组的依据发生了变化外，分组统计过程和此前介绍的双变量分组统计特征衍生过程并没有任何差异。当然，从直观的结果上来看，多变量分组统计特征衍生能够更细粒度的呈现数据集信息，例如在以tenure作为分组依据统计MonthlyCharges时相当于计算不同入网时间用户的平均月消费金额（以mean为例），而如果是以tenure与SeniorCitizen交叉组合结果作为分组依据统计MonthlyCharges时，则相当于是计算不同入网时间、不同年龄段用户的平均消费金额，而往往更细粒度的信息展示就能够帮助模型达到更好的效果，因此，有限范围内的多变量分组统计特征衍生，是能达到更好的效果的。但同时需要注意的是，这种“细粒度”的呈现并不是越细粒度越好，我们知道，参与分组的交叉特征越多、分组也就越多，而在相同数据集下，分组越多、每一组的组内样本数量就越少，而在进行组内统计量计算时，如果组内样本数量太少，统计量往往就不具备代表性了，例如上述极简示例中ID为1的样本，在tenure和SeniorCitizen交叉分组后该样本所属分组只有一条样本，后续计算的统计量也没有任何“统计”方面的价值了。因此，多变量交叉分组也并不是越多变量越细粒度越好。一般来说，对于人工判断极重要的特征，可以考虑两个或三个特征进行交叉组合后分组。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br><span class="line">135</span><br><span class="line">136</span><br><span class="line">137</span><br><span class="line">138</span><br><span class="line">139</span><br><span class="line">140</span><br><span class="line">141</span><br><span class="line">142</span><br><span class="line">143</span><br><span class="line">144</span><br><span class="line">145</span><br><span class="line">146</span><br><span class="line">147</span><br><span class="line">148</span><br><span class="line">149</span><br><span class="line">150</span><br><span class="line">151</span><br><span class="line">152</span><br><span class="line">153</span><br><span class="line">154</span><br><span class="line">155</span><br><span class="line">156</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">def</span> <span class="hljs-title function_">Multi_Group_Statistics</span>(<span class="hljs-params">keyCol, </span><br><span class="hljs-params">                           features, </span><br><span class="hljs-params">                           col_num=<span class="hljs-literal">None</span>, </span><br><span class="hljs-params">                           col_cat=<span class="hljs-literal">None</span>, </span><br><span class="hljs-params">                           num_stat=[<span class="hljs-string">&#x27;mean&#x27;</span>, <span class="hljs-string">&#x27;var&#x27;</span>, <span class="hljs-string">&#x27;max&#x27;</span>, <span class="hljs-string">&#x27;min&#x27;</span>, <span class="hljs-string">&#x27;skew&#x27;</span>, <span class="hljs-string">&#x27;median&#x27;</span>], </span><br><span class="hljs-params">                           cat_stat=[<span class="hljs-string">&#x27;mean&#x27;</span>, <span class="hljs-string">&#x27;var&#x27;</span>, <span class="hljs-string">&#x27;max&#x27;</span>, <span class="hljs-string">&#x27;min&#x27;</span>, <span class="hljs-string">&#x27;median&#x27;</span>, <span class="hljs-string">&#x27;count&#x27;</span>, <span class="hljs-string">&#x27;nunique&#x27;</span>], </span><br><span class="hljs-params">                           quant=<span class="hljs-literal">True</span></span>):<br>    <span class="hljs-string">&quot;&quot;&quot;</span><br><span class="hljs-string">    多变量分组统计特征衍生函数</span><br><span class="hljs-string">    </span><br><span class="hljs-string">    :param keyCol: 分组参考的关键变量</span><br><span class="hljs-string">    :param features: 原始数据集</span><br><span class="hljs-string">    :param col_num: 参与衍生的连续型变量</span><br><span class="hljs-string">    :param col_cat: 参与衍生的离散型变量</span><br><span class="hljs-string">    :param num_stat: 连续变量分组统计量</span><br><span class="hljs-string">    :param cat_num: 离散变量分组统计量  </span><br><span class="hljs-string">    :param quant: 是否计算分位数  </span><br><span class="hljs-string"></span><br><span class="hljs-string">    :return：交叉衍生后的新特征和新特征的名称</span><br><span class="hljs-string">    &quot;&quot;&quot;</span><br>    <span class="hljs-comment"># 生成原数据合并的主键</span><br>    features_key1, col1 = Multi_Cross_Combination(keyCol, features, OneHot=<span class="hljs-literal">False</span>)<br>    <br>    <span class="hljs-comment"># 当输入的特征有连续型特征时</span><br>    <span class="hljs-keyword">if</span> col_num != <span class="hljs-literal">None</span>:<br>        aggs_num = &#123;&#125;<br>        colNames = col_num<br>        <br>        <span class="hljs-comment"># 创建agg方法所需字典</span><br>        <span class="hljs-keyword">for</span> col <span class="hljs-keyword">in</span> col_num:<br>            aggs_num[col] = num_stat <br>            <br>        <span class="hljs-comment"># 创建衍生特征名称列表</span><br>        cols_num = keyCol.copy()<br><br>        <span class="hljs-keyword">for</span> key <span class="hljs-keyword">in</span> aggs_num.keys():<br>            cols_num.extend([key+<span class="hljs-string">&#x27;_&#x27;</span>+col1+<span class="hljs-string">&#x27;_&#x27;</span>+stat <span class="hljs-keyword">for</span> stat <span class="hljs-keyword">in</span> aggs_num[key]])<br>            <br>        <span class="hljs-comment"># 创建衍生特征df</span><br>        features_num_new = features[col_num+keyCol].groupby(keyCol).agg(aggs_num).reset_index()<br>        features_num_new.columns = cols_num <br>        <br>        <span class="hljs-comment"># 生成主键</span><br>        features_key2, col2 = Multi_Cross_Combination(keyCol, features_num_new, OneHot=<span class="hljs-literal">False</span>)<br>        <br>        <span class="hljs-comment"># 创建包含合并主键的数据集</span><br>        features_num_new = pd.concat([features_key2, features_num_new], axis=<span class="hljs-number">1</span>)<br>        <br>        <br>        <span class="hljs-comment"># 当输入的特征有连续型也有离散型特征时</span><br>        <span class="hljs-keyword">if</span> col_cat != <span class="hljs-literal">None</span>:        <br>            aggs_cat = &#123;&#125;<br>            colNames = col_num + col_cat<br><br>            <span class="hljs-comment"># 创建agg方法所需字典</span><br>            <span class="hljs-keyword">for</span> col <span class="hljs-keyword">in</span> col_cat:<br>                aggs_cat[col] = cat_stat<br><br>            <span class="hljs-comment"># 创建衍生特征名称列表</span><br>            cols_cat = keyCol.copy()<br>            <br>            <span class="hljs-keyword">for</span> key <span class="hljs-keyword">in</span> aggs_cat.keys():<br>                cols_cat.extend([key+<span class="hljs-string">&#x27;_&#x27;</span>+col1+<span class="hljs-string">&#x27;_&#x27;</span>+stat <span class="hljs-keyword">for</span> stat <span class="hljs-keyword">in</span> aggs_cat[key]])    <br><br>            <span class="hljs-comment"># 创建衍生特征df</span><br>            features_cat_new = features[col_cat+keyCol].groupby(keyCol).agg(aggs_cat).reset_index()<br>            features_cat_new.columns = cols_cat<br>            <br>            <span class="hljs-comment"># 生成主键</span><br>            features_key3, col3 = Multi_Cross_Combination(keyCol, features_cat_new, OneHot=<span class="hljs-literal">False</span>)<br><br>            <span class="hljs-comment"># 创建包含合并主键的数据集</span><br>            features_cat_new = pd.concat([features_key3, features_cat_new], axis=<span class="hljs-number">1</span>)            <br>    <br>    <br>            <span class="hljs-comment"># 合并连续变量衍生结果与离散变量衍生结果</span><br>            <span class="hljs-comment"># 合并新的特征矩阵</span><br>            df_temp = pd.concat([features_num_new, features_cat_new], axis=<span class="hljs-number">1</span>)<br>            df_temp = df_temp.loc[:, ~df_temp.columns.duplicated()]<br>            <span class="hljs-comment"># 将新的特征矩阵与原始数据集合并</span><br>            features_new = pd.merge(features_key1, df_temp, how=<span class="hljs-string">&#x27;left&#x27;</span>,on=col1)<br>         <br>        <br>        <span class="hljs-comment"># 当只有连续变量时</span><br>        <span class="hljs-keyword">else</span>:<br>            <span class="hljs-comment"># merge连续变量衍生结果与原始数据，然后删除重复列</span><br>            features_new = pd.merge(features_key1, features_num_new, how=<span class="hljs-string">&#x27;left&#x27;</span>,on=col1)<br>            features_new = features_new.loc[:, ~features_new.columns.duplicated()]<br>    <br>    <span class="hljs-comment"># 当没有输入连续变量时</span><br>    <span class="hljs-keyword">else</span>:<br>        <span class="hljs-comment"># 但存在分类变量时，即只有分类变量时</span><br>        <span class="hljs-keyword">if</span> col_cat != <span class="hljs-literal">None</span>:<br>            aggs_cat = &#123;&#125;<br>            colNames = col_cat<br><br>            <span class="hljs-keyword">for</span> col <span class="hljs-keyword">in</span> col_cat:<br>                aggs_cat[col] = cat_stat<br><br>            cols_cat = keyCol.copy()<br>            <br>            <span class="hljs-keyword">for</span> key <span class="hljs-keyword">in</span> aggs_cat.keys():<br>                cols_cat.extend([key+<span class="hljs-string">&#x27;_&#x27;</span>+col1+<span class="hljs-string">&#x27;_&#x27;</span>+stat <span class="hljs-keyword">for</span> stat <span class="hljs-keyword">in</span> aggs_cat[key]])    <br><br>            features_cat_new = features[col_cat+keyCol].groupby(keyCol).agg(aggs_cat).reset_index()<br>            features_cat_new.columns = cols_cat            <br>             <br>            features_new = pd.merge(features_key1, features_cat_new, how=<span class="hljs-string">&#x27;left&#x27;</span>,on=col1)<br>            features_new = features_new.loc[:, ~features_new.columns.duplicated()]<br>    <br>    <span class="hljs-keyword">if</span> quant:<br>        <span class="hljs-comment"># 定义四分位计算函数</span><br>        <span class="hljs-keyword">def</span> <span class="hljs-title function_">q1</span>(<span class="hljs-params">x</span>):<br>            <span class="hljs-string">&quot;&quot;&quot;</span><br><span class="hljs-string">            下四分位数</span><br><span class="hljs-string">            &quot;&quot;&quot;</span><br>            <span class="hljs-keyword">return</span> x.quantile(<span class="hljs-number">0.25</span>)<br><br>        <span class="hljs-keyword">def</span> <span class="hljs-title function_">q2</span>(<span class="hljs-params">x</span>):<br>            <span class="hljs-string">&quot;&quot;&quot;</span><br><span class="hljs-string">            上四分位数</span><br><span class="hljs-string">            &quot;&quot;&quot;</span><br>            <span class="hljs-keyword">return</span> x.quantile(<span class="hljs-number">0.75</span>)<br><br>        aggs = &#123;&#125;<br>        <span class="hljs-keyword">for</span> col <span class="hljs-keyword">in</span> colNames:<br>            aggs[col] = [<span class="hljs-string">&#x27;q1&#x27;</span>, <span class="hljs-string">&#x27;q2&#x27;</span>]<br><br>        cols = keyCol.copy()<br>        <br>        <span class="hljs-keyword">for</span> key <span class="hljs-keyword">in</span> aggs.keys():<br>            cols.extend([key+<span class="hljs-string">&#x27;_&#x27;</span>+col1+<span class="hljs-string">&#x27;_&#x27;</span>+stat <span class="hljs-keyword">for</span> stat <span class="hljs-keyword">in</span> aggs[key]])    <br><br>        aggs = &#123;&#125;<br>        <span class="hljs-keyword">for</span> col <span class="hljs-keyword">in</span> colNames:<br>            aggs[col] = [q1, q2]    <br><br>        features_temp = features[colNames+keyCol].groupby(keyCol).agg(aggs).reset_index()<br>        features_temp.columns = cols<br>        features_new.drop(keyCol, axis=<span class="hljs-number">1</span>, inplace=<span class="hljs-literal">True</span>)<br>    <br>        <span class="hljs-comment"># 生成主键</span><br>        features_key4, col4 = Multi_Cross_Combination(keyCol, features_temp, OneHot=<span class="hljs-literal">False</span>)<br>        <br>        <span class="hljs-comment"># 创建包含合并主键的数据集</span><br>        features_temp = pd.concat([features_key4, features_temp], axis=<span class="hljs-number">1</span>)        <br><br>        <span class="hljs-comment"># 合并新特征矩阵</span><br>        features_new = pd.merge(features_new, features_temp, how=<span class="hljs-string">&#x27;left&#x27;</span>,on=col1)<br>        features_new = features_new.loc[:, ~features_new.columns.duplicated()]<br>  <br><br>    features_new.drop(keyCol+[col1], axis=<span class="hljs-number">1</span>, inplace=<span class="hljs-literal">True</span>)<br>    colNames_new = <span class="hljs-built_in">list</span>(features_new.columns)<br>    <br>    <span class="hljs-keyword">return</span> features_new, colNames_new<br></code></pre></td></tr></table></figure><h3 id="多变量高阶多项式特征衍生">多变量高阶多项式特征衍生</h3><p>多变量的多项式衍生过程并不复杂，无非就是在多项式计算时带入更多特征进行计算，而在进行多项式计算时并无本质区别，都是进行幂运算和交叉项计算。首先回顾双变量二阶多项式衍生过程：</p><p><img src="https://pjs-1312672154.cos.ap-shanghai.myqcloud.com/MKXbm2tpf1hFVRw.png"></p><p>此时如果我们增加参与多项式计算的特征，则有如下多变量多项式衍生过程：</p><p><img src="https://pjs-1312672154.cos.ap-shanghai.myqcloud.com/2Hunyt6rRGeKf1T.png"></p><p>当然，对于二阶多项式衍生，多变量的计算过程其实等价于多个双变量组合衍生的结果，例如上述X1、X2、X3三个变量的二阶多项式衍生，其实就等价于X1和X2、X1和X3（或X2、X3）两组二阶多项式衍生后去重的结果，因此如果是二阶多项式衍生的话，多变量的交叉组合结果完全等价于多变量中两两变量的二阶多项式衍生结果。但如果是三阶甚至是更高阶的多项式衍生，结果就会有所不同：</p><p><img src="https://pjs-1312672154.cos.ap-shanghai.myqcloud.com/Ser2R1dj975XlZC.png"></p><p><img src="https://pjs-1312672154.cos.ap-shanghai.myqcloud.com/mMhWDJAXUiPeubf.png"></p><p>不难发现，多变量的多项式衍生和多变量两两交叉多项式衍生的差异主要体现在多个变量的交叉项上，当然伴随着多项式阶数增加，多变量交叉项本身也会更多更复杂，二者差异也会更加明显。当然，多个特征的交叉组合乘积也同样会增加特征的表现，但同时也会增加伴随着多变量多项式衍生的变量数量增加以及阶数的增加，特征数量也会呈指数级增加趋势，并且衍生特征的取值也将变得非常不稳定，会伴随着阶数增加绝对值快速趋近于0或者一个非常大的数。因此，和此前的多变量特征衍生方法的使用场景类似，一般是针对人工判断的非常重要的特征可以考虑进行多变量的三阶甚至四阶多项式衍生。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">def</span> <span class="hljs-title function_">Muti_PolynomialFeatures</span>(<span class="hljs-params">colNames, degree, features</span>):<br>    <span class="hljs-string">&quot;&quot;&quot;</span><br><span class="hljs-string">    连续变量多变量多项式衍生函数</span><br><span class="hljs-string">    </span><br><span class="hljs-string">    :param colNames: 参与交叉衍生的列名称</span><br><span class="hljs-string">    :param degree: 多项式最高阶</span><br><span class="hljs-string">    :param features: 原始数据集</span><br><span class="hljs-string">    </span><br><span class="hljs-string">    :return：交叉衍生后的新特征和新列名称</span><br><span class="hljs-string">    &quot;&quot;&quot;</span><br>    <br>    <br>    <span class="hljs-comment"># 创建空列表容器</span><br>    colNames_new_l = []<br>    <br>    <span class="hljs-comment"># 计算带入多项式计算的特征数</span><br>    n = <span class="hljs-built_in">len</span>(colNames)<br>    <br>    <span class="hljs-comment"># 提取需要进行多项式衍生的特征</span><br>    features = features[colNames]<br>    <br>    <span class="hljs-comment"># 进行多项式特征组合</span><br>    array_new_temp = PolynomialFeatures(degree=degree, include_bias=<span class="hljs-literal">False</span>).fit_transform(features)<br>    <span class="hljs-comment"># 选取衍生的特征</span><br>    array_new_temp = array_new_temp[:, n:]<br>    <br>    <br>    <span class="hljs-comment"># 创建列名称列表</span><br>    deg = <span class="hljs-number">2</span><br>    <span class="hljs-keyword">while</span> deg &lt;= degree:<br>        m = <span class="hljs-number">1</span><br>        a1 = <span class="hljs-built_in">range</span>(deg, -<span class="hljs-number">1</span>, -<span class="hljs-number">1</span>)<br>        a2 = []<br>        <span class="hljs-keyword">while</span> m &lt; n:<br>            a1 = <span class="hljs-built_in">list</span>(product(a1, <span class="hljs-built_in">range</span>(deg, -<span class="hljs-number">1</span>, -<span class="hljs-number">1</span>)))<br>            <span class="hljs-keyword">if</span> m &gt; <span class="hljs-number">1</span>:<br>                <span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> a1:<br>                    i_temp = <span class="hljs-built_in">list</span>(i[<span class="hljs-number">0</span>])<br>                    i_temp.append(i[<span class="hljs-number">1</span>])<br>                    a2.append(i_temp)<br>                a1 = a2.copy()<br>                a2 = []    <br>            m += <span class="hljs-number">1</span><br>            <br>        a1 = np.array(a1)<br>        a3 = a1[a1.<span class="hljs-built_in">sum</span>(<span class="hljs-number">1</span>) == deg]<br>        <br>        <span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> a3:<br>            colNames_new_l.append(<span class="hljs-string">&#x27;&amp;&#x27;</span>.join(colNames) + <span class="hljs-string">&#x27;_&#x27;</span> + <span class="hljs-string">&#x27;&#x27;</span>.join([<span class="hljs-built_in">str</span>(i) <span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> i]))    <br>        <br>        deg += <span class="hljs-number">1</span><br>    <br>    <span class="hljs-comment"># 拼接新特征矩阵</span><br>    features_new = pd.DataFrame(array_new_temp, columns=colNames_new_l)<br>    colNames_new = colNames_new_l<br>    <span class="hljs-keyword">return</span> features_new, colNames_new<br></code></pre></td></tr></table></figure>]]></content>
    
    
    <categories>
      
      <category>machine learning</category>
      
      <category>特征工程</category>
      
    </categories>
    
    
    <tags>
      
      <tag>machine learning</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>双变量特征衍生</title>
    <link href="/posts/11354.html"/>
    <url>/posts/11354.html</url>
    
    <content type="html"><![CDATA[<hr><div class="note note-success">            <p>机器学习 特征工程</p>          </div><h2 id="特征衍生方法汇总">特征衍生方法汇总</h2><h3 id="批量自动化特征衍生">批量自动化特征衍生</h3><p><img src="https://pjs-1312672154.cos.ap-shanghai.myqcloud.com/gANubs8OwQ256Dd.png"></p><h4 id="双变量特征衍生">双变量特征衍生</h4><h5 id="四则运算特征衍生">四则运算特征衍生</h5><p>该过程非常简单，就是单纯的选取两列进行四则运算，基本过程如下：</p><p><img src="https://pjs-1312672154.cos.ap-shanghai.myqcloud.com/hZOarqcndsHDxlV.png"></p><p>该过程并不复杂，实际代码执行过程也只需要单独索引出两列然后进行四则运算即可。一般来说，四则运算特征衍生的使用场景较为固定，主要有以下三个：</p><ul><li>其一是用于创建业务补充字段：在某些数据集中，我们需要通过四则运算来创建具有明显业务含义的补充字段，例如在上述电信用户流失数据集中，我们可以通过将总消费金额除以用户入网时间，即可算出用户平均每月的消费金额，或者使用用户每月消费金额除以购买服务总数，则可算出每项服务的平均价格，这些字段有明确的业务含义，我们甚至可以将其视作原始字段;</li><li>其二，往往在特征衍生的所有工作结束后，我们会就这一系列衍生出来的新字段进行四则运算特征衍生，作为数据信息的一种补充；</li><li>其三，在某些极为特殊的字段创建过程中使用，例如竞赛中常用的黄金组合特征、流量平滑特征等，需要使用四则运算进行特征衍生。</li></ul><h5 id="交叉组合特征衍生">交叉组合特征衍生</h5><p>所谓交叉组合特征衍生，指的是不同分类变量不同取值水平之间进行交叉组合，从而创建新字段的过程。例如此前我们创建的老年且经济不独立的标识字段，实际上就是是否是老年人字段（SeniorCitizen）和是否经济独立字段（Dependents）两个字段交叉组合衍生过程中的一个：</p><p><img src="https://pjs-1312672154.cos.ap-shanghai.myqcloud.com/BiH4LtVTOjkWQuI.png"></p><p>不难看出，该计算流程并不复杂，需要注意的是，交叉组合后衍生的特征个数是参数交叉组合的特征的取值水平之积，因此交叉组合特征衍生一般只适用于取值水平较少的分类变量之间进行，若是分类变量或者取值水平较多的离散变量彼此之间进行交叉组合，则会导致衍生特征矩阵过于稀疏，从而无法为模型提供有效的训练信息。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">def</span> <span class="hljs-title function_">Binary_Cross_Combination</span>(<span class="hljs-params">colNames, features, OneHot=<span class="hljs-literal">True</span></span>):<br>    <span class="hljs-string">&quot;&quot;&quot;</span><br><span class="hljs-string">    分类变量两两组合交叉衍生函数</span><br><span class="hljs-string">    </span><br><span class="hljs-string">    :param colNames: 参与交叉衍生的列名称</span><br><span class="hljs-string">    :param features: 原始数据集</span><br><span class="hljs-string">    :param OneHot: 是否进行独热编码</span><br><span class="hljs-string">    </span><br><span class="hljs-string">    :return：交叉衍生后的新特征和新列名称</span><br><span class="hljs-string">    &quot;&quot;&quot;</span><br>    colNames_new_lst = []<br>    features_lst = []<br>    <span class="hljs-keyword">for</span> index,value <span class="hljs-keyword">in</span> <span class="hljs-built_in">enumerate</span>(colNames):<br>        <span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(index+<span class="hljs-number">1</span>,<span class="hljs-built_in">len</span>(colNames)):<br>            name_temp = value+<span class="hljs-string">&quot;&amp;&quot;</span>+colNames[i]<br>            colNames_new_lst.append(name_temp)<br>            series_temp = pd.Series(features[value].astype(<span class="hljs-built_in">str</span>)+<span class="hljs-string">&quot;&amp;&quot;</span>+features[colNames[i]].astype(<span class="hljs-built_in">str</span>),name=name_temp)<br>            features_lst.append(series_temp)<br>    features_res = pd.concat(features_lst,axis=<span class="hljs-number">1</span>)<br>    <span class="hljs-keyword">if</span> OneHot==<span class="hljs-literal">True</span>:<br>        enc = preprocessing.OneHotEncoder()<br>        df_arr = enc.fit_transform(features_res).toarray()<br>        features_res = pd.DataFrame(df_arr,columns=cate_colName(enc,colNames_new_lst,drop=<span class="hljs-literal">None</span>))<br>    <span class="hljs-keyword">return</span> features_res,colNames_new_lst<br></code></pre></td></tr></table></figure><p>需要注意的是对于类别数多的分类变量，交叉组合特征衍生产生的特征会增长很快。在操作前应该初步判断产生新特征的个数。</p><h5 id="分组统计特征衍生">分组统计特征衍生</h5><p>所谓分组统计，顾名思义，就是A特征根据B特征的不同取值进行分组统计，统计量可以是均值、方差等针对连续变量的统计指标，也可以是众数、分位数等针对离散变量的统计指标，例如我们可以计算不同入网时间用户的平均月消费金额、消费金额最大值、消费金额最小值等，基本过程如下：</p><p><img src="https://pjs-1312672154.cos.ap-shanghai.myqcloud.com/6YzMGo9uI1Dm8rc.png"></p><p>同样，该过程也并不复杂，在实际执行分组统计特征衍生的过程中（假设是A特征根据B特征的不同取值进行分组统计），有以下几点需要注意：</p><ul><li><p>首先，一般来说A特征可以是离散变量也可以是连续变量，而B特征必须是离散变量，且最好是一些取值较多的离散变量（或者固定取值的连续变量），例如本数据集中的tenure字段，总共有73个取值。主要原因是如果B特征取值较少，则在衍生的特征矩阵中会出现大量的重复的行；</p></li><li><p>其次，在实际计算A的分组统计量时，可以不局限于连续特征只用连续变量的统计量、离散特征只用离散的统计量，完全可以交叉使用，例如A是离散变量，我们也可以分组统计其均值、方差、偏度、峰度等，连续变量也可以统计众数、分位数等。很多时候，更多的信息组合有可能会带来更多的可能性；</p></li><li><p>其三，有的时候分组统计还可以用于多表连接的场景，例如假设现在给出的数据集不是每个用户的汇总统计结果，而是每个用户在过去的一段时间内的行为记录，则我们可以根据用户ID对其进行分组统计汇总：</p></li></ul><p><img src="https://pjs-1312672154.cos.ap-shanghai.myqcloud.com/mE9hBtyaHpOIlvR.png"></p><ul><li>其四，很多时候我们还会考虑进一步围绕特征A和分组统计结果进行再一次的四则运算特征衍生，例如用月度消费金额减去分组均值，则可以比较每一位用户与相同时间入网用户的消费平均水平的差异，围绕衍生特征再次进行衍生，我们将其称为统计演变特征，也是分组汇总衍生特征的重要应用场景：</li></ul><p><img src="https://pjs-1312672154.cos.ap-shanghai.myqcloud.com/Z1bgnjBui7VT4dI.png"></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">def</span> <span class="hljs-title function_">Binary_Group_Statistics</span>(<span class="hljs-params">keyCol, </span><br><span class="hljs-params">                            features, </span><br><span class="hljs-params">                            col_num=<span class="hljs-literal">None</span>, </span><br><span class="hljs-params">                            col_cat=<span class="hljs-literal">None</span>, </span><br><span class="hljs-params">                            num_stat=[<span class="hljs-string">&#x27;mean&#x27;</span>, <span class="hljs-string">&#x27;var&#x27;</span>, <span class="hljs-string">&#x27;max&#x27;</span>, <span class="hljs-string">&#x27;min&#x27;</span>, <span class="hljs-string">&#x27;skew&#x27;</span>, <span class="hljs-string">&#x27;median&#x27;</span>], </span><br><span class="hljs-params">                            cat_stat=[<span class="hljs-string">&#x27;mean&#x27;</span>, <span class="hljs-string">&#x27;var&#x27;</span>, <span class="hljs-string">&#x27;max&#x27;</span>, <span class="hljs-string">&#x27;min&#x27;</span>, <span class="hljs-string">&#x27;median&#x27;</span>, <span class="hljs-string">&#x27;count&#x27;</span>, <span class="hljs-string">&#x27;nunique&#x27;</span>], </span><br><span class="hljs-params">                            quant=<span class="hljs-literal">True</span></span>):<br>    <span class="hljs-string">&quot;&quot;&quot;</span><br><span class="hljs-string">    双变量分组统计特征衍生函数</span><br><span class="hljs-string">    </span><br><span class="hljs-string">    :param keyCol: 分组参考的关键变量</span><br><span class="hljs-string">    :param features: 原始数据集</span><br><span class="hljs-string">    :param col_num: 参与衍生的连续型变量</span><br><span class="hljs-string">    :param col_cat: 参与衍生的离散型变量</span><br><span class="hljs-string">    :param num_stat: 连续变量分组统计量</span><br><span class="hljs-string">    :param cat_num: 离散变量分组统计量  </span><br><span class="hljs-string">    :param quant: 是否计算分位数  </span><br><span class="hljs-string"></span><br><span class="hljs-string">    :return：交叉衍生后的新特征和新特征的名称</span><br><span class="hljs-string">    &quot;&quot;&quot;</span><br>    aggs = &#123;&#125;<br>    colName_new = []<br>    <span class="hljs-keyword">if</span> col_num != <span class="hljs-literal">None</span>:<br>        <span class="hljs-keyword">for</span> col_n <span class="hljs-keyword">in</span> col_num:<br>            aggs[col_n] = num_stat<br>            colName_new.extend([col_n+<span class="hljs-string">&quot;_&quot;</span>+keyCol+<span class="hljs-string">&quot;_&quot;</span>+i <span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> num_stat])<br>        <span class="hljs-keyword">if</span> col_cat != <span class="hljs-literal">None</span>:<br>            <span class="hljs-keyword">for</span> col_c <span class="hljs-keyword">in</span> col_cat:<br>                aggs[col_c] = cat_stat<br>                colName_new.extend([col_c+<span class="hljs-string">&quot;_&quot;</span>+keyCol+<span class="hljs-string">&quot;_&quot;</span>+i <span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> cat_stat])<br>            colName = col_num+col_cat<br>            features_new = features.groupby(keyCol).agg(aggs).reset_index()<br>            features_res = pd.merge(features,features_new,how=<span class="hljs-string">&quot;left&quot;</span>,on=keyCol)<br>            features_res.columns = [keyCol]+colName+colName_new<br>        <span class="hljs-keyword">else</span>:<br>            colName = col_num<br>            features_new = features.groupby(keyCol).agg(aggs).reset_index()<br>            features_res = pd.merge(features,features_new,how=<span class="hljs-string">&quot;left&quot;</span>,on=keyCol)<br>            features_res.columns = [keyCol]+colName+colName_new<br>    <span class="hljs-keyword">else</span>:<br>        <span class="hljs-keyword">if</span> col_cat != <span class="hljs-literal">None</span>:<br>            <span class="hljs-keyword">for</span> col_c <span class="hljs-keyword">in</span> col_cat:<br>                aggs[col_c] = cat_stat<br>                colName_new.extend([col_c+<span class="hljs-string">&quot;_&quot;</span>+keyCol+<span class="hljs-string">&quot;_&quot;</span>+i <span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> cat_stat])<br>            colName = col_cat<br>            features_new = features.groupby(keyCol).agg(aggs).reset_index()<br>            features_res = pd.merge(features,features_new,how=<span class="hljs-string">&quot;left&quot;</span>,on=keyCol)<br>            features_res.columns = [keyCol]+colName+colName_new<br>    <span class="hljs-keyword">if</span> quant == <span class="hljs-literal">True</span>:<br>        aggs_temp = &#123;&#125;<br>        colName_new_temp = []<br>        <span class="hljs-keyword">def</span> <span class="hljs-title function_">q1</span>(<span class="hljs-params">x</span>):<br>            <span class="hljs-string">&quot;&quot;&quot;下四分位数&quot;&quot;&quot;</span><br>            <span class="hljs-keyword">return</span> x.quantile(<span class="hljs-number">0.25</span>)<br>        <span class="hljs-keyword">def</span> <span class="hljs-title function_">q2</span>(<span class="hljs-params">x</span>):<br>            <span class="hljs-string">&quot;&quot;&quot;上四分位数&quot;&quot;&quot;</span><br>            <span class="hljs-keyword">return</span> x.quantile(<span class="hljs-number">0.75</span>)<br>        <span class="hljs-keyword">for</span> col <span class="hljs-keyword">in</span> colName:<br>            aggs_temp[col] = [q1,q2]<br>            colName_new_temp.extend([col+<span class="hljs-string">&quot;_&quot;</span>+keyCol+<span class="hljs-string">&quot;_&quot;</span>+i <span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> [<span class="hljs-string">&quot;q1&quot;</span>,<span class="hljs-string">&quot;q2&quot;</span>]])<br>        features_new = features.groupby(keyCol).agg(aggs_temp).reset_index()<br>        features_quan = pd.merge(features_res,features_new,how=<span class="hljs-string">&quot;left&quot;</span>,on=keyCol)<br>        features_quan.columns = [keyCol]+colName+colName_new+colName_new_temp<br>        features_res = features_quan<br>    <span class="hljs-keyword">return</span> features_res,features_res.columns.tolist()<br></code></pre></td></tr></table></figure><h5 id="多项式特征衍生">多项式特征衍生</h5><p>双变量的多项式衍生会比单变量多项式衍生更有效果，该过程并不复杂，只是在单变量多项式衍生基础上增加了交叉项的计算，例如X1和X2都是某连续变量，在进行双变量二阶多项式衍生时计算过程如下：</p><p><img src="https://pjs-1312672154.cos.ap-shanghai.myqcloud.com/MKXbm2tpf1hFVRw.png"></p><p>更高阶的多项式衍生过程也依此类推。在实际使用过程中，有以下几点注意事项：</p><ul><li><p>一般来说双变量多项式衍生只适用于两个连续变量之间，一个连续变量一个离散变量或者两个离散变量进行多项式衍生意义不大（除非类似tenure字段，离散字段带有非常多不同的取值）；</p></li><li><p>在选取特征进行多项式衍生的过程中，往往我们不会随意组合连续变量来进行多项式衍生，而是只针对我们判断非常重要的特征来进行多项式衍生。就这点而言，多项式衍生和四则运算衍生非常类似，其使用场景背后的基本思路也完全一致：强化重要特征的表现形式；</p></li><li><p>关于衍生多少阶，一般来说伴随着多项式阶数的增加，各列数值也会呈现指数级递增（或递减），因此往往我们只会衍生3阶左右，极少数情况会衍生5-10阶。而伴随着多项式阶数的增加，也需要配合一些手段来消除数值绝对值爆炸或者衰减所造成的影响，例如对数据进行归一化处理等；</p></li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">def</span> <span class="hljs-title function_">Binary_PolynomialFeatures</span>(<span class="hljs-params">colNames, degree,features</span>):<br>    <span class="hljs-string">&quot;&quot;&quot;</span><br><span class="hljs-string">    连续变量两变量多项式衍生函数</span><br><span class="hljs-string">    </span><br><span class="hljs-string">    :param colNames: 参与交叉衍生的列名称</span><br><span class="hljs-string">    :param degree: 多项式最高阶</span><br><span class="hljs-string">    :param features: 原始数据集</span><br><span class="hljs-string">    </span><br><span class="hljs-string">    :return：交叉衍生后的新特征和新列名称</span><br><span class="hljs-string">    &quot;&quot;&quot;</span><br>    features_lst = []<br>    colName_new = []<br>    <span class="hljs-keyword">for</span> index,value <span class="hljs-keyword">in</span> <span class="hljs-built_in">enumerate</span>(colNames):<br>        <span class="hljs-keyword">for</span> v <span class="hljs-keyword">in</span> colNames[index+<span class="hljs-number">1</span>:]:<br>            colName_temp = [value,v]<br>            features_temp = preprocessing.PolynomialFeatures(degree=degree,include_bias=<span class="hljs-literal">False</span>).fit_transform(features[colName_temp])<br>            features_lst.append(pd.DataFrame(features_temp[:,<span class="hljs-built_in">len</span>(colNames):]))<br>            <span class="hljs-keyword">for</span> deg <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(<span class="hljs-number">2</span>,degree+<span class="hljs-number">1</span>):<br>                <span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(deg+<span class="hljs-number">1</span>):<br>                    colName_new.append(colName_temp[<span class="hljs-number">0</span>]+<span class="hljs-string">&quot;**&quot;</span>+<span class="hljs-built_in">str</span>(deg-i)+<span class="hljs-string">&quot; &quot;</span>+colName_temp[<span class="hljs-number">1</span>]+<span class="hljs-string">&quot;**&quot;</span>+<span class="hljs-built_in">str</span>(i))<br>    features_new = pd.concat(features_lst,axis=<span class="hljs-number">1</span>)<br>    features_new.columns = colName_new<br>    <span class="hljs-keyword">return</span> features_new,features_new.columns.tolist()<br></code></pre></td></tr></table></figure><h5 id="统计演变特征">统计演变特征</h5><ul><li>二阶特征衍生</li></ul><p>一种很自然的联想，是当我们已经完成了一些特征衍生后，还会考虑以衍生特征为基础，进一步进行特征衍生，这也就是所谓的二阶特征衍生（注意区分二阶多项式衍生）。当然这个过程可以无限重复，这也是此前讨论为何会出现无限特征的根本原因之一。不过，在大多数情况下，二阶甚至是更高阶的特征衍生（以下简称高阶特征衍生）往往伴随着严重的信息衰减，大多数高阶衍生出来的特征其本身的有效性也将急剧下降，外加高阶特征衍生是在已有的大量衍生出来的一阶特征基础上再进行衍生，其计算过程往往需要消耗巨大的计算量，外加需要从一系列高阶衍生特征中挑选出极个别有用的特征也较为繁琐，因此，高阶衍生往往性价比较低，除非特殊情况，否则并不建议在广泛特征基础上进行大量高阶特征衍生的尝试。</p><ul><li>统计演变特征</li></ul><p>当然，尽管并不建议手动进行尝试，但在长期的实践过程中，人们还是总结出某些高阶衍生特征（主要是二阶衍生特征）在很多情况下都能起到很好的效果。需要注意的是，这里的着重指的是一些特征，而不是特征衍生的策略。在这些普遍有效的高阶特征中，最著名的就是所谓的统计演变特征，这些特征由原始特征和分组统计特征、或分组统计特征彼此之间交叉衍生而来，在很多算法竞赛和企业应用中，都被证明了有较高的尝试价值。</p><h6 id="流量平滑特征">流量平滑特征</h6><p>该特征通过分组键除以分组汇总均值（中位数）后的特征计算而来。当然因为是进行除法运算，为了避免分母为零的情况，我们可以在分母位上加上一个很小的数。</p><h6 id="黄金组合特征">黄金组合特征</h6><p>所谓黄金组合特征，就是简单的利用分组键特征减去分组汇总均值后的特征计算得出。</p><h6 id="组内归一化特征">组内归一化特征</h6><p>所谓组内归一化特征，指的是用分组键特征减去分组汇总均值后的特征，再除以分组汇总标准差后的特征，其计算过程非常类似于归一化过程，即某列数据减去该列的均值再除以该列的标准差，这也是组内归一化名称的由来。</p><h6 id="gap特征">Gap特征</h6><p>Gap特征通过分组汇总后的上四分位数-下四分位数计算得出。</p><h6 id="数据倾斜">数据倾斜</h6><p>我们还可以通过中位数和均值的比较来计算组内的数据倾斜情况：当均值大于中位数时，数据呈现正倾斜，均值小于中位数时，数据正弦负倾斜。当然衡量倾斜的方法有两种，其一是计算差值，其二则是计算比值。</p><h6 id="变异系数">变异系数</h6><p>变异系数是通过分组统计的标准差除以均值，变异系数计算的是离中趋势，变异系数越大、说明数据离散程度越高。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">def</span> <span class="hljs-title function_">Group_Statistics_Extension</span>(<span class="hljs-params">colNames, keyCol, features</span>):<br>    <span class="hljs-string">&quot;&quot;&quot;</span><br><span class="hljs-string">    双变量分组统计二阶特征衍生函数</span><br><span class="hljs-string">    </span><br><span class="hljs-string">    :param colNames: 参与衍生的特征</span><br><span class="hljs-string">    :param keyCol: 分组参考的关键变量</span><br><span class="hljs-string">    :param features: 原始数据集</span><br><span class="hljs-string">    </span><br><span class="hljs-string">    :return：交叉衍生后的新特征和新列名称</span><br><span class="hljs-string">    &quot;&quot;&quot;</span><br>    <br>    <span class="hljs-comment"># 定义四分位计算函数</span><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">q1</span>(<span class="hljs-params">x</span>):<br>        <span class="hljs-string">&quot;&quot;&quot;</span><br><span class="hljs-string">        下四分位数</span><br><span class="hljs-string">        &quot;&quot;&quot;</span><br>        <span class="hljs-keyword">return</span> x.quantile(<span class="hljs-number">0.25</span>)<br><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">q2</span>(<span class="hljs-params">x</span>):<br>        <span class="hljs-string">&quot;&quot;&quot;</span><br><span class="hljs-string">        上四分位数</span><br><span class="hljs-string">        &quot;&quot;&quot;</span><br>        <span class="hljs-keyword">return</span> x.quantile(<span class="hljs-number">0.75</span>)   <br>    <br>    <span class="hljs-comment"># 一阶特征衍生</span><br>    <span class="hljs-comment"># 先定义用于生成列名称的aggs</span><br>    aggs = &#123;&#125;    <br>    <span class="hljs-keyword">for</span> col <span class="hljs-keyword">in</span> colNames:<br>        aggs[col] = [<span class="hljs-string">&#x27;mean&#x27;</span>, <span class="hljs-string">&#x27;var&#x27;</span>, <span class="hljs-string">&#x27;median&#x27;</span>, <span class="hljs-string">&#x27;q1&#x27;</span>, <span class="hljs-string">&#x27;q2&#x27;</span>]       <br>    cols = [keyCol]<br>    <span class="hljs-keyword">for</span> key <span class="hljs-keyword">in</span> aggs.keys():<br>        cols.extend([key+<span class="hljs-string">&#x27;_&#x27;</span>+keyCol+<span class="hljs-string">&#x27;_&#x27;</span>+stat <span class="hljs-keyword">for</span> stat <span class="hljs-keyword">in</span> aggs[key]])<br><br>    <span class="hljs-comment"># 再定义用于进行分组汇总的aggs</span><br>    aggs = &#123;&#125;   <br>    <span class="hljs-keyword">for</span> col <span class="hljs-keyword">in</span> colNames:<br>        aggs[col] = [<span class="hljs-string">&#x27;mean&#x27;</span>, <span class="hljs-string">&#x27;var&#x27;</span>, <span class="hljs-string">&#x27;median&#x27;</span>, q1, q2] <br>           <br>    features_new = features[colNames+[keyCol]].groupby(keyCol).agg(aggs).reset_index()<br>    features_new.columns = cols<br>             <br>    features_new = pd.merge(features[keyCol], features_new, how=<span class="hljs-string">&#x27;left&#x27;</span>,on=keyCol)<br>    features_new.loc[:, ~features_new.columns.duplicated()]<br>    colNames_new = cols<br>    colNames_new.remove(keyCol)<br>    col1 = colNames_new.copy()<br>    <br>    <span class="hljs-comment"># 二阶特征衍生</span><br>    <span class="hljs-comment"># 流量平滑特征</span><br>    <span class="hljs-keyword">for</span> col_temp <span class="hljs-keyword">in</span> colNames:<br>        col = col_temp+<span class="hljs-string">&#x27;_&#x27;</span>+keyCol+<span class="hljs-string">&#x27;_&#x27;</span>+<span class="hljs-string">&#x27;mean&#x27;</span><br>        features_new[col_temp+<span class="hljs-string">&#x27;_dive1_&#x27;</span>+col] = features_new[keyCol] / (features_new[col] + <span class="hljs-number">1e-5</span>)<br>        colNames_new.append(col_temp+<span class="hljs-string">&#x27;_dive1_&#x27;</span>+col)<br>        col = col_temp+<span class="hljs-string">&#x27;_&#x27;</span>+keyCol+<span class="hljs-string">&#x27;_&#x27;</span>+<span class="hljs-string">&#x27;median&#x27;</span><br>        features_new[col_temp+<span class="hljs-string">&#x27;_dive2_&#x27;</span>+col] = features_new[keyCol] / (features_new[col] + <span class="hljs-number">1e-5</span>)<br>        colNames_new.append(col_temp+<span class="hljs-string">&#x27;_dive2_&#x27;</span>+col)<br>        <br>    <span class="hljs-comment"># 黄金组合特征</span><br>    <span class="hljs-keyword">for</span> col_temp <span class="hljs-keyword">in</span> colNames:<br>        col = col_temp+<span class="hljs-string">&#x27;_&#x27;</span>+keyCol+<span class="hljs-string">&#x27;_&#x27;</span>+<span class="hljs-string">&#x27;mean&#x27;</span><br>        features_new[col_temp+<span class="hljs-string">&#x27;_minus1_&#x27;</span>+col] = features_new[keyCol] - features_new[col]<br>        colNames_new.append(col_temp+<span class="hljs-string">&#x27;_minus1_&#x27;</span>+col)<br>        col = col_temp+<span class="hljs-string">&#x27;_&#x27;</span>+keyCol+<span class="hljs-string">&#x27;_&#x27;</span>+<span class="hljs-string">&#x27;median&#x27;</span><br>        features_new[col_temp+<span class="hljs-string">&#x27;_minus2_&#x27;</span>+col] = features_new[keyCol] - features_new[col] <br>        colNames_new.append(col_temp+<span class="hljs-string">&#x27;_minus2_&#x27;</span>+col)<br>        <br>    <span class="hljs-comment"># 组内归一化特征</span><br>    <span class="hljs-keyword">for</span> col_temp <span class="hljs-keyword">in</span> colNames:<br>        col_mean = col_temp+<span class="hljs-string">&#x27;_&#x27;</span>+keyCol+<span class="hljs-string">&#x27;_&#x27;</span>+<span class="hljs-string">&#x27;mean&#x27;</span><br>        col_var = col_temp+<span class="hljs-string">&#x27;_&#x27;</span>+keyCol+<span class="hljs-string">&#x27;_&#x27;</span>+<span class="hljs-string">&#x27;var&#x27;</span><br>        features_new[col_temp+<span class="hljs-string">&#x27;_norm_&#x27;</span>+keyCol] = (features_new[keyCol] - features_new[col_mean]) / (np.sqrt(features_new[col_var]) + <span class="hljs-number">1e-5</span>)      <br>        colNames_new.append(col_temp+<span class="hljs-string">&#x27;_norm_&#x27;</span>+keyCol)<br>    <br>    <span class="hljs-comment"># Gap特征</span><br>    <span class="hljs-keyword">for</span> col_temp <span class="hljs-keyword">in</span> colNames:<br>        col_q1 = col_temp+<span class="hljs-string">&#x27;_&#x27;</span>+keyCol+<span class="hljs-string">&#x27;_&#x27;</span>+<span class="hljs-string">&#x27;q1&#x27;</span><br>        col_q2 = col_temp+<span class="hljs-string">&#x27;_&#x27;</span>+keyCol+<span class="hljs-string">&#x27;_&#x27;</span>+<span class="hljs-string">&#x27;q2&#x27;</span><br>        features_new[col_temp+<span class="hljs-string">&#x27;_gap_&#x27;</span>+keyCol] = features_new[col_q2] - features_new[col_q1]  <br>        colNames_new.append(col_temp+<span class="hljs-string">&#x27;_gap_&#x27;</span>+keyCol)<br>        <br>    <span class="hljs-comment"># 数据倾斜特征</span><br>    <span class="hljs-keyword">for</span> col_temp <span class="hljs-keyword">in</span> colNames:<br>        col_mean = col_temp+<span class="hljs-string">&#x27;_&#x27;</span>+keyCol+<span class="hljs-string">&#x27;_&#x27;</span>+<span class="hljs-string">&#x27;mean&#x27;</span><br>        col_median = col_temp+<span class="hljs-string">&#x27;_&#x27;</span>+keyCol+<span class="hljs-string">&#x27;_&#x27;</span>+<span class="hljs-string">&#x27;median&#x27;</span><br>        features_new[col_temp+<span class="hljs-string">&#x27;_mag1_&#x27;</span>+keyCol] = features_new[col_median] - features_new[col_mean]    <br>        colNames_new.append(col_temp+<span class="hljs-string">&#x27;_mag1_&#x27;</span>+keyCol)<br>        features_new[col_temp+<span class="hljs-string">&#x27;_mag2_&#x27;</span>+keyCol] = features_new[col_median] / (features_new[col_mean] + <span class="hljs-number">1e-5</span>)<br>        colNames_new.append(col_temp+<span class="hljs-string">&#x27;_mag2_&#x27;</span>+keyCol)<br>        <br>    <span class="hljs-comment"># 变异系数</span><br>    <span class="hljs-keyword">for</span> col_temp <span class="hljs-keyword">in</span> colNames:<br>        col_mean = col_temp+<span class="hljs-string">&#x27;_&#x27;</span>+keyCol+<span class="hljs-string">&#x27;_&#x27;</span>+<span class="hljs-string">&#x27;mean&#x27;</span><br>        col_var = col_temp+<span class="hljs-string">&#x27;_&#x27;</span>+keyCol+<span class="hljs-string">&#x27;_&#x27;</span>+<span class="hljs-string">&#x27;var&#x27;</span><br>        features_new[col_temp+<span class="hljs-string">&#x27;_cv_&#x27;</span>+keyCol] = np.sqrt(features_new[col_var]) / (features_new[col_mean] + <span class="hljs-number">1e-5</span>)<br>        colNames_new.append(col_temp+<span class="hljs-string">&#x27;_cv_&#x27;</span>+keyCol)<br><br>    features_new.drop([keyCol], axis=<span class="hljs-number">1</span>, inplace=<span class="hljs-literal">True</span>)<br>    features_new.drop(col1, axis=<span class="hljs-number">1</span>, inplace=<span class="hljs-literal">True</span>)<br>    colNames_new = <span class="hljs-built_in">list</span>(features_new.columns)<br>    <br>    <span class="hljs-keyword">return</span> features_new, colNames_new<br></code></pre></td></tr></table></figure>]]></content>
    
    
    <categories>
      
      <category>machine learning</category>
      
      <category>特征工程</category>
      
    </categories>
    
    
    <tags>
      
      <tag>machine learning</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>单变量特征衍生</title>
    <link href="/posts/36920.html"/>
    <url>/posts/36920.html</url>
    
    <content type="html"><![CDATA[<hr><div class="note note-success">            <p>机器学习 特征工程</p>          </div><h2 id="特征衍生方法汇总">特征衍生方法汇总</h2><h3 id="批量自动化特征衍生">批量自动化特征衍生</h3><p><img src="https://pjs-1312672154.cos.ap-shanghai.myqcloud.com/gANubs8OwQ256Dd.png"></p><h3 id="单变量特征衍生">单变量特征衍生</h3><h4 id="数据重编码特征衍生">数据重编码特征衍生</h4><ul><li>离散字段数据重编码方式<ul><li>自然数编码/字典编码</li><li>独热编码/哑变量编码</li></ul></li><li>连续字段数据重编码方式<ul><li>标准化：0-1标准化/Z-score标准化</li><li>离散化：等距分箱/等频分箱/聚类分箱</li></ul></li></ul><h5 id="离散字段数据重编码方式">离散字段数据重编码方式</h5><ol type="1"><li>自然数编码</li></ol><p>我们可以使用自然数编码将分类变量转化为自然数包括-1.有时候我们却不能直接的使用自然数编码，那是因为在此过程中会将特征取值强制加入了顺序.</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">from</span> sklearn <span class="hljs-keyword">import</span> preprocessing<br>enc = preprocessing.OrdinalEncoder()<br>enc.fit(X) <span class="hljs-comment">#X : array-like of shape (n_samples, n_features).The data to determine the categories of each feature.</span><br>enc.transform(X)<br></code></pre></td></tr></table></figure><p>我们可以调用评估器的如下属性来查看对应的映射关系</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs python">enc.catrgories_<br></code></pre></td></tr></table></figure><p>对于该属性的输出结果为一个array，每一个元素与其位置索引一一映射。</p><ol start="2" type="1"><li>独热编码</li></ol><p>独热编码过程如下图所示：</p><p><img src="https://pjs-1312672154.cos.ap-shanghai.myqcloud.com/MP9g8LuAxN3iJBo.png"></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">from</span> sklearn <span class="hljs-keyword">import</span> preprocessing<br>enc = preprocessing.OneHotEncoder()<br>enc.fit_transform(X).toarray()<span class="hljs-comment">#X : array-like of shape (n_samples, n_features).</span><br>enc.categories_ <span class="hljs-comment">#同样可以这样查看映射关系</span><br></code></pre></td></tr></table></figure><p>对于独热编码的使用，有一点是额外需要注意的，那就是对于二分类离散变量来说，独热编码往往是没有实际作用的。例如对于上述极简数据集而言，Gender的取值是能是M或者F，独热编码转化后，某行Gender_F取值为1、则Gender_M取值必然为0，反之亦然。因此很多时候我们在进行独热编码转化的时候会考虑只对多分类离散变量进行转化，而保留二分类离散变量的原始取值。此时就需要将OneHotEncoder中drop参数调整为'if_binary'，以表示跳过二分类离散变量列。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><code class="hljs python">&gt;&gt;&gt;X = pd.DataFrame(&#123;<span class="hljs-string">&#x27;Gender&#x27;</span>: [<span class="hljs-string">&#x27;F&#x27;</span>, <span class="hljs-string">&#x27;M&#x27;</span>, <span class="hljs-string">&#x27;M&#x27;</span>, <span class="hljs-string">&#x27;F&#x27;</span>], <span class="hljs-string">&#x27;Income&#x27;</span>: [<span class="hljs-string">&#x27;High&#x27;</span>, <span class="hljs-string">&#x27;Medium&#x27;</span>, <span class="hljs-string">&#x27;High&#x27;</span>, <span class="hljs-string">&#x27;Low&#x27;</span>]&#125;)<br>&gt;&gt;&gt;drop_enc = preprocessing.OneHotEncoder(drop=<span class="hljs-string">&#x27;if_binary&#x27;</span>)<br>&gt;&gt;&gt;drop_enc.fit_transform(X).toarray()<br>array([[<span class="hljs-number">0.</span>, <span class="hljs-number">1.</span>, <span class="hljs-number">0.</span>, <span class="hljs-number">0.</span>],<br>       [<span class="hljs-number">1.</span>, <span class="hljs-number">0.</span>, <span class="hljs-number">0.</span>, <span class="hljs-number">1.</span>],<br>       [<span class="hljs-number">1.</span>, <span class="hljs-number">1.</span>, <span class="hljs-number">0.</span>, <span class="hljs-number">0.</span>],<br>       [<span class="hljs-number">0.</span>, <span class="hljs-number">0.</span>, <span class="hljs-number">1.</span>, <span class="hljs-number">0.</span>]])<br>&gt;&gt;&gt;drop_enc.categories_<br>[array([<span class="hljs-string">&#x27;F&#x27;</span>, <span class="hljs-string">&#x27;M&#x27;</span>], dtype=<span class="hljs-built_in">object</span>),<br> array([<span class="hljs-string">&#x27;High&#x27;</span>, <span class="hljs-string">&#x27;Low&#x27;</span>, <span class="hljs-string">&#x27;Medium&#x27;</span>], dtype=<span class="hljs-built_in">object</span>)]<br></code></pre></td></tr></table></figure><p>对于sklearn的独热编码转化器来说，尽管其使用过程会更加方便，但却无法自动创建转化后的列名称，而在需要考察字段业务背景含义的场景中，必然需要知道每一列的实际名称（通过“原列名_字段取值”来进行命名），因此我们需要定义一个函数来批量创建独热编码后新数据集各字段名称的函数。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">def</span> <span class="hljs-title function_">cate_colName</span>(<span class="hljs-params">Transformer,category_cols,drop=<span class="hljs-string">&quot;if_binary&quot;</span></span>):<br>    <span class="hljs-string">&quot;&quot;&quot;</span><br><span class="hljs-string">    离散字段独热编码后字段名创建函数</span><br><span class="hljs-string">    </span><br><span class="hljs-string">    :param Transformer: 独热编码转化器</span><br><span class="hljs-string">    :param category_cols: 输入转化器的离散变量名</span><br><span class="hljs-string">    :param drop: 独热编码转化器的drop参数</span><br><span class="hljs-string">    &quot;&quot;&quot;</span><br>    name_lst = []<br>    <span class="hljs-keyword">for</span> index,value <span class="hljs-keyword">in</span> <span class="hljs-built_in">enumerate</span>(category_cols):<br>        <span class="hljs-keyword">if</span> (<span class="hljs-built_in">len</span>(Transformer.categories_[index])==<span class="hljs-number">2</span>) &amp; (drop==<span class="hljs-string">&quot;if_binary&quot;</span>):<br>            name_lst.append(value)<br>        <span class="hljs-keyword">else</span>:<br>            <span class="hljs-keyword">for</span> v <span class="hljs-keyword">in</span> Transformer.categories_[index]:<br>                name_lst.append(value+<span class="hljs-string">&quot;_&quot;</span>+v)<br>    <span class="hljs-keyword">return</span> name_lst<br></code></pre></td></tr></table></figure><h5 id="连续字段数据重编码方式">连续字段数据重编码方式</h5><ol type="1"><li>标准化</li></ol><ul><li>Z-score标准化</li></ul><p><span class="math display">\[X=\{x_i:i=1,\dots,n\},\mu=\frac{\sum\limits_{i=1}^{n}x_i}{n},s^{2}=\frac{\sum\limits_{i=1}^{n}(x_i-\mu)^{2}}{n-1}\]</span></p><p><span class="math display">\[\frac{X-\mu}{s}\]</span></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><code class="hljs python">&gt;&gt;&gt;<span class="hljs-keyword">from</span> sklearn <span class="hljs-keyword">import</span> preprocessing<br>&gt;&gt;&gt;<span class="hljs-keyword">from</span> sklearn.model_selection <span class="hljs-keyword">import</span> train_test_split<br>&gt;&gt;&gt;scaler = preprocessing.SrandardScaler()<br>&gt;&gt;&gt;X = np.arange(<span class="hljs-number">15</span>).reshape(<span class="hljs-number">5</span>, <span class="hljs-number">3</span>)<br>array([[ <span class="hljs-number">0</span>,  <span class="hljs-number">1</span>,  <span class="hljs-number">2</span>],<br>       [ <span class="hljs-number">3</span>,  <span class="hljs-number">4</span>,  <span class="hljs-number">5</span>],<br>       [ <span class="hljs-number">6</span>,  <span class="hljs-number">7</span>,  <span class="hljs-number">8</span>],<br>       [ <span class="hljs-number">9</span>, <span class="hljs-number">10</span>, <span class="hljs-number">11</span>],<br>       [<span class="hljs-number">12</span>, <span class="hljs-number">13</span>, <span class="hljs-number">14</span>]])<br>&gt;&gt;&gt;Xtrain,Xtest = train_test_split(X)<br>&gt;&gt;&gt;scaler.fit(Xtrain)<span class="hljs-comment">#训练过程就是统计各列训练集的统计量</span><br>&gt;&gt;&gt;scaler.transform(Xtest)<span class="hljs-comment">#转化过程用到的统计量为训练过程统计的统计量</span><br>&gt;&gt;&gt;scaler.scale_<span class="hljs-comment">#查看训练数据各列标准差</span><br>array([<span class="hljs-number">3.74165739</span>, <span class="hljs-number">3.74165739</span>, <span class="hljs-number">3.74165739</span>])<br>&gt;&gt;&gt;scaler.mean_<span class="hljs-comment">#查看训练数据各列均值</span><br>array([<span class="hljs-number">5.</span>, <span class="hljs-number">6.</span>, <span class="hljs-number">7.</span>])<br>&gt;&gt;&gt;scaler.var_<span class="hljs-comment">#查看训练数据各列方差</span><br>array([<span class="hljs-number">14.</span>, <span class="hljs-number">14.</span>, <span class="hljs-number">14.</span>])<br></code></pre></td></tr></table></figure><ul><li>0-1标准化</li></ul><p><span class="math display">\[X_{std} = \frac{X-X_{min}}{X_{max}-X_{min}}\]</span></p><p><span class="math display">\[X = X_{std}(X_{max}-X_{min})+X_{min}\]</span></p><p>(3)为归一化过程，（4）为反归一化过程</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><code class="hljs python">&gt;&gt;&gt;<span class="hljs-keyword">from</span> sklearn <span class="hljs-keyword">import</span> preprocessing<br>&gt;&gt;&gt;<span class="hljs-keyword">from</span> sklearn.model_selection <span class="hljs-keyword">import</span> train_test_split<br>&gt;&gt;&gt;scaler = preprocessing.MinMaxScaler<br>&gt;&gt;&gt;X = np.arange(<span class="hljs-number">15</span>).reshape(<span class="hljs-number">5</span>, <span class="hljs-number">3</span>)<br>array([[ <span class="hljs-number">0</span>,  <span class="hljs-number">1</span>,  <span class="hljs-number">2</span>],<br>       [ <span class="hljs-number">3</span>,  <span class="hljs-number">4</span>,  <span class="hljs-number">5</span>],<br>       [ <span class="hljs-number">6</span>,  <span class="hljs-number">7</span>,  <span class="hljs-number">8</span>],<br>       [ <span class="hljs-number">9</span>, <span class="hljs-number">10</span>, <span class="hljs-number">11</span>],<br>       [<span class="hljs-number">12</span>, <span class="hljs-number">13</span>, <span class="hljs-number">14</span>]])<br>&gt;&gt;&gt;scaler.fit_transform(X)<br>array([[<span class="hljs-number">0.</span>  , <span class="hljs-number">0.</span>  , <span class="hljs-number">0.</span>  ],<br>       [<span class="hljs-number">0.25</span>, <span class="hljs-number">0.25</span>, <span class="hljs-number">0.25</span>],<br>       [<span class="hljs-number">0.5</span> , <span class="hljs-number">0.5</span> , <span class="hljs-number">0.5</span> ],<br>       [<span class="hljs-number">0.75</span>, <span class="hljs-number">0.75</span>, <span class="hljs-number">0.75</span>],<br>       [<span class="hljs-number">1.</span>  , <span class="hljs-number">1.</span>  , <span class="hljs-number">1.</span>  ]])<br>&gt;&gt;&gt;scaler.data_min_<span class="hljs-comment">#查看数据各列最小值</span><br>array([<span class="hljs-number">0.</span>, <span class="hljs-number">1.</span>, <span class="hljs-number">2.</span>])<br>&gt;&gt;&gt;scaler.data_max_<span class="hljs-comment">#查看数据各列最大值</span><br>array([<span class="hljs-number">12.</span>, <span class="hljs-number">13.</span>, <span class="hljs-number">14.</span>])<br></code></pre></td></tr></table></figure><p>2.连续字段分箱</p><p>在实际建模的过程中，我们也可能会将连续变量离散化，即将连续性字段转化为离散性字段。</p><p>连续字段的离散过程如下所示：</p><p><img src="https://pjs-1312672154.cos.ap-shanghai.myqcloud.com/gXUG6Oe71wfAEC4.png"></p><p>连续变量的离散过程也可以理解为连续变量取值的重新编码过程，在很多时候，连续变量的离散化也被称为连续变量分箱。需要注意的是，离散之后字段的含义将发生变化，原始字段Income代表用户真实收入状况，而离散之后的含义就变成了用户收入的等级划分，0表示低收入人群、1表示中等收入人群、2代表高收入人群。连续字段的离散化能够更加简洁清晰的呈现特征信息，并且能够极大程度减少异常值的影响（例如Income取值为180的用户），同时也能够消除特征量纲影响，当然，最重要的一点是，对于很多线性模型来说，连续变量的分箱实际上相当于在线性方程中引入了非线性的因素，从而提升模型表现。当然，连续变量的分箱过程会让连续变量损失一些信息，而对于其他很多模型来说（例如树模型），分箱损失的信息则大概率会影响最终模型效果。</p><p>当然，分箱的过程并不复杂，唯一需要注意的就是需要确定划分几类、以及每一类代表什么含义。一般来说分箱的规则基本可以由业务指标来确定或者由某种计算流程来确定。</p><ul><li>根据业务指标确定</li></ul><p>在一些有明确业务背景的场景中，或许能够找到一些根据长期实践经验积累下来的业务指标来作为划分依据，例如很多金融行业会通过一些业务指标来对用户进行价值划分，例如会规定月收入10000以上属于高收入人群，此时10000就可以作为连续变量离散化的依据。</p><ul><li>根据计算流程确定</li></ul><p>当然，更常见的一种情况是并没有明确的业务指标作为划分依据，此时我们就需要通过某种计算流程来进行确定。常见方法有四种，分别是等宽分箱（等距分箱）、等频分箱（等深分箱）、聚类分箱和有监督分箱，接下来我们对这四种方法依次进行介绍。</p><p>（1）等宽分箱</p><p>所谓等宽分箱，需要先确定划分成几分，然后根据连续变量的取值范围划分对应数量的宽度相同的区间，并据此对连续变量进行分箱。例如上述Income字段取值在[0,180]之间，现对其进行等宽分箱分成三份，则每一份的取值范围分别是[0,60),[60,120),[120,180]，连续字段将据此进行划分，分箱过程如下所示：</p><p><img src="https://pjs-1312672154.cos.ap-shanghai.myqcloud.com/gXUG6Oe71wfAEC4.png"></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><code class="hljs python">&gt;&gt;&gt;<span class="hljs-keyword">from</span> sklearn <span class="hljs-keyword">import</span> preprocessing<br>&gt;&gt;&gt;income = np.array([<span class="hljs-number">0</span>, <span class="hljs-number">10</span>, <span class="hljs-number">180</span>, <span class="hljs-number">30</span>, <span class="hljs-number">55</span>, <span class="hljs-number">35</span>, <span class="hljs-number">25</span>, <span class="hljs-number">75</span>, <span class="hljs-number">80</span>, <span class="hljs-number">10</span>]).reshape(-<span class="hljs-number">1</span>, <span class="hljs-number">1</span>)<br>&gt;&gt;&gt;est = preprocessing.KBinsDiscretizer(n_bins=<span class="hljs-number">3</span>,encoder=<span class="hljs-string">&quot;ordinal&quot;</span>,strategy=<span class="hljs-string">&quot;uniform&quot;</span>)<br>&gt;&gt;&gt;est.fit_transform(income)<br>&gt;&gt;&gt;dis.bin_edges_<span class="hljs-comment">#查看箱体边界</span><br>array([array([  <span class="hljs-number">0.</span>,  <span class="hljs-number">60.</span>, <span class="hljs-number">120.</span>, <span class="hljs-number">180.</span>])], dtype=<span class="hljs-built_in">object</span>)<br></code></pre></td></tr></table></figure><p>（2）等频分箱</p><p>在等频分箱的过程中，需要先确定划分成几分，然后选择能够让每一份包含样本数量相同的划分方式。例如对于上述数据集，若需要分成两份，则需要先对所有数据进行排序，然后选取一个中间值对其进行切分，对于income来说，“中间值”应该是32.5：</p><p><img src="https://pjs-1312672154.cos.ap-shanghai.myqcloud.com/gEJd9kGM5KpY7U3.png"></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><code class="hljs python">&gt;&gt;&gt;<span class="hljs-keyword">from</span> sklearn <span class="hljs-keyword">import</span> preprocessing<br>&gt;&gt;&gt;income = np.array([<span class="hljs-number">0</span>, <span class="hljs-number">10</span>, <span class="hljs-number">180</span>, <span class="hljs-number">30</span>, <span class="hljs-number">55</span>, <span class="hljs-number">35</span>, <span class="hljs-number">25</span>, <span class="hljs-number">75</span>, <span class="hljs-number">80</span>, <span class="hljs-number">10</span>]).reshape(-<span class="hljs-number">1</span>, <span class="hljs-number">1</span>)<br>&gt;&gt;&gt;est = preprocessing.KBinsDiscretizer(n_bins=<span class="hljs-number">2</span>,encoder=<span class="hljs-string">&quot;ordinal&quot;</span>,strategy=<span class="hljs-string">&quot;quantile&quot;</span>)<br>&gt;&gt;&gt;est.fit_transform(income)<br>&gt;&gt;&gt;dis.bin_edges_<span class="hljs-comment">#查看箱体边界</span><br>array([array([  <span class="hljs-number">0.</span> ,  <span class="hljs-number">32.5</span>, <span class="hljs-number">180.</span> ])], dtype=<span class="hljs-built_in">object</span>)<br></code></pre></td></tr></table></figure><p>（3）聚类分箱</p><p>所谓聚类分箱，指的是先对某连续变量进行聚类（往往是KMeans聚类），然后用样本所属类别作为标记代替原始数值，从而完成分箱的过程。</p><p><img src="https://pjs-1312672154.cos.ap-shanghai.myqcloud.com/gOtAFNG7J4ReY3i%20(1).png"></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><code class="hljs python">&gt;&gt;&gt;<span class="hljs-keyword">from</span> sklearn <span class="hljs-keyword">import</span> preprocessing<br>&gt;&gt;&gt;income = np.array([<span class="hljs-number">0</span>, <span class="hljs-number">10</span>, <span class="hljs-number">180</span>, <span class="hljs-number">30</span>, <span class="hljs-number">55</span>, <span class="hljs-number">35</span>, <span class="hljs-number">25</span>, <span class="hljs-number">75</span>, <span class="hljs-number">80</span>, <span class="hljs-number">10</span>]).reshape(-<span class="hljs-number">1</span>, <span class="hljs-number">1</span>)<br>&gt;&gt;&gt;est = preprocessing.KBinsDiscretizer(n_bins=<span class="hljs-number">2</span>,encoder=<span class="hljs-string">&quot;ordinal&quot;</span>,strategy=<span class="hljs-string">&quot;kmeans&quot;</span>)<br>&gt;&gt;&gt;est.fit_transform(income)<br>&gt;&gt;&gt;dis.bin_edges_<span class="hljs-comment">#查看箱体边界</span><br>array([array([  <span class="hljs-number">0.</span>        ,  <span class="hljs-number">44.16666667</span>, <span class="hljs-number">125.</span>        , <span class="hljs-number">180.</span>        ])],<br> dtype=<span class="hljs-built_in">object</span>)<br></code></pre></td></tr></table></figure><h5 id="columntransformer流水转化线">ColumnTransformer流水转化线</h5><p>在执行单独的转化器时，我们需要单独将要转化的列提取出来，然后对其转化，并且在转化完成后再和其他列拼接成新的数据集。尽管很多时候表格的拆分和拼接不可避免，但该过程显然不够“自动化”。在sklearn的0.20版本中，加入了ColumnTransformer转化流水线评估器，使得上述情况得以改善。该评估器和pipeline类似，能够集成多个评估器（转化器），并一次性对输入数据的不同列采用不同处理方法，并输出转化完成并且拼接完成的数据。</p><p>ColumnTransformer流水转化线格式如下:</p><p>(评估器名称（自定义）, 转化器, 数据集字段（转化器作用的字段）)</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">from</span> sklearn.compose <span class="hljs-keyword">import</span> ColumnTransformer<br>preprocess_col = ColumnTransformer([<br>    (<span class="hljs-string">&#x27;cat&#x27;</span>, preprocessing.OneHotEncoder(drop=<span class="hljs-string">&#x27;if_binary&#x27;</span>), category_cols), <br>    (<span class="hljs-string">&#x27;num&#x27;</span>, <span class="hljs-string">&#x27;passthrough&#x27;</span>, numeric_cols)<br>])<br>preprocess_col.fit(tcc)<span class="hljs-comment">#tcc为原始数据集</span><br>preprocess_col.named_transformers_<span class="hljs-comment">#使用named_transformers_查看每个训练好的转化器</span><br>categories_col_new = cate_colName(preprocess_col.named_transformers_[<span class="hljs-string">&quot;cat&quot;</span>],category_cols)<span class="hljs-comment">#生成新的独热编码后的列名称</span><br>col_new = categories_col_new+numeric_cols<span class="hljs-comment">#生成新的经过流水转划线后的列名称。注意：字段顺序和ColumnTransformer集成顺序一致。</span><br>df_new = pd.DataFrame(preprocess_col.transform(tcc),columns=col_new)<span class="hljs-comment">#生成新的DateFrame</span><br></code></pre></td></tr></table></figure><h4 id="高阶多项式特征衍生">高阶多项式特征衍生</h4><p>对于单变量的高阶多项式特征衍生主要是生成该变量的一些高次方数据。下面我们使用sklearn中的PolyNomialFeatures评估器来实现该过程。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><code class="hljs python">&gt;&gt;&gt;form sklearn.preprocessing <span class="hljs-keyword">import</span> PolyNomialFeatures<br>&gt;&gt;&gt;x1 = np.array([<span class="hljs-number">1</span>, <span class="hljs-number">2</span>, <span class="hljs-number">4</span>, <span class="hljs-number">1</span>, <span class="hljs-number">3</span>])<br>&gt;&gt;&gt;PolynomialFeatures(degree=<span class="hljs-number">5</span>).fit_transform(x1.reshape(-<span class="hljs-number">1</span>, <span class="hljs-number">1</span>))<br>array([[<span class="hljs-number">1.000e+00</span>, <span class="hljs-number">1.000e+00</span>, <span class="hljs-number">1.000e+00</span>, <span class="hljs-number">1.000e+00</span>, <span class="hljs-number">1.000e+00</span>, <span class="hljs-number">1.000e+00</span>],<br>       [<span class="hljs-number">1.000e+00</span>, <span class="hljs-number">2.000e+00</span>, <span class="hljs-number">4.000e+00</span>, <span class="hljs-number">8.000e+00</span>, <span class="hljs-number">1.600e+01</span>, <span class="hljs-number">3.200e+01</span>],<br>       [<span class="hljs-number">1.000e+00</span>, <span class="hljs-number">4.000e+00</span>, <span class="hljs-number">1.600e+01</span>, <span class="hljs-number">6.400e+01</span>, <span class="hljs-number">2.560e+02</span>, <span class="hljs-number">1.024e+03</span>],<br>       [<span class="hljs-number">1.000e+00</span>, <span class="hljs-number">1.000e+00</span>, <span class="hljs-number">1.000e+00</span>, <span class="hljs-number">1.000e+00</span>, <span class="hljs-number">1.000e+00</span>, <span class="hljs-number">1.000e+00</span>],<br>       [<span class="hljs-number">1.000e+00</span>, <span class="hljs-number">3.000e+00</span>, <span class="hljs-number">9.000e+00</span>, <span class="hljs-number">2.700e+01</span>, <span class="hljs-number">8.100e+01</span>, <span class="hljs-number">2.430e+02</span>]])<br></code></pre></td></tr></table></figure>]]></content>
    
    
    <categories>
      
      <category>machine learning</category>
      
      <category>特征工程</category>
      
    </categories>
    
    
    <tags>
      
      <tag>machine learning</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>Groupby机制</title>
    <link href="/posts/42638.html"/>
    <url>/posts/42638.html</url>
    
    <content type="html"><![CDATA[<hr><div class="note note-success">            <p>Python pandas</p>          </div><h2 id="groupby机制">Groupby机制</h2><p>在数据科学中有一个表示分组运算的术语"split-apply-combine"。第一阶段，pandas对象会根据你所提供的一个或多个“分组键”拆分为多组。拆分操作是在对象的特定轴上执行的。然后，将一个函数应用到各个分组并产生新的值。最后，所有这些函数执行结果会被合并到最终的结果对象中。</p><h3 id="数据分组">数据分组</h3><p>分组键：</p><ul><li>列表或数组，其长度与待分组的轴一样。</li><li>表示DataFrame某个列名的值。</li><li>字典或Series，给出待分组轴上的值与分组名之间的对应关系。</li><li>函数，用于处理轴索引或索引中的各个标签。</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br></pre></td><td class="code"><pre><code class="hljs python">&gt;&gt;&gt;<span class="hljs-keyword">import</span> pandas <span class="hljs-keyword">as</span> pd<br>&gt;&gt;&gt;<span class="hljs-keyword">import</span> numpy <span class="hljs-keyword">as</span> np<br>&gt;&gt;&gt;df = pd.DataFrame(&#123;<span class="hljs-string">&quot;key1&quot;</span>:[<span class="hljs-string">&quot;a&quot;</span>,<span class="hljs-string">&quot;a&quot;</span>,<span class="hljs-string">&quot;b&quot;</span>,<span class="hljs-string">&quot;b&quot;</span>,<span class="hljs-string">&quot;a&quot;</span>],<span class="hljs-string">&quot;key2&quot;</span>:[<span class="hljs-string">&quot;one&quot;</span>,<span class="hljs-string">&quot;two&quot;</span>,<span class="hljs-string">&quot;one&quot;</span>,<span class="hljs-string">&quot;two&quot;</span>,<span class="hljs-string">&quot;one&quot;</span>],<span class="hljs-string">&quot;data1&quot;</span>:np.random.randn(<span class="hljs-number">5</span>),<span class="hljs-string">&quot;data2&quot;</span>:np.random.randn(<span class="hljs-number">5</span>)&#125;)<br>&gt;&gt;&gt;df<br>key1key2data1data2<br><span class="hljs-number">0</span>aone-<span class="hljs-number">1.260911</span>-<span class="hljs-number">0.241765</span><br><span class="hljs-number">1</span>atwo-<span class="hljs-number">1.055654</span>-<span class="hljs-number">1.155897</span><br><span class="hljs-number">2</span>bone<span class="hljs-number">0.390380</span>-<span class="hljs-number">0.375067</span><br><span class="hljs-number">3</span>btwo<span class="hljs-number">0.889461</span><span class="hljs-number">1.772159</span><br><span class="hljs-number">4</span>aone<span class="hljs-number">0.570429</span>-<span class="hljs-number">0.039133</span><br>&gt;&gt;&gt;grouped = df[<span class="hljs-string">&quot;data1&quot;</span>].groupby(df[<span class="hljs-string">&quot;key1&quot;</span>]) <span class="hljs-comment">#该分组键本质是数组</span><br><span class="hljs-comment">#上述过程等价于</span><br>&gt;&gt;&gt;grouped = df.groupby(df[<span class="hljs-string">&quot;key1&quot;</span>])[<span class="hljs-string">&quot;data1&quot;</span>]<br>&gt;&gt;&gt;grouped<span class="hljs-comment">#变量grouped是Groupby对象，它实际上没有进行任何计算，只是含有一些关于分组键的中间数据。</span><br>&lt;pandas.core.groupby.generic.SeriesGroupBy <span class="hljs-built_in">object</span> at <span class="hljs-number">0x000001BDEE8B67C0</span>&gt;<br>&gt;&gt;&gt;grouped.mean()<br>key1<br>a   -<span class="hljs-number">0.582045</span><br>b    <span class="hljs-number">0.639921</span><br>Name: data1, dtype: float64<br><span class="hljs-comment">#分组键不仅仅可以为一个数组，还可以为数组的列表</span><br>&gt;&gt;&gt;means = df[<span class="hljs-string">&quot;data1&quot;</span>].groupby([df[<span class="hljs-string">&quot;key1&quot;</span>],df[<span class="hljs-string">&quot;key2&quot;</span>]]).mean()<br>&gt;&gt;&gt;means<br>key1  key2<br>a     one    -<span class="hljs-number">0.345241</span><br>      two    -<span class="hljs-number">1.055654</span><br>b     one     <span class="hljs-number">0.390380</span><br>      two     <span class="hljs-number">0.889461</span><br>Name: data1, dtype: float64<br>&gt;&gt;&gt;means.unstack()<br>key2onetwo<br>key1<br>a-<span class="hljs-number">0.345241</span>-<span class="hljs-number">1.055654</span><br>b<span class="hljs-number">0.390380</span><span class="hljs-number">0.889461</span><br><span class="hljs-comment">#分组键还可以为列名</span><br>&gt;&gt;&gt;df.groupby(<span class="hljs-string">&quot;key1&quot;</span>).mean()<br>data1data2<br>key1<br>a-<span class="hljs-number">0.582045</span>-<span class="hljs-number">0.478932</span><br>b<span class="hljs-number">0.639921</span><span class="hljs-number">0.698546</span><br><span class="hljs-comment">#还可以为列名组成的列表</span><br>&gt;&gt;&gt;df.groupby([<span class="hljs-string">&quot;key1&quot;</span>,<span class="hljs-string">&quot;key2&quot;</span>]).mean()<br>key1  key2<br>a     one    -<span class="hljs-number">0.345241</span><br>      two    -<span class="hljs-number">1.055654</span><br>b     one     <span class="hljs-number">0.390380</span><br>      two     <span class="hljs-number">0.889461</span><br> <span class="hljs-comment">#默认情况下数值列会进行聚合，而非数值列会被从结果中排除。</span><br>&gt;&gt;&gt;df.groupby([<span class="hljs-string">&quot;key1&quot;</span>,<span class="hljs-string">&quot;key2&quot;</span>]).size()<br>key1  key2<br>a     one     <span class="hljs-number">2</span><br>      two     <span class="hljs-number">1</span><br>b     one     <span class="hljs-number">1</span><br>      two     <span class="hljs-number">1</span><br>dtype: int64<br><span class="hljs-comment">#通过字典或Series进行分组</span><br>&gt;&gt;&gt;mapping = &#123;<span class="hljs-number">0</span>:<span class="hljs-string">&quot;red&quot;</span>,<span class="hljs-number">1</span>:<span class="hljs-string">&quot;red&quot;</span>,<span class="hljs-number">2</span>:<span class="hljs-string">&quot;red&quot;</span>,<span class="hljs-number">3</span>:<span class="hljs-string">&quot;blue&quot;</span>,<span class="hljs-number">4</span>:<span class="hljs-string">&quot;blue&quot;</span>&#125;<br>&gt;&gt;&gt;df.groupby(mapping).size()<br>blue    <span class="hljs-number">2</span><br>red     <span class="hljs-number">3</span><br>dtype: int64<br><span class="hljs-comment">#series和字典一样，都是将索引值按照某种映射关系进行分组</span><br>&gt;&gt;&gt;series = pd.Series(mapping)<br>&gt;&gt;&gt;df.groupby(series),size()<br>blue    <span class="hljs-number">2</span><br>red     <span class="hljs-number">3</span><br>dtype: int64<br></code></pre></td></tr></table></figure><h4 id="通过函数进行分组">通过函数进行分组</h4><p>比起使用字典或Series，使用python函数是一种更原生的方法定义分组映射。任何被当做分组键的函数都会在各个索引值上被调用一次，其返回值就会被用作分组名称。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><code class="hljs python">&gt;&gt;&gt;<span class="hljs-keyword">def</span> <span class="hljs-title function_">get_letter_type</span>(<span class="hljs-params">letter</span>):<br><span class="hljs-meta">&gt;&gt;&gt; </span>   <span class="hljs-keyword">if</span> letter[<span class="hljs-number">0</span>].lower() <span class="hljs-keyword">in</span> <span class="hljs-string">&quot;aeiou&quot;</span>:<br><span class="hljs-meta">&gt;&gt;&gt; </span>       <span class="hljs-keyword">return</span> <span class="hljs-string">&quot;元音&quot;</span><br><span class="hljs-meta">&gt;&gt;&gt; </span>   <span class="hljs-keyword">else</span>:<br><span class="hljs-meta">&gt;&gt;&gt; </span>       <span class="hljs-keyword">return</span> <span class="hljs-string">&quot;辅音&quot;</span><br>&gt;&gt;&gt;df.set_index(<span class="hljs-string">&quot;key2&quot;</span>).groupby(get_letter_type).size()<br>key2<br>元音    <span class="hljs-number">3</span><br>辅音    <span class="hljs-number">2</span><br>dtype: int64<br></code></pre></td></tr></table></figure><h3 id="数据聚合">数据聚合</h3><p>聚合指的是任何能够从数组产生标量值的数据转化过程。下表给出了常见的聚合运算。</p><table><thead><tr class="header"><th>函数名</th><th>说明</th></tr></thead><tbody><tr class="odd"><td>count</td><td>分组中非NA值的数量</td></tr><tr class="even"><td>sum</td><td>非NA值的和</td></tr><tr class="odd"><td>mean</td><td>非NA值的平均值</td></tr><tr class="even"><td>median</td><td>非NA值的算术中位数</td></tr><tr class="odd"><td>std、var</td><td>无偏（分母为n-1）标准差和方差</td></tr><tr class="even"><td>min、max</td><td>非NA值的最小值和最大值</td></tr><tr class="odd"><td>prod</td><td>非NA值的积</td></tr><tr class="even"><td>first、last</td><td>第一个和最后一个非NA值</td></tr></tbody></table><p>除了上述函数，还可以使用自己发明的聚合运算，还可以调用分组对象上已经定义好的任何方法。例如，quantile可以计算series或DataFrame列的样本分位数。</p><p>虽然quantile并没用明确的实现于GroupBy,但他是一个Series方法，所以这里是能用的。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><code class="hljs python">&gt;&gt;&gt;grouped = df.groupby(<span class="hljs-string">&quot;key1&quot;</span>)[<span class="hljs-string">&quot;data1&quot;</span>].quantile(<span class="hljs-number">0.9</span>)<br>&gt;&gt;&gt;grouped<br>key1<br>a    <span class="hljs-number">0.245213</span><br>b    <span class="hljs-number">0.839553</span><br>Name: data1, dtype: float64<br></code></pre></td></tr></table></figure><p>如果使用自己的聚合函数，只需要将其传入agg方法即可：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><code class="hljs python">&gt;&gt;&gt;<span class="hljs-keyword">def</span> <span class="hljs-title function_">peak_to_peak</span>(<span class="hljs-params">arr</span>):<br><span class="hljs-meta">&gt;&gt;&gt; </span>   <span class="hljs-keyword">return</span> arr.<span class="hljs-built_in">max</span>()-arr.<span class="hljs-built_in">min</span>()<br>&gt;&gt;&gt;df.groupby(<span class="hljs-string">&quot;key1&quot;</span>)[<span class="hljs-string">&quot;data1&quot;</span>].agg(peak_to_peak)<br>key1<br>a    <span class="hljs-number">1.831340</span><br>b    <span class="hljs-number">0.499081</span><br>Name: data1, dtype: float64<br></code></pre></td></tr></table></figure><h4 id="对一列应用多个函数">对一列应用多个函数</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs python">&gt;&gt;&gt;grouped = df.groupby([<span class="hljs-string">&quot;key1&quot;</span>,<span class="hljs-string">&quot;key2&quot;</span>])[<span class="hljs-string">&quot;data1&quot;</span>]<br>&gt;&gt;&gt;grouped.agg([peak_to_peak,<span class="hljs-string">&quot;mean&quot;</span>,<span class="hljs-string">&quot;std&quot;</span>])<br></code></pre></td></tr></table></figure><p><img src="https://pjs-1312672154.cos.ap-shanghai.myqcloud.com/QQ截图20220705185705.png"></p><p>我们可以看出，当我们传入一组函数或者函数名的时候，得到的DataFrame的列会以函数名命名。</p><p>我们可以传入一个由（name，function）元组组成的列表，则各元组的第一个元素就会被用作DataFrame的列名。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs python">&gt;&gt;&gt;grouped.agg([(<span class="hljs-string">&quot;极差&quot;</span>,peak_to_peak),(<span class="hljs-string">&quot;均值&quot;</span>,<span class="hljs-string">&quot;mean&quot;</span>),(<span class="hljs-string">&quot;方差&quot;</span>,<span class="hljs-string">&quot;std&quot;</span>)])<br></code></pre></td></tr></table></figure><p><img src="https://pjs-1312672154.cos.ap-shanghai.myqcloud.com/QQ截图20220705190158.png"></p><h4 id="对不同的列应用相同的函数组">对不同的列应用相同的函数组</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs python">&gt;&gt;&gt;grouped = df.groupby([<span class="hljs-string">&quot;key1&quot;</span>,<span class="hljs-string">&quot;key2&quot;</span>])[<span class="hljs-string">&quot;data1&quot;</span>,<span class="hljs-string">&quot;data2&quot;</span>]<br>&gt;&gt;&gt;res = grouped.agg([(<span class="hljs-string">&quot;极差&quot;</span>,peak_to_peak),(<span class="hljs-string">&quot;均值&quot;</span>,<span class="hljs-string">&quot;mean&quot;</span>),(<span class="hljs-string">&quot;方差&quot;</span>,<span class="hljs-string">&quot;std&quot;</span>)])<br></code></pre></td></tr></table></figure><p><img src="https://pjs-1312672154.cos.ap-shanghai.myqcloud.com/QQ截图20220705190514.png"></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs python">&gt;&gt;&gt;res[<span class="hljs-string">&quot;data1&quot;</span>]<br></code></pre></td></tr></table></figure><p><img src="https://pjs-1312672154.cos.ap-shanghai.myqcloud.com/QQ截图20220705190636.png"></p><h4 id="对不同的列应用不同的函数组">对不同的列应用不同的函数组</h4><p>具体的方法是向agg传入一个从列名映射到函数的字典。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs python">grouped.agg(&#123;<span class="hljs-string">&quot;data1&quot;</span>:[(<span class="hljs-string">&quot;极差&quot;</span>,peak_to_peak),(<span class="hljs-string">&quot;均值&quot;</span>,<span class="hljs-string">&quot;mean&quot;</span>)],<span class="hljs-string">&quot;data2&quot;</span>:[(<span class="hljs-string">&quot;均值&quot;</span>,<span class="hljs-string">&quot;mean&quot;</span>),(<span class="hljs-string">&quot;方差&quot;</span>,<span class="hljs-string">&quot;std&quot;</span>)]&#125;)<br></code></pre></td></tr></table></figure><p><img src="https://pjs-1312672154.cos.ap-shanghai.myqcloud.com/QQ截图20220705191251.png"></p><h4 id="以没有行索引的形式返回聚合数据">以没有行索引的形式返回聚合数据</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs python">&gt;&gt;&gt;grouped = df.groupby([<span class="hljs-string">&quot;key1&quot;</span>,<span class="hljs-string">&quot;key2&quot;</span>],as_index=<span class="hljs-literal">False</span>)<br>&gt;&gt;&gt;grouped.agg(&#123;<span class="hljs-string">&quot;data1&quot;</span>:[(<span class="hljs-string">&quot;极差&quot;</span>,peak_to_peak),(<span class="hljs-string">&quot;均值&quot;</span>,<span class="hljs-string">&quot;mean&quot;</span>)],<span class="hljs-string">&quot;data2&quot;</span>:[(<span class="hljs-string">&quot;均值&quot;</span>,<span class="hljs-string">&quot;mean&quot;</span>),(<span class="hljs-string">&quot;方差&quot;</span>,<span class="hljs-string">&quot;std&quot;</span>)]&#125;)<br></code></pre></td></tr></table></figure><p><img src="https://pjs-1312672154.cos.ap-shanghai.myqcloud.com/QQ截图20220705191251.png"></p><h3 id="apply用法">apply用法</h3><h4 id="实例一用特定于分组的值填充缺失值">实例一：用特定于分组的值填充缺失值</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br></pre></td><td class="code"><pre><code class="hljs python">states = [<span class="hljs-string">&quot;Ohio&quot;</span>,<span class="hljs-string">&quot;New York&quot;</span>,<span class="hljs-string">&quot;Vermont&quot;</span>,<span class="hljs-string">&quot;Florida&quot;</span>,<span class="hljs-string">&quot;Oregon&quot;</span>,<span class="hljs-string">&quot;Nevada&quot;</span>,<span class="hljs-string">&quot;Caliornia&quot;</span>,<span class="hljs-string">&quot;Idaho&quot;</span>] <br>group_key = [<span class="hljs-string">&quot;East&quot;</span>]*<span class="hljs-number">4</span>+[<span class="hljs-string">&quot;West&quot;</span>]*<span class="hljs-number">4</span> <span class="hljs-comment">#分组键</span><br>data = pd.Series(np.random.randn(<span class="hljs-number">8</span>),index=states) <span class="hljs-comment">#创建数据</span><br>data[[<span class="hljs-string">&quot;Vermont&quot;</span>,<span class="hljs-string">&quot;Nevada&quot;</span>,<span class="hljs-string">&quot;Idaho&quot;</span>]] = np.nan <span class="hljs-comment">#生成缺失值</span><br>grouped = data.groupby(group_key) <span class="hljs-comment">#分组</span><br>fill_mean = <span class="hljs-keyword">lambda</span> x:x.fillna(x.mean()) <span class="hljs-comment">#填充的函数</span><br>res = grouped.apply(fill_mean)<span class="hljs-comment">#分组填充缺失值（均值填充）</span><br>res<br>Ohio        -<span class="hljs-number">0.662863</span><br>New York    -<span class="hljs-number">0.062301</span><br>Vermont     -<span class="hljs-number">0.317830</span><br>Florida     -<span class="hljs-number">0.228326</span><br>Oregon      -<span class="hljs-number">1.421787</span><br>Nevada      -<span class="hljs-number">0.089019</span><br>Caliornia    <span class="hljs-number">1.243750</span><br>Idaho       -<span class="hljs-number">0.089019</span><br>dtype: float64<br>fill_values = &#123;<span class="hljs-string">&quot;East&quot;</span>:<span class="hljs-number">0.5</span>,<span class="hljs-string">&quot;West&quot;</span>:-<span class="hljs-number">1</span>&#125;<br>fill_func = <span class="hljs-keyword">lambda</span> x:x.fillna(fill_values[x.name])<span class="hljs-comment">#分组具有name属性</span><br>res = grouped.apply(fill_func)<span class="hljs-comment">#指定值填充</span><br>res<br>Ohio        -<span class="hljs-number">0.662863</span><br>New York    -<span class="hljs-number">0.062301</span><br>Vermont      <span class="hljs-number">0.500000</span><br>Florida     -<span class="hljs-number">0.228326</span><br>Oregon      -<span class="hljs-number">1.421787</span><br>Nevada      -<span class="hljs-number">1.000000</span><br>Caliornia    <span class="hljs-number">1.243750</span><br>Idaho       -<span class="hljs-number">1.000000</span><br>dtype: float64<br></code></pre></td></tr></table></figure><h4 id="实例二分组加权平均数和相关系数">实例二：分组加权平均数和相关系数</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><code class="hljs python">df = pd.DataFrame(&#123;<span class="hljs-string">&quot;category&quot;</span>:[<span class="hljs-string">&quot;a&quot;</span>,<span class="hljs-string">&quot;a&quot;</span>,<span class="hljs-string">&quot;a&quot;</span>,<span class="hljs-string">&quot;a&quot;</span>,<span class="hljs-string">&quot;b&quot;</span>,<span class="hljs-string">&quot;b&quot;</span>,<span class="hljs-string">&quot;b&quot;</span>,<span class="hljs-string">&quot;b&quot;</span>],<span class="hljs-string">&quot;data&quot;</span>:np.random.randn(<span class="hljs-number">8</span>),<span class="hljs-string">&quot;weights&quot;</span>:np.random.dirichlet(np.ones(<span class="hljs-number">8</span>),size=<span class="hljs-number">1</span>).flatten()&#125;)<br>df<br>categorydataweights<br><span class="hljs-number">0</span>a-<span class="hljs-number">0.480924</span><span class="hljs-number">0.082778</span><br><span class="hljs-number">1</span>a<span class="hljs-number">0.503605</span><span class="hljs-number">0.200813</span><br><span class="hljs-number">2</span>a-<span class="hljs-number">0.436033</span><span class="hljs-number">0.047614</span><br><span class="hljs-number">3</span>a-<span class="hljs-number">1.309123</span><span class="hljs-number">0.013908</span><br><span class="hljs-number">4</span>b-<span class="hljs-number">0.344479</span><span class="hljs-number">0.005045</span><br><span class="hljs-number">5</span>b-<span class="hljs-number">0.030181</span><span class="hljs-number">0.341696</span><br><span class="hljs-number">6</span>b-<span class="hljs-number">0.194018</span><span class="hljs-number">0.022650</span><br><span class="hljs-number">7</span>b-<span class="hljs-number">0.487371</span><span class="hljs-number">0.285495</span><br>grouped = df.groupby(<span class="hljs-string">&quot;category&quot;</span>)<br>get_wavg = <span class="hljs-keyword">lambda</span> x:np.average(x[<span class="hljs-string">&quot;data&quot;</span>],weights=x[<span class="hljs-string">&quot;weights&quot;</span>])<br>grouped.apply(get_wavg)<br>category<br>a    <span class="hljs-number">0.064764</span><br>b   -<span class="hljs-number">0.237579</span><br>dtype: float64<br></code></pre></td></tr></table></figure><h4 id="组级别的线性回归">组级别的线性回归</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">import</span> statsmodels.api <span class="hljs-keyword">as</span> sm<span class="hljs-comment">#计量经济学库</span><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">regression</span>(<span class="hljs-params">data,yvar,xvars</span>):<br>    Y = data[yvar]<br>    X = data[xvars]<br>    X[<span class="hljs-string">&quot;intercept&quot;</span>] = <span class="hljs-number">1</span><br>    res = sm.OLS(Y,X).fit()<br>    <span class="hljs-keyword">return</span> res.params<br>grouped = df_t.groupby(<span class="hljs-keyword">lambda</span> x:x.day)<br>grouped.apply(regression,<span class="hljs-number">0</span>,[<span class="hljs-number">1</span>])<br></code></pre></td></tr></table></figure>]]></content>
    
    
    <categories>
      
      <category>Python</category>
      
      <category>pandas</category>
      
    </categories>
    
    
    <tags>
      
      <tag>Python</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>LATEX插图</title>
    <link href="/posts/24447.html"/>
    <url>/posts/24447.html</url>
    
    <content type="html"><![CDATA[<hr><div class="note note-success">            <p>数学建模 latex</p>          </div><h3 id="数学建模之latex插图入门">数学建模之latex插图入门</h3><p>导言区 <figure class="highlight latex"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs latex"><span class="hljs-keyword">\usepackage</span>&#123;graphicx&#125;<br><span class="hljs-keyword">\usepackage</span>&#123;subfigure&#125;<br><span class="hljs-keyword">\graphicspath</span>&#123;&#123;figures/&#125;&#125;<span class="hljs-comment">%指定插图路径</span><br></code></pre></td></tr></table></figure></p><h4 id="一行只插入一个图片">一行只插入一个图片</h4><figure class="highlight latex"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><code class="hljs latex"><span class="hljs-keyword">\begin</span>&#123;figure&#125;[H]<br>    <span class="hljs-keyword">\centering</span><span class="hljs-keyword">\label</span>&#123;图&#125;<br>    <span class="hljs-keyword">\includegraphics</span>[width=0.9<span class="hljs-keyword">\linewidth</span>]&#123;location&#125;<br>    <span class="hljs-keyword">\caption</span>&#123;位置说明图&#125;<br><span class="hljs-keyword">\end</span>&#123;figure&#125;<br></code></pre></td></tr></table></figure><p>其中[H]是浮动体控制图片位置。此处记得[width=0.9]，占用行宽的0.9，图片展示效果更佳美观。{location}里面为图片名字，在导言区已经指定图片路径。</p><p><img src="https://pjs-1312672154.cos.ap-shanghai.myqcloud.com/QQ截图20220701213006.png"></p><h4 id="并排插入图片">并排插入图片</h4><figure class="highlight latex"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><code class="hljs latex"><span class="hljs-keyword">\begin</span>&#123;figure&#125;[H]<br><span class="hljs-keyword">\centering</span><br><span class="hljs-keyword">\subfigure</span>[figure1]<br>&#123;<br><span class="hljs-keyword">\begin</span>&#123;minipage&#125;[b]&#123;.45<span class="hljs-keyword">\linewidth</span>&#125;<span class="hljs-comment">%表示该图片会占用该行的0.45空间</span><br><span class="hljs-keyword">\centering</span><br><span class="hljs-keyword">\includegraphics</span>[scale=0.4]&#123;location&#125;<br><span class="hljs-keyword">\end</span>&#123;minipage&#125;<br>&#125;<br><span class="hljs-keyword">\subfigure</span>[figure2]<span class="hljs-comment">%此处figure2为子图的单独序号</span><br>&#123;<br><span class="hljs-keyword">\begin</span>&#123;minipage&#125;[b]&#123;.45<span class="hljs-keyword">\linewidth</span>&#125;<br><span class="hljs-keyword">\centering</span><br><span class="hljs-keyword">\includegraphics</span>[scale=0.4]&#123;location&#125;<br><span class="hljs-keyword">\end</span>&#123;minipage&#125;<br>&#125;<br><span class="hljs-keyword">\caption</span>&#123;位置说明图&#125;<br><span class="hljs-keyword">\end</span>&#123;figure&#125;<br></code></pre></td></tr></table></figure><p>注意：一定要实现安排好图的尺寸。如果一行有两张图的时候0.45空间比例，一行有三张图片时候0.3空间比例，会更佳好看。</p><p><img src="https://pjs-1312672154.cos.ap-shanghai.myqcloud.com/QQ截图20220701213204.png"></p><h4 id="多行多列排版">多行多列排版</h4><figure class="highlight latex"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br></pre></td><td class="code"><pre><code class="hljs latex"><span class="hljs-keyword">\begin</span>&#123;figure&#125;[H]<br><span class="hljs-keyword">\centering</span><br><span class="hljs-keyword">\subfigure</span>[figure1]<br>&#123;<br><span class="hljs-keyword">\begin</span>&#123;minipage&#125;[b]&#123;.45<span class="hljs-keyword">\linewidth</span>&#125;<br><span class="hljs-keyword">\centering</span><br><span class="hljs-keyword">\includegraphics</span>[scale=0.4]&#123;location&#125;<br><span class="hljs-keyword">\end</span>&#123;minipage&#125;<br>&#125;<br><span class="hljs-keyword">\subfigure</span>[figure2]<br>&#123;<br><span class="hljs-keyword">\begin</span>&#123;minipage&#125;[b]&#123;.45<span class="hljs-keyword">\linewidth</span>&#125;<br><span class="hljs-keyword">\centering</span><br><span class="hljs-keyword">\includegraphics</span>[scale=0.4]&#123;location&#125;<br><span class="hljs-keyword">\end</span>&#123;minipage&#125;<br>&#125;<br><span class="hljs-keyword">\subfigure</span>[figure3]<br>&#123;<br><span class="hljs-keyword">\begin</span>&#123;minipage&#125;[b]&#123;.45<span class="hljs-keyword">\linewidth</span>&#125;<br><span class="hljs-keyword">\centering</span><br><span class="hljs-keyword">\includegraphics</span>[scale=0.4]&#123;location&#125;<br><span class="hljs-keyword">\end</span>&#123;minipage&#125;<br>&#125;<br><span class="hljs-keyword">\subfigure</span>[figure4]<br>&#123;<br><span class="hljs-keyword">\begin</span>&#123;minipage&#125;[b]&#123;.45<span class="hljs-keyword">\linewidth</span>&#125;<br><span class="hljs-keyword">\centering</span><br><span class="hljs-keyword">\includegraphics</span>[scale=0.4]&#123;location&#125;<br><span class="hljs-keyword">\end</span>&#123;minipage&#125;<br>&#125;<br><span class="hljs-keyword">\caption</span>&#123;位置说明图&#125;<br><span class="hljs-keyword">\end</span>&#123;figure&#125;<br></code></pre></td></tr></table></figure><p>多行多列排版只是subfigure的堆叠，利用\begin{minipage}[b]{.45}来实现自动换行。</p><p><img src="https://pjs-1312672154.cos.ap-shanghai.myqcloud.com/QQ截图20220701213316.png"></p><h4 id="图片分组显式横排">图片分组显式[横排]</h4><figure class="highlight latex"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br></pre></td><td class="code"><pre><code class="hljs latex"><span class="hljs-keyword">\begin</span>&#123;figure&#125;[H]<br><span class="hljs-keyword">\centering</span><br><span class="hljs-keyword">\subfigure</span>[figure1]<br>&#123;<br><span class="hljs-keyword">\begin</span>&#123;minipage&#125;[b]&#123;.45<span class="hljs-keyword">\linewidth</span>&#125;<br><span class="hljs-keyword">\centering</span><br><span class="hljs-keyword">\includegraphics</span>[scale=0.4]&#123;location&#125;<br><span class="hljs-keyword">\end</span>&#123;minipage&#125;<br><span class="hljs-keyword">\begin</span>&#123;minipage&#125;[b]&#123;.45<span class="hljs-keyword">\linewidth</span>&#125;<br><span class="hljs-keyword">\centering</span><br><span class="hljs-keyword">\includegraphics</span>[scale=0.4]&#123;location&#125;<br><span class="hljs-keyword">\end</span>&#123;minipage&#125;<br>&#125;<br><span class="hljs-keyword">\subfigure</span>[figure2]<br>&#123;<br><span class="hljs-keyword">\begin</span>&#123;minipage&#125;[b]&#123;.45<span class="hljs-keyword">\linewidth</span>&#125;<br><span class="hljs-keyword">\centering</span><br><span class="hljs-keyword">\includegraphics</span>[scale=0.4]&#123;location&#125;<br><span class="hljs-keyword">\end</span>&#123;minipage&#125;<br><span class="hljs-keyword">\begin</span>&#123;minipage&#125;[b]&#123;.45<span class="hljs-keyword">\linewidth</span>&#125;<br><span class="hljs-keyword">\centering</span><br><span class="hljs-keyword">\includegraphics</span>[scale=0.4]&#123;location&#125;<br><span class="hljs-keyword">\end</span>&#123;minipage&#125;<br>&#125;<br><span class="hljs-keyword">\caption</span>&#123;位置说明图&#125;<br><span class="hljs-keyword">\end</span>&#123;figure&#125;<br></code></pre></td></tr></table></figure><p><img src="https://pjs-1312672154.cos.ap-shanghai.myqcloud.com/QQ截图20220701213419.png"></p><h4 id="图片分组显式竖排">图片分组显式[竖排]</h4><figure class="highlight latex"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><code class="hljs latex"><span class="hljs-keyword">\begin</span>&#123;figure&#125;[H]<br><span class="hljs-keyword">\centering</span><br><span class="hljs-keyword">\subfigure</span>[figure1]<br>&#123;<br><span class="hljs-keyword">\begin</span>&#123;minipage&#125;[b]&#123;.45<span class="hljs-keyword">\linewidth</span>&#125;<br><span class="hljs-keyword">\centering</span><br><span class="hljs-keyword">\includegraphics</span>[scale=0.4]&#123;location&#125;<span class="hljs-keyword">\\</span><br><span class="hljs-keyword">\includegraphics</span>[scale=0.4]&#123;location&#125;<br><span class="hljs-keyword">\end</span>&#123;minipage&#125;<br>&#125;<br><span class="hljs-keyword">\subfigure</span>[figure2]<br>&#123;<br><span class="hljs-keyword">\begin</span>&#123;minipage&#125;[b]&#123;.45<span class="hljs-keyword">\linewidth</span>&#125;<br><span class="hljs-keyword">\centering</span><br><span class="hljs-keyword">\includegraphics</span>[scale=0.4]&#123;location&#125;<span class="hljs-keyword">\\</span><br><span class="hljs-keyword">\includegraphics</span>[scale=0.4]&#123;location&#125;<br><span class="hljs-keyword">\end</span>&#123;minipage&#125;<br>&#125;<br><span class="hljs-keyword">\caption</span>&#123;位置说明图&#125;<br><span class="hljs-keyword">\end</span>&#123;figure&#125;<br></code></pre></td></tr></table></figure><p><img src="https://pjs-1312672154.cos.ap-shanghai.myqcloud.com/QQ截图20220701213429.png"></p>]]></content>
    
    
    <categories>
      
      <category>数学建模</category>
      
      <category>LATEX</category>
      
    </categories>
    
    
    <tags>
      
      <tag>数学建模</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>LATEX表格</title>
    <link href="/posts/24312.html"/>
    <url>/posts/24312.html</url>
    
    <content type="html"><![CDATA[<hr><div class="note note-success">            <p>数学建模 latex</p>          </div><h3 id="建模中可能用到的latex表格">建模中可能用到的LATEX表格</h3><h4 id="tabular环境">tabular环境</h4><p>其一般输入格式如下：</p><ul><li>特殊符号:\表示换行，&amp;表示分隔单元格</li><li>垂直对齐方式：可选参数，一般很少用到：t按表格顶部对齐，顶部是表格的第一行或表线；b按表格底部对齐，底部是表格的最后一行或表线；默认 垂直居中</li><li>列格式：l左，c中，r右对齐</li></ul><p>注：&amp;和\具有分组作用，每个单元格中可以添加一些设置命令（单元格中不能用\换行）</p><figure class="highlight latex"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><code class="hljs latex"><span class="hljs-keyword">\begin</span>&#123;tabular&#125;&#123;lcr&#125;<br><span class="hljs-keyword">\bfseries</span> left <span class="hljs-built_in">&amp;</span><span class="hljs-keyword">\bfseries</span> center <span class="hljs-built_in">&amp;</span><span class="hljs-keyword">\bfseries</span> right<span class="hljs-keyword">\\</span><br>左对齐 <span class="hljs-built_in">&amp;</span> 居中 <span class="hljs-built_in">&amp;</span> 右对齐<span class="hljs-keyword">\\</span><br><span class="hljs-keyword">\end</span>&#123;tabular&#125;<br></code></pre></td></tr></table></figure><p>注：</p><p><img src="https://pjs-1312672154.cos.ap-shanghai.myqcloud.com/QQ截图20220701163516.png"></p><p>在列表格说明中用|表示画一条竖线，在表格的行尾用.</p><figure class="highlight latex"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><code class="hljs latex"><span class="hljs-keyword">\begin</span>&#123;tabular&#125;&#123;|l|c|r|&#125;<br><span class="hljs-keyword">\hline</span><br><span class="hljs-keyword">\bfseries</span> left <span class="hljs-built_in">&amp;</span><span class="hljs-keyword">\bfseries</span> center <span class="hljs-built_in">&amp;</span><span class="hljs-keyword">\bfseries</span> right<span class="hljs-keyword">\\</span><span class="hljs-keyword">\hline</span><br>左对齐 <span class="hljs-built_in">&amp;</span> 居中 <span class="hljs-built_in">&amp;</span> 右对齐<span class="hljs-keyword">\\</span><span class="hljs-keyword">\hline</span><br><span class="hljs-keyword">\end</span>&#123;tabular&#125;<br></code></pre></td></tr></table></figure><ul><li>h为horizontal</li></ul><p><img src="https://pjs-1312672154.cos.ap-shanghai.myqcloud.com/QQ截图20220701164148.png"></p><p>行内单元格合并命令：.</p><figure class="highlight latex"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><code class="hljs latex"><span class="hljs-keyword">\begin</span>&#123;tabular&#125;&#123;|c|c|&#125;<br><span class="hljs-keyword">\hline</span><br><span class="hljs-keyword">\multicolumn</span>&#123;2&#125;&#123;|c|&#125;&#123;成绩&#125;<span class="hljs-keyword">\\</span><br><span class="hljs-keyword">\hline</span><br>语文 <span class="hljs-built_in">&amp;</span> 数学<span class="hljs-keyword">\\</span><span class="hljs-keyword">\hline</span><br>97 <span class="hljs-built_in">&amp;</span> 100<span class="hljs-keyword">\\</span><span class="hljs-keyword">\hline</span><br><span class="hljs-keyword">\end</span>&#123;tabular&#125;<br></code></pre></td></tr></table></figure><p><img src="https://pjs-1312672154.cos.ap-shanghai.myqcloud.com/QQ截图20220701164856.png"></p><p>此合并命令还可以“合并”一个单元格，用于更改此单元格的格式。</p><figure class="highlight latex"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><code class="hljs latex"><span class="hljs-keyword">\begin</span>&#123;tabular&#125;&#123;|c|c|&#125;<br><span class="hljs-keyword">\hline</span><br><span class="hljs-keyword">\multicolumn</span>&#123;2&#125;&#123;|c|&#125;&#123;成绩&#125;<span class="hljs-keyword">\\</span><br><span class="hljs-keyword">\hline</span><br>语文 <span class="hljs-built_in">&amp;</span> 数学<span class="hljs-keyword">\\</span><span class="hljs-keyword">\hline</span><br><span class="hljs-keyword">\multicolumn</span>&#123;1&#125;&#123;|r|&#125;&#123;97&#125; <span class="hljs-built_in">&amp;</span> <span class="hljs-keyword">\multicolumn</span>&#123;1&#125;&#123;r|&#125;&#123;100&#125;<span class="hljs-keyword">\\</span><span class="hljs-keyword">\hline</span><br><span class="hljs-keyword">\end</span>&#123;tabular&#125;<br></code></pre></td></tr></table></figure><p><img src="https://pjs-1312672154.cos.ap-shanghai.myqcloud.com/QQ截图20220701165455.png"></p><p>,画水平表格线，但是需要指定划线的起始和终止列号。</p><figure class="highlight latex"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><code class="hljs latex"><span class="hljs-keyword">\begin</span>&#123;tabular&#125;&#123;|c|r|r|&#125;<br><span class="hljs-keyword">\hline</span><br> <span class="hljs-built_in">&amp;</span><span class="hljs-keyword">\multicolumn</span>&#123;2&#125;&#123;|c|&#125;&#123;成绩&#125;<span class="hljs-keyword">\\</span><br><span class="hljs-keyword">\cline</span>&#123;2-3&#125;<br>姓名<span class="hljs-built_in">&amp;</span>语文 <span class="hljs-built_in">&amp;</span> 数学<span class="hljs-keyword">\\</span><span class="hljs-keyword">\hline</span><br>小明<span class="hljs-built_in">&amp;</span><span class="hljs-keyword">\multicolumn</span>&#123;1&#125;&#123;|r|&#125;&#123;97&#125; <span class="hljs-built_in">&amp;</span> <span class="hljs-keyword">\multicolumn</span>&#123;1&#125;&#123;r|&#125;&#123;100&#125;<span class="hljs-keyword">\\</span><span class="hljs-keyword">\hline</span><br><span class="hljs-keyword">\end</span>&#123;tabular&#125;<br></code></pre></td></tr></table></figure><p><img src="https://pjs-1312672154.cos.ap-shanghai.myqcloud.com/QQ截图20220701181818.png"></p><p>列内单元格合并：需要加载multirow宏包，命令为:</p><p>:内容达到指定宽度后会自动换行；</p><p>*{<内容>}：单元格的宽度即为输入内容的宽度.</内容></p><figure class="highlight latex"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><code class="hljs latex"><span class="hljs-comment">%导言区 \usepackage&#123;multirow&#125;</span><br><span class="hljs-keyword">\begin</span>&#123;tabular&#125;&#123;|c|r|r|&#125;<br><span class="hljs-keyword">\hline</span><br> <span class="hljs-keyword">\multirow</span>&#123;2&#125;*&#123;姓名&#125;<span class="hljs-built_in">&amp;</span><span class="hljs-keyword">\multicolumn</span>&#123;2&#125;&#123;|c|&#125;&#123;成绩&#125;<span class="hljs-keyword">\\</span><br><span class="hljs-keyword">\cline</span>&#123;2-3&#125;<br><span class="hljs-built_in">&amp;</span>语文 <span class="hljs-built_in">&amp;</span> 数学<span class="hljs-keyword">\\</span><span class="hljs-keyword">\hline</span><br>小明<span class="hljs-built_in">&amp;</span><span class="hljs-keyword">\multicolumn</span>&#123;1&#125;&#123;|r|&#125;&#123;97&#125; <span class="hljs-built_in">&amp;</span> <span class="hljs-keyword">\multicolumn</span>&#123;1&#125;&#123;r|&#125;&#123;100&#125;<span class="hljs-keyword">\\</span><span class="hljs-keyword">\hline</span><br><span class="hljs-keyword">\end</span>&#123;tabular&#125;<br></code></pre></td></tr></table></figure><p><img src="https://pjs-1312672154.cos.ap-shanghai.myqcloud.com/QQ截图20220701182442.png"></p><h4 id="tabularx环境">tabularx环境</h4><p>tabularx宏包提供tabularx环境，X列格式说明符（列宽自动延伸）.</p><figure class="highlight latex"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><code class="hljs latex"><span class="hljs-comment">% 导言区 \usepackage&#123;tabularx&#125;</span><br><span class="hljs-keyword">\begin</span>&#123;tabularx&#125;&#123;<span class="hljs-keyword">\textwidth</span>&#125;&#123;|c|c|X|X|X|X|&#125;<br><span class="hljs-keyword">\hline</span><br>数字<span class="hljs-built_in">&amp;</span>1<span class="hljs-built_in">&amp;</span>2<span class="hljs-built_in">&amp;</span>3<span class="hljs-built_in">&amp;</span>4<span class="hljs-built_in">&amp;</span>5<span class="hljs-keyword">\\</span><span class="hljs-keyword">\hline</span><br>字母<span class="hljs-built_in">&amp;</span>A<span class="hljs-built_in">&amp;</span>B<span class="hljs-built_in">&amp;</span>C<span class="hljs-built_in">&amp;</span>D<span class="hljs-built_in">&amp;</span>E<span class="hljs-keyword">\\</span><span class="hljs-keyword">\hline</span><br>天干<span class="hljs-built_in">&amp;</span>甲<span class="hljs-built_in">&amp;</span>乙<span class="hljs-built_in">&amp;</span>丙<span class="hljs-built_in">&amp;</span>丁<span class="hljs-built_in">&amp;</span>戊<span class="hljs-keyword">\\</span><span class="hljs-keyword">\hline</span><br><span class="hljs-keyword">\end</span>&#123;tabularx&#125;<br></code></pre></td></tr></table></figure><p>内部单元格默认左对齐.</p><p><img src="https://pjs-1312672154.cos.ap-shanghai.myqcloud.com/QQ截图20220701183714.png"></p><p>可以看出只有前两列没有列宽自动延伸</p><h4 id="三线式表格">三线式表格</h4><p>booktabs宏包提供如下命令：</p><ul><li>,画表格顶部粗线；</li><li>,画表格中间细线；</li><li>,画表格底部粗线;</li><li>,与</li></ul><p>控制表格在本页的显式位置需要table环境，参数有htbp四种，分别表示here,top,bottom,float。table环境可以通过.</p><figure class="highlight latex"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><code class="hljs latex"><span class="hljs-comment">% 导言区 \usepackage&#123;float&#125;</span><br>通过计算，我们得到六个种类之间的相对的<span class="hljs-built_in">$</span>SID<span class="hljs-built_in">$</span>值,见下表:<span class="hljs-keyword">\par</span><br><span class="hljs-keyword">\begin</span>&#123;table&#125;[H]<span class="hljs-comment">%控制在当前位置显式</span><br><span class="hljs-keyword">\centering</span><span class="hljs-keyword">\caption</span>&#123;六个种类的<span class="hljs-built_in">$</span>SID<span class="hljs-built_in">$</span>表&#125;<span class="hljs-keyword">\label</span>&#123;SID表&#125;<br><span class="hljs-keyword">\begin</span>&#123;tabularx&#125;&#123;<span class="hljs-keyword">\textwidth</span>&#125;&#123;XXXXXXX&#125;<br><span class="hljs-keyword">\toprule</span><br>       <span class="hljs-built_in">&amp;</span> 种类一 <span class="hljs-built_in">&amp;</span> 种类二 <span class="hljs-built_in">&amp;</span> 种类三 <span class="hljs-built_in">&amp;</span>种类四<span class="hljs-built_in">&amp;</span>种类五<span class="hljs-built_in">&amp;</span>种类六<span class="hljs-keyword">\\</span><span class="hljs-keyword">\midrule</span><br>     种类一<span class="hljs-built_in">&amp;</span>0<span class="hljs-built_in">&amp;</span>0.0344<span class="hljs-built_in">&amp;</span>0.0362<span class="hljs-built_in">&amp;</span>0.2190<span class="hljs-built_in">&amp;</span>0.0460<span class="hljs-built_in">&amp;</span>0.1415<span class="hljs-keyword">\\</span><br>     种类二<span class="hljs-built_in">&amp;</span>0.0344<span class="hljs-built_in">&amp;</span>0<span class="hljs-built_in">&amp;</span>0.0118<span class="hljs-built_in">&amp;</span>0.1571<span class="hljs-built_in">&amp;</span>0.0109<span class="hljs-built_in">&amp;</span>0.0907<span class="hljs-keyword">\\</span><br>     种类三<span class="hljs-built_in">&amp;</span>0.0362<span class="hljs-built_in">&amp;</span>0.0118<span class="hljs-built_in">&amp;</span>0<span class="hljs-built_in">&amp;</span>0.2047<span class="hljs-built_in">&amp;</span>0.0028<span class="hljs-built_in">&amp;</span>0.1233 <span class="hljs-keyword">\\</span><br>     种类四<span class="hljs-built_in">&amp;</span>0.2190<span class="hljs-built_in">&amp;</span>0.1571<span class="hljs-built_in">&amp;</span>0.2047<span class="hljs-built_in">&amp;</span>0<span class="hljs-built_in">&amp;</span>0.1997<span class="hljs-built_in">&amp;</span> 0.1271 <span class="hljs-keyword">\\</span><br>     种类五<span class="hljs-built_in">&amp;</span>0.0460<span class="hljs-built_in">&amp;</span>0.0109<span class="hljs-built_in">&amp;</span>0.0028<span class="hljs-built_in">&amp;</span>0.1997<span class="hljs-built_in">&amp;</span>0<span class="hljs-built_in">&amp;</span>0.1204<span class="hljs-keyword">\\</span><br>     种类六<span class="hljs-built_in">&amp;</span>0.1415<span class="hljs-built_in">&amp;</span>0.0907<span class="hljs-built_in">&amp;</span>0.1233<span class="hljs-built_in">&amp;</span>0.1271<span class="hljs-built_in">&amp;</span>0.1204<span class="hljs-built_in">&amp;</span>0<span class="hljs-keyword">\\</span><br>     <span class="hljs-keyword">\bottomrule</span> <br><span class="hljs-keyword">\end</span>&#123;tabularx&#125;<br><span class="hljs-keyword">\end</span>&#123;table&#125;<span class="hljs-keyword">\par</span><br>    由表<span class="hljs-keyword">\ref</span>&#123;SID表&#125;可知，种类一、二、三、五与种类四差异最大，数据最不接近，根据推测可能是因为地域原因、地理位置较远；种类一与种类六对种类二的数据<span class="hljs-built_in">$</span>SID<span class="hljs-built_in">$</span>值相对最小，分别为<span class="hljs-built_in">$</span>0.0344<span class="hljs-built_in">$</span>与<span class="hljs-built_in">$</span>0.0907<span class="hljs-built_in">$</span>；而种类二与种类五<span class="hljs-built_in">$</span>SID<span class="hljs-built_in">$</span>值相对较小，分别为<span class="hljs-built_in">$</span>0.0109<span class="hljs-built_in">$</span>与<span class="hljs-built_in">$</span>0.0028<span class="hljs-built_in">$</span>。所以总结:种类一、二、三、五、六地理位置应该相隔不远，环境气候相似，导致中药材的化学组成成分相差不大。<span class="hljs-keyword">\par</span><br></code></pre></td></tr></table></figure><p><img src="https://pjs-1312672154.cos.ap-shanghai.myqcloud.com/QQ截图20220701185515.png"></p><p><img src="https://pjs-1312672154.cos.ap-shanghai.myqcloud.com/QQ截图20220701185522.png"></p><p>给表格添加说明文字</p><p>给表格添加标签方便交叉引用</p>]]></content>
    
    
    <categories>
      
      <category>数学建模</category>
      
      <category>LATEX</category>
      
    </categories>
    
    
    <tags>
      
      <tag>数学建模</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>旅行商问题</title>
    <link href="/posts/11411.html"/>
    <url>/posts/11411.html</url>
    
    <content type="html"><![CDATA[<hr><div class="note note-success">            <p>数学建模 图论 Python</p>          </div><h3 id="旅行商问题tsp问题">旅行商问题(TSP)问题</h3><p>定义:各顶点相异的道路称为轨道.起点和终点重合的道路称为圈.图中含有所有顶点轨道称为Hamilton轨,闭合的Hamilton轨称为Hamilton圈,含有Hamilton圈的图称为Hamilton图.</p><p>一名推销员准备前往若干城市推销产品,然后回到驻地.如何为他设计一条最短的旅行路线(从驻地出发,经过每个城市恰好一次,最后返回驻地)?这个问题称为旅行商问题.用图论的术语,就是在一个赋权完全图中,找出一个有最小权的Hamilton圈.称这种圈为最优圈.目前还没有求解旅行商问题的有效算法.所以希望有一个方法以获得相当好的解.</p><p>例:从北京(Pe)乘飞机到东京(T),纽约(N),墨西哥城(M),伦敦(L),巴黎(Pa)五城市旅游,每城市恰好去一次再回北京,应如何安排旅游线,使旅程最短?用修改圈算法,求一个近似解.各城市之间的航线距离如下表:</p><table><thead><tr class="header"><th></th><th>L</th><th>M</th><th>N</th><th>Pa</th><th>Pe</th><th>T</th></tr></thead><tbody><tr class="odd"><td>L</td><td></td><td>56</td><td>35</td><td>21</td><td>51</td><td>60</td></tr><tr class="even"><td>M</td><td>56</td><td></td><td>21</td><td>57</td><td>78</td><td>70</td></tr><tr class="odd"><td>N</td><td>35</td><td>21</td><td></td><td>36</td><td>68</td><td>68</td></tr><tr class="even"><td>Pa</td><td>21</td><td>57</td><td>36</td><td></td><td>51</td><td>61</td></tr><tr class="odd"><td>Pe</td><td>51</td><td>78</td><td>68</td><td>51</td><td></td><td>13</td></tr><tr class="even"><td>T</td><td>60</td><td>70</td><td>68</td><td>61</td><td>13</td><td></td></tr></tbody></table><h3 id="旅行商问题的数学规划模型">旅行商问题的数学规划模型</h3><p>设城市的个数为<span class="math inline">\(n,d_{ij}\)</span>是两个城市<span class="math inline">\(i\)</span>与<span class="math inline">\(j\)</span>之间的距离,<span class="math inline">\(x_{ij}=0\)</span>或<span class="math inline">\(1\)</span>(1表示走过城市<span class="math inline">\(i\)</span>到城市<span class="math inline">\(j\)</span>的路,0表示没有选择走这条路),则有: <span class="math display">\[\min \sum_{i\ne j}d_{ij}x_{ij},\\s.t.\begin{cases}\sum\limits_{j=1}^{n}x_{ij}=1,i=1,2,\dots,n,\text{(每个点只有一条边出去)}\\\sum\limits_{i=1}^{n}x_{ij}=1,j=1,2,\dots,n,\text{(每个点只有一条边进去)}\\\sum\limits_{i,j\inE}\le \vert s\vert-1,2\le\vert s\vert \len-1,s\subset\{1,2,\dots,n\},\text{(除起点和终点外,各边不构成圈)}\\x_{ij}\in\{0,1\},i,j=1,2,\dots,n,i\ne j\end{cases}\]</span></p><blockquote><p>下面为遗传算法寻找边权最小Hamilto圈的代码</p></blockquote><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">import</span> numpy <span class="hljs-keyword">as</span> np<br><span class="hljs-comment"># 初始化种群</span><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">init</span>(<span class="hljs-params">NP</span>):<br>    res = []<br>    <span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(NP):<br>        x = np.random.uniform(size=<span class="hljs-number">5</span>)<br>        temp_0 = np.array([<span class="hljs-number">0</span>])<br>        temp_1 = np.array([<span class="hljs-number">1</span>])<br>        temp_arr = np.concatenate((temp_0,x,temp_1))<br>        res.append(temp_arr)<br>    <span class="hljs-keyword">return</span> np.array(res)<br><span class="hljs-comment">#解码</span><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">decoding</span>(<span class="hljs-params">code_arr</span>):<br>    index = np.argsort(code_arr)<br>    <span class="hljs-keyword">return</span> index<br><span class="hljs-comment">#适值函数</span><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">fitness_function</span>(<span class="hljs-params">index_arr,W</span>):<br>    x = index_arr[::-<span class="hljs-number">1</span>]<br>    x[<span class="hljs-number">0</span>] = <span class="hljs-number">0</span><br>    i = <span class="hljs-number">0</span><br>    res = <span class="hljs-number">0</span><br>    <span class="hljs-keyword">while</span> i&lt;<span class="hljs-built_in">len</span>(x)-<span class="hljs-number">1</span>:<br>        res += W[x[i],x[i+<span class="hljs-number">1</span>]]<br>        i += <span class="hljs-number">1</span><br>    <span class="hljs-keyword">return</span> res <span class="hljs-comment">#适应值</span><br><span class="hljs-keyword">import</span> random<br><span class="hljs-keyword">def</span> <span class="hljs-title function_">crossover</span>(<span class="hljs-params">gene_f,gene_m,p_c</span>):<span class="hljs-comment">#交叉</span><br>    seed = np.random.uniform()<br>    <span class="hljs-keyword">if</span> seed&lt;p_c:<br>        cross_p = random.randint(<span class="hljs-number">1</span>,<span class="hljs-built_in">len</span>(gene_f)-<span class="hljs-number">1</span>)<br>        gene_1 = np.concatenate((gene_f[<span class="hljs-number">0</span>:cross_p],gene_m[cross_p:]))<br>        gene_2 = np.concatenate((gene_m[<span class="hljs-number">0</span>:cross_p],gene_f[cross_p:]))<br>        <span class="hljs-keyword">return</span> gene_1,gene_2<br>    <span class="hljs-keyword">else</span>:<br>        <span class="hljs-keyword">return</span> gene_f,gene_m<br><span class="hljs-keyword">def</span> <span class="hljs-title function_">mutation</span>(<span class="hljs-params">gene,p_m</span>):<span class="hljs-comment">#突变</span><br>    seed = np.random.uniform()<br>    <span class="hljs-keyword">if</span> seed&lt;p_m:<br>        mutation_p = np.sort(np.random.randint(<span class="hljs-number">1</span>,<span class="hljs-built_in">len</span>(gene)-<span class="hljs-number">2</span>,size=<span class="hljs-number">3</span>))<br>        gene_new = np.concatenate((gene[<span class="hljs-number">0</span>:mutation_p[<span class="hljs-number">0</span>]],gene[mutation_p[<span class="hljs-number">1</span>]+<span class="hljs-number">1</span>:mutation_p[<span class="hljs-number">2</span>]+<span class="hljs-number">1</span>],gene[mutation_p[<span class="hljs-number">0</span>]:mutation_p[<span class="hljs-number">1</span>]+<span class="hljs-number">1</span>],gene[mutation_p[<span class="hljs-number">2</span>]+<span class="hljs-number">1</span>:]))<br>        <span class="hljs-keyword">return</span> gene_new<br>    <span class="hljs-keyword">else</span>:<br>        <span class="hljs-keyword">return</span> gene_new<br><span class="hljs-keyword">def</span> <span class="hljs-title function_">selection</span>(<span class="hljs-params">population,W,NP</span>):<br>    fit_value = []<br>    <span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> population:<br>        fit_value.append(fitness_function(decoding(i),W))<br>    fit_arr = np.array(fit_value)<br>    index = np.argsort(fit_arr)<br>    res = []<br>    <span class="hljs-keyword">for</span> j <span class="hljs-keyword">in</span> index:<br>        res.append(population[j,:])<br>    <span class="hljs-keyword">return</span> np.array(res[<span class="hljs-number">0</span>:NP+<span class="hljs-number">1</span>])<br><span class="hljs-keyword">def</span> <span class="hljs-title function_">genetic_algo</span>(<span class="hljs-params">W,N,NP,p_m,p_c</span>):<br>    popu = init(NP)<br>    i = <span class="hljs-number">1</span><br>    <span class="hljs-keyword">while</span> i&lt;=N:<br>        <span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(NP*<span class="hljs-number">2</span>):<br>            num_1,num_2=np.random.randint(<span class="hljs-number">0</span>,NP-<span class="hljs-number">1</span>,size=<span class="hljs-number">2</span>)<br>            gene_1,gene_2=crossover(popu[num_1],popu[num_2],p_c)<br>            popu[num_1] = gene_1<br>            popu[num_2] = gene_2 <span class="hljs-comment">#没有留父代</span><br>        <span class="hljs-keyword">for</span> j <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(NP):<br>            num = np.random.randint(<span class="hljs-number">0</span>,NP-<span class="hljs-number">1</span>)<br>            gene_new = mutation(popu[num],p_m)<br>            popu[num] = gene_new<br>        popu = selection(popu,W,NP)<br>        i += <span class="hljs-number">1</span><br>    res = decoding(selection(popu,W,NP)[<span class="hljs-number">0</span>])[::-<span class="hljs-number">1</span>]<br>    <span class="hljs-keyword">return</span> res<br>W = np.array([[<span class="hljs-number">0</span>,<span class="hljs-number">56</span>,<span class="hljs-number">35</span>,<span class="hljs-number">21</span>,<span class="hljs-number">51</span>,<span class="hljs-number">60</span>]<br>            ,[<span class="hljs-number">56</span>,<span class="hljs-number">0</span>,<span class="hljs-number">21</span>,<span class="hljs-number">57</span>,<span class="hljs-number">78</span>,<span class="hljs-number">70</span>]<br>            ,[<span class="hljs-number">35</span>,<span class="hljs-number">21</span>,<span class="hljs-number">0</span>,<span class="hljs-number">36</span>,<span class="hljs-number">68</span>,<span class="hljs-number">68</span>]<br>            ,[<span class="hljs-number">21</span>,<span class="hljs-number">57</span>,<span class="hljs-number">36</span>,<span class="hljs-number">0</span>,<span class="hljs-number">51</span>,<span class="hljs-number">61</span>]<br>            ,[<span class="hljs-number">51</span>,<span class="hljs-number">78</span>,<span class="hljs-number">68</span>,<span class="hljs-number">51</span>,<span class="hljs-number">0</span>,<span class="hljs-number">13</span>]<br>            ,[<span class="hljs-number">60</span>,<span class="hljs-number">70</span>,<span class="hljs-number">68</span>,<span class="hljs-number">61</span>,<span class="hljs-number">13</span>,<span class="hljs-number">0</span>]])<br>res = genetic_algo(W,<span class="hljs-number">100</span>,<span class="hljs-number">100</span>,<span class="hljs-number">1</span>,<span class="hljs-number">0.05</span>)<br>fitness_function(res[::-<span class="hljs-number">1</span>],W)<br></code></pre></td></tr></table></figure><figure class="highlight apache"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs apache"><span class="hljs-attribute">array</span>([<span class="hljs-number">6</span>, <span class="hljs-number">2</span>, <span class="hljs-number">1</span>, <span class="hljs-number">5</span>, <span class="hljs-number">4</span>, <span class="hljs-number">3</span>, <span class="hljs-number">0</span>], dtype=int64)<br></code></pre></td></tr></table></figure><figure class="highlight"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs">211<br></code></pre></td></tr></table></figure>]]></content>
    
    
    <categories>
      
      <category>数学建模</category>
      
      <category>图论</category>
      
    </categories>
    
    
    <tags>
      
      <tag>数学建模</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>马尔科夫预测</title>
    <link href="/posts/30115.html"/>
    <url>/posts/30115.html</url>
    
    <content type="html"><![CDATA[<hr><div class="note note-success">            <p>数学建模 预测 Python</p>          </div><h3 id="马尔科夫预测">马尔科夫预测</h3><h4 id="马尔科夫链的定义">马尔科夫链的定义</h4><p>现实世界中有很多这样的现象,某一系统在已知现在情况的条件下系统未来时刻的情况只与现在有关,而与过去的历史无直接关系.比如研究一个商店的累计销售额.如果现在时刻的累计销售额已知,则未来某一时刻的累计销售额与现在时刻以前的任一时刻累计销售额无关.描述这类随机现象的数学模型称为马尔科夫模型,简称马氏模型.</p><p>定义:设<span class="math inline">\(\{X_n,n=1,2,\dots\}\)</span>是一个随机序列,状态空间<span class="math inline">\(E\)</span>为有限或者可列,对于任意的正整数<span class="math inline">\(m,n\)</span>,若<span class="math inline">\(i,j,i_k\in E(k=1,\dots,n-1),\)</span>有<span class="math inline">\(P\{X_{n+m}=j\vertX_n=i,X_{n-1}=i_{n-1},\cdots,X_{1}=i_1\}=P\{X_{n+m}=j\vertX_n=i\}\)</span>,则称<span class="math inline">\(\{X_n,n=1,2,\dots\}\)</span>为一个马尔科夫链.事实上,可以证明若上述等式对于<span class="math inline">\(m=1\)</span>成立,则它对于任意的正整数<span class="math inline">\(m\)</span>也成立.因此,只要当<span class="math inline">\(m=1\)</span>时上述等式成立,就可以称随机序列<span class="math inline">\(\{X_n,n=1,2,\dots\}\)</span>具有马氏性</p><p>定义:设<span class="math inline">\(\{X_n,n=1,2,\dots\}\)</span>是一个马氏链.如果上述等式右边的条件概率与<span class="math inline">\(n\)</span>无关,即 <span class="math display">\[P\{X_{n+m}=j\vert X_n=i\} = p_{ij}(m)\]</span> 则称<span class="math inline">\(\{X_n,n=1,2,\dots\}\)</span>为时齐的马氏链.称<span class="math inline">\(p_{ij}(m)\)</span>为系统由状态<span class="math inline">\(i\)</span>经过<span class="math inline">\(m\)</span>个时间间隔转移到状态<span class="math inline">\(j\)</span>的转移概率.式<span class="math inline">\((1)\)</span>称为时齐性,它的含义是系统由状态<span class="math inline">\(i\)</span>到状态<span class="math inline">\(j\)</span>的转移概率只依赖于时间间隔的长短,与起始的时刻无关.下面介绍的马氏链假定都是时齐的,为了行文方便省略"时齐"二字.</p><h4 id="转移状态矩阵及柯尔莫哥洛夫定理">转移状态矩阵及柯尔莫哥洛夫定理</h4><p>对于一个马尔科夫链<span class="math inline">\(\{X_n,n=1,2,\dots\}\)</span>,称以<span class="math inline">\(m\)</span>步转移概率<span class="math inline">\(p_{ij}(m)\)</span>为元素的矩阵<span class="math inline">\(P(m)=(p_{ij}(m))\)</span>为马尔科夫链的<span class="math inline">\(m\)</span>步转移矩阵.当<span class="math inline">\(m=1\)</span>时,记<span class="math inline">\(P(1)=P\)</span>称为马尔科夫链的一步状态转移矩阵,或简称转移矩阵.它们具有以下三个基本性质:</p><p><span class="math inline">\((1)\)</span>对一切<span class="math inline">\(i,j\in E,0\le p_{ij}(m)\le1\)</span></p><p><span class="math inline">\((2)\)</span>对一切<span class="math inline">\(i\in E,\sum\limits_{j\inE}P_{ij}(m)=1\)</span></p><p><span class="math inline">\((3)\)</span>对一切<span class="math inline">\(i,j\inE,p_{ij}(0)=\delta_{ij}=\begin{cases}1&amp;,\text{当}i=j\\0,&amp;,\text{当}i\nej\end{cases}\)</span></p><p>当实际问题可以用马尔科夫链来描述时,首先需要确定它的状态空间集参数集合,然后确定它的一步转移概率.关于这一概率的确定,可以由问题的内在规律得到,也可以由过去的经验给出,还可以根据观测数据来估计.</p><p>定理(柯尔莫哥洛夫-----开普曼定理):设<span class="math inline">\(\{X_n,n=1,2,\dots\}\)</span>是一个马尔科夫链,其状态空间<span class="math inline">\(E=\{1,2,\dots\},\)</span>则对任意的正整数<span class="math inline">\(m,n\)</span>,有 <span class="math display">\[p_{ij}(n+m)=\sum\limits_{k\in E}p_{ik}(n)p_{kj}(m),\quad where\,i,j\in E\]</span> 定理:设<span class="math inline">\(P\)</span>是一步马氏链转移矩阵(<span class="math inline">\(P\)</span>的行向量是概率向量),<span class="math inline">\(P^{(0)}\)</span>是初始分布行向量,则第<span class="math inline">\(n\)</span>步的概率分布为 <span class="math display">\[P^{(n)}=P^{(0)}P^{n}\]</span></p><h4 id="转移概率的渐进性质----极限概率分布">转移概率的渐进性质----极限概率分布</h4><p>定义:一个马氏链的转移矩阵<span class="math inline">\(P\)</span>是正则的,当且仅当存在正整数<span class="math inline">\(k\)</span>,使<span class="math inline">\(P^{k}\)</span>的每一个元素都是正数.</p><p>定理:若<span class="math inline">\(P\)</span>是一个马氏链的正则阵,则:</p><p>(1)<span class="math inline">\(P\)</span>有唯一的不动点向量<span class="math inline">\(W\)</span>,<span class="math inline">\(W\)</span>的每一个分量为正.</p><p><span class="math inline">\((2)P\)</span>的<span class="math inline">\(n\)</span>次幂(n为正整数)随<span class="math inline">\(n\)</span>的增加趋近于矩阵<span class="math inline">\(\overline{W}\)</span>,<span class="math inline">\(\overline{W}\)</span>的每一行向量均等于不动点向量<span class="math inline">\(W\)</span></p><p>一般地,设马氏链的状态空间为<span class="math inline">\(E\)</span>,如果对于所有的<span class="math inline">\(i,j\in E\)</span>,状态概率<span class="math inline">\(p_{ij}(n)\)</span>存在极限 <span class="math display">\[\lim\limits_{n\to\infty}p_{ij}(n)=\pi_j\]</span> 或 <span class="math display">\[P(n)=P^{n}\longrightarrow\begin{bmatrix}\pi_1&amp;\pi_2&amp;\cdots&amp;\pi_j&amp;\cdots\\\pi_1&amp;\pi_2&amp;\cdots&amp;\pi_j&amp;\cdots\\\cdots&amp;\cdots&amp;\cdots&amp;\cdots&amp;\cdots\\\pi_1&amp;\pi_2&amp;\cdots&amp;\pi_j&amp;\cdots\\\cdots&amp;\cdots&amp;\cdots&amp;\cdots&amp;\cdots\\\end{bmatrix},\quadn\to\infty\]</span> 则称此链具有遍历性.又若<span class="math inline">\(\sum\limits_{j}\pi_{j}=1\)</span>,则同时称<span class="math inline">\(\pi=[\pi_1,\pi_2,\dots]\)</span>为链的极限分布</p><p>定理:设马氏链<span class="math inline">\(\{X_n,n=1,2,\dots\}\)</span>的状态空间为<span class="math inline">\(E=\{a_1,\dots,a_N\},P=(p_{ij})\)</span>是它的一步转移概率矩阵,如果存在正整数<span class="math inline">\(m\)</span>,使得对任意的<span class="math inline">\(a_i,a_j\in E\)</span>,都有 <span class="math display">\[p_{ij}(m)&gt;0,\,i,j=1,2,\dots,N\]</span> 则此链具有遍历性;且有极限分布<span class="math inline">\(\pi=[\pi_1,\dots,\pi_N],\)</span>它是方程组 <span class="math display">\[\pi = \piP\,\text{或者}\,\pi_j=\sum_{i=1}^{N}\pi_ip_{ij},\quad,j=1,\dots,N\]</span> 的满足条件<span class="math inline">\(\pi_j&gt;0,\sum\limits_{j=1}^{N}\pi_{j}=1\)</span>的唯一解</p><p>例:为适应日益扩大的旅游事业的需要,某城市的甲,乙,丙三个照相馆组成一个联营部,联合经营出租相机的业务.游客可由甲,乙,丙三处任何一处租出相机,用完后,还在三处中任意一处即可.估计其转移概率如下所示.今欲选择其中之一附近设置相机维修点,问该点设在哪一个照相馆为最好?<span class="math display">\[\begin{bmatrix}0.2&amp;0.8&amp;0\\0.8&amp;0&amp;0.2\\0.1&amp;0.3&amp;0.6\end{bmatrix},\quadwhere\quad p_{ij}\text{表示在}i\text{处租,在}j\text{处还的概率}\]</span> 解:设<span class="math inline">\(\{X_n,n=1,2,\dots\}\)</span>是一个马尔科夫链,表示相机第<span class="math inline">\(n\)</span>次租时在甲,乙,丙馆.已知它是一个马尔科夫链,其转移矩阵为<span class="math inline">\((8)\)</span>.考虑维修点的设置地点问题,实际上要计算这一马尔科夫链的极限概率分布.</p><p>已知状态转移矩阵是正则的,极限概率存在,解方程组 <span class="math display">\[\begin{cases}&amp;p_1=0.2p_1+0.8p_2+0.1p_3,\\&amp;p_2=0.8p_1+0.3p_3,\\&amp;p_3=0.2p_2+0.6p_3,\\&amp;p_1+p_2+p_3=1\end{cases}\]</span> 得极限概率<span class="math inline">\(p_1=0.4146,p_2=0.3902,p_3=0.1951\)</span></p><p>由计算可看出,经过长期经营后,该联营部的每驾照相机还到甲,乙,丙照相馆的概率分别是0.4146,0.3902,0.1951.由于还到甲馆的照相机较多,因此维修点设在甲馆较好.但由于还到乙馆的相机与还到甲馆的相差不多,若是乙的其他因素更为有利的话,比如,交通较甲方便,便于零件的运输,电力供应稳定等等,也可以考虑设在乙馆.</p>]]></content>
    
    
    <categories>
      
      <category>数学建模</category>
      
      <category>预测</category>
      
    </categories>
    
    
    <tags>
      
      <tag>数学建模</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>最小费用流问题</title>
    <link href="/posts/26295.html"/>
    <url>/posts/26295.html</url>
    
    <content type="html"><![CDATA[<hr><div class="note note-success">            <p>数学建模 图论 Python</p>          </div><h3 id="最小费用流问题">最小费用流问题</h3><p>在许多实际问题中,往往还要考虑网络流上流的费用问题.例如,在运输问题中,人们总是希望在完成运输任务的同时,寻求一个能使总费用最小的运输方案.</p><p>设<span class="math inline">\(f_{ij}\)</span>为弧<span class="math inline">\((v_i,v_j)\)</span>上的流量,<span class="math inline">\(b_{ij}\)</span>为弧<span class="math inline">\((v_i,v_j)\)</span>上的单位费用,<span class="math inline">\(c_{ij}\)</span>为弧<span class="math inline">\((v_I,v_j)\)</span>上的容量,则最小费用流问题可以用如下数学模型描述:<span class="math display">\[\min\quad\sum_{(v_i,v_j)\in A}b_{ij}f_{ij},\\s.t. \begin{cases}\sum\limits_{j:(v_i,v_j)\inA}f_{ij}-\sum\limits_{j:(v_j,v_i)\inA}f_{ji}=\begin{cases}v&amp;,i=s\\-v&amp;,i=t\\0&amp;,i\nes,t,\end{cases} \\0\le f_{ij}\le c_{ij},\forall(v_i,v_j)\in A\end{cases}\]</span> 当<span class="math inline">\(v=\)</span>最大流<span class="math inline">\(v_{max}\)</span>时,本问题就是最小费用最大流问题;如果<span class="math inline">\(v&gt;v_{max}\)</span>,本问题无解.</p><p>例:如下图带有运费的网络,求从<span class="math inline">\(v_1\)</span>到<span class="math inline">\(v_6\)</span>的最小费用最大流,其中弧上权重的第一个数字是网络的容量,第二个数字是网络的单位运费.</p><p><img src="https://pjs-1312672154.cos.ap-shanghai.myqcloud.com/figure8.png"></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">import</span> numpy <span class="hljs-keyword">as</span> np<br><span class="hljs-keyword">import</span> networkx <span class="hljs-keyword">as</span> nx<br><span class="hljs-keyword">from</span> networkx.algorithms.matching <span class="hljs-keyword">import</span> max_weight_matching<br><span class="hljs-keyword">import</span> seaborn <span class="hljs-keyword">as</span> sns<br><span class="hljs-keyword">import</span> matplotlib.pyplot <span class="hljs-keyword">as</span> plt<br><span class="hljs-keyword">import</span> pandas <span class="hljs-keyword">as</span> pd<br>sns.set_theme(style=<span class="hljs-string">&quot;dark&quot;</span>)<span class="hljs-comment">#用来设置主题背景</span><br>plt.rcParams[<span class="hljs-string">&quot;font.sans-serif&quot;</span>] = [<span class="hljs-string">&quot;SimHei&quot;</span>] <span class="hljs-comment">#用来正常显示中文标签</span><br>plt.rcParams[<span class="hljs-string">&quot;axes.unicode_minus&quot;</span>] = <span class="hljs-literal">False</span> <span class="hljs-comment">#用来正常显示负号</span><br>L = [(<span class="hljs-number">1</span>,<span class="hljs-number">2</span>,<span class="hljs-number">5</span>,<span class="hljs-number">3</span>),(<span class="hljs-number">1</span>,<span class="hljs-number">3</span>,<span class="hljs-number">3</span>,<span class="hljs-number">6</span>),(<span class="hljs-number">2</span>,<span class="hljs-number">4</span>,<span class="hljs-number">2</span>,<span class="hljs-number">8</span>),(<span class="hljs-number">3</span>,<span class="hljs-number">2</span>,<span class="hljs-number">1</span>,<span class="hljs-number">2</span>),(<span class="hljs-number">3</span>,<span class="hljs-number">5</span>,<span class="hljs-number">4</span>,<span class="hljs-number">2</span>),(<span class="hljs-number">4</span>,<span class="hljs-number">3</span>,<span class="hljs-number">1</span>,<span class="hljs-number">1</span>),(<span class="hljs-number">4</span>,<span class="hljs-number">5</span>,<span class="hljs-number">3</span>,<span class="hljs-number">4</span>),(<span class="hljs-number">4</span>,<span class="hljs-number">6</span>,<span class="hljs-number">2</span>,<span class="hljs-number">10</span>),(<span class="hljs-number">5</span>,<span class="hljs-number">6</span>,<span class="hljs-number">5</span>,<span class="hljs-number">2</span>)] <span class="hljs-comment">#注意此处不能直接由邻接矩阵生成图</span><br>G = nx.DiGraph()<br><span class="hljs-keyword">for</span> k <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(<span class="hljs-built_in">len</span>(L)):<br>    G.add_edge(L[k][<span class="hljs-number">0</span>]-<span class="hljs-number">1</span>,L[k][<span class="hljs-number">1</span>]-<span class="hljs-number">1</span>,capacity=L[k][<span class="hljs-number">2</span>],weight=L[k][<span class="hljs-number">3</span>])<br>mincostFlow = nx.max_flow_min_cost(G,<span class="hljs-number">0</span>,<span class="hljs-number">5</span>)<span class="hljs-comment">#求解网络最小费用最大流问题</span><br>dict_temp = &#123;&#125;<br><span class="hljs-keyword">for</span> i,item <span class="hljs-keyword">in</span> mincostFlow.items():<br>    <span class="hljs-keyword">for</span> j,weight <span class="hljs-keyword">in</span> item.items():<br>        dict_temp[(i,j)] = weight <span class="hljs-comment">#改变字典结构</span><br>plt.figure(dpi=<span class="hljs-number">500</span>)<br>node_labels=<span class="hljs-built_in">dict</span>(<span class="hljs-built_in">zip</span>(<span class="hljs-built_in">range</span>(<span class="hljs-number">6</span>),[<span class="hljs-string">&quot;V&quot;</span>+<span class="hljs-built_in">str</span>(i) <span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(<span class="hljs-number">1</span>,<span class="hljs-number">7</span>)])) <span class="hljs-comment">#构造用于顶点标记的字典</span><br>pos = nx.circular_layout(G)<span class="hljs-comment">#设置布局</span><br>path_edges = [key <span class="hljs-keyword">for</span> key,item <span class="hljs-keyword">in</span> dict_temp.items() <span class="hljs-keyword">if</span> item !=<span class="hljs-number">0</span>]<br>nx.draw_networkx(G,pos,node_size=<span class="hljs-number">270</span>,labels=node_labels) <span class="hljs-comment">#绘制图</span><br>nx.draw_networkx_edge_labels(G,pos,font_size=<span class="hljs-number">10</span>,edge_labels=dict_temp)<span class="hljs-comment">#标记权重</span><br>nx.draw_networkx_edges(G,pos,edgelist=path_edges,edge_color=<span class="hljs-string">&quot;r&quot;</span>,width=<span class="hljs-number">3</span>)<span class="hljs-comment">#标记路径</span><br>plt.savefig(<span class="hljs-string">&quot;figure9.png&quot;</span>)<br>plt.show()<br>mincost = nx.cost_of_flow(G,mincostFlow)<br><span class="hljs-built_in">print</span>(<span class="hljs-string">&quot;最小费用为&#123;&#125;&quot;</span>.<span class="hljs-built_in">format</span>(mincost))<br></code></pre></td></tr></table></figure><figure class="highlight"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs">最小费用为63<br></code></pre></td></tr></table></figure>]]></content>
    
    
    <categories>
      
      <category>数学建模</category>
      
      <category>图论</category>
      
    </categories>
    
    
    <tags>
      
      <tag>数学建模</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>最大流问题</title>
    <link href="/posts/26900.html"/>
    <url>/posts/26900.html</url>
    
    <content type="html"><![CDATA[<hr><div class="note note-success">            <p>数学建模 图论 Python</p>          </div><h3 id="最大流问题">最大流问题</h3><p>许多系统包含了流量问题,如公里系统中有车辆流,金融系统中有现金流等.这些流问题都可归结为网络流问题,且都存在如何安排使流量最大的问题,即最大流问题.</p><p>定义:给定一个有向图<span class="math inline">\(D=(V,A)\)</span>,其中<span class="math inline">\(A\)</span>为弧集,在<span class="math inline">\(V\)</span>中指定一点,称为源(记为<span class="math inline">\(v_S\)</span>),该点只有发出的弧;同时指定一个点为汇(记为<span class="math inline">\(v_t\)</span>),该点只有进入的弧;其余的点叫做中间点,对于每一条弧<span class="math inline">\((v_i,v_j)\in A\)</span>,对应有一个<span class="math inline">\(c(v_i,v_j)\ge0\)</span>称为弧的容量.通常就把这样的有向图<span class="math inline">\(D\)</span>叫做一个网络,记作<span class="math inline">\(D=(V,A,C),where C=\{c_{ij}\}\)</span></p><p>所谓网路上的流,是指定义在弧集合<span class="math inline">\(A\)</span>上的v一个函数<span class="math inline">\(f=\{f_{ij}\}=\{f(v_i,v_j)\},\)</span>并称<span class="math inline">\(f_{ij}\)</span>为弧<span class="math inline">\((v_I,v_j)\)</span>的流量.</p><p>定义 满足下列条件的流称为==可行流==</p><p>(1)容量限制条件:对每一弧<span class="math inline">\((v_i,v_j)\inA,0\le f_{ij}\le c_{ij};\)</span></p><p>(2)平衡条件:对于中间点,流出量<span class="math inline">\(=\)</span>流入量,即对每一个<span class="math inline">\(i(i\ne s,t)\)</span>有 <span class="math display">\[\sum_{j:(v_i,v_j)\in A}f_{ij}-\sum_{j:(v_i,v_j)\in A}f_{ji} = 0\]</span> 对于出发点<span class="math inline">\(v_s\)</span>,记 <span class="math display">\[\sum_{(v_s,v_j)\in A}f_{sj}-\sum_{(v_j,v_s)}f_{js} = v\]</span> 对于收点<span class="math inline">\(v_t\)</span> <span class="math display">\[\sum_{(v_j,v_t)}f_{jt}-\sum_{(v_t,v_j)}f_{tj}=v\]</span> 其中<span class="math inline">\(v\)</span>称为这个可行流的流量,即出发点的净输出量.</p>最大流问题可以写成如下的线性规划模型 $$<span class="math display">\[\begin{split}&amp;max\quad v\\&amp;s.t. \begin{cases}        \sum\limits_{j:(v_i,v_j)\in A}f_{ij}-\sum\limits_{j:(v_j,v_i)\inA}f_{ji} = \begin{cases}                                                                                                                                                        v,\quadi=s,\\                                                                        -v,\quadi=t\\                                                                        0,\quadi\ne s,t                                                                            \end{cases}\\                                                                            0\lef_{ij}\le c_{ij},\quad \forall (v_i,v_j)\in A      \end{cases}\end{split}\]</span><p>$$</p><h4 id="用networkx求网络最大流问题">用networkx求网络最大流问题</h4><p>例:求下图所示网络从<span class="math inline">\(v_1\)</span>到<span class="math inline">\(v_6\)</span>的最大流(图中边上所标数字不代表权重,代表容量capacity)</p><p><img src="https://drive.imgod.me/api/v3/file/get/62004/figure6.png?sign=Jzqi9WPHio0NM7cfX8hN-xPrY4cIN7l_dy2061tZEIU%3D%3A0"></p><figure class="highlight"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs">最大流量为5<br></code></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">import</span> numpy <span class="hljs-keyword">as</span> np<br><span class="hljs-keyword">import</span> networkx <span class="hljs-keyword">as</span> nx<br><span class="hljs-keyword">from</span> networkx.algorithms.matching <span class="hljs-keyword">import</span> max_weight_matching<br><span class="hljs-keyword">import</span> seaborn <span class="hljs-keyword">as</span> sns<br><span class="hljs-keyword">import</span> matplotlib.pyplot <span class="hljs-keyword">as</span> plt<br><span class="hljs-keyword">import</span> pandas <span class="hljs-keyword">as</span> pd<br>sns.set_theme(style=<span class="hljs-string">&quot;dark&quot;</span>)<span class="hljs-comment">#用来设置主题背景</span><br>plt.rcParams[<span class="hljs-string">&quot;font.sans-serif&quot;</span>] = [<span class="hljs-string">&quot;SimHei&quot;</span>] <span class="hljs-comment">#用来正常显示中文标签</span><br>plt.rcParams[<span class="hljs-string">&quot;axes.unicode_minus&quot;</span>] = <span class="hljs-literal">False</span> <span class="hljs-comment">#用来正常显示负号</span><br>L = [(<span class="hljs-number">1</span>,<span class="hljs-number">2</span>,<span class="hljs-number">5</span>),(<span class="hljs-number">1</span>,<span class="hljs-number">3</span>,<span class="hljs-number">3</span>),(<span class="hljs-number">2</span>,<span class="hljs-number">4</span>,<span class="hljs-number">2</span>),(<span class="hljs-number">3</span>,<span class="hljs-number">2</span>,<span class="hljs-number">1</span>),(<span class="hljs-number">3</span>,<span class="hljs-number">5</span>,<span class="hljs-number">4</span>),(<span class="hljs-number">4</span>,<span class="hljs-number">3</span>,<span class="hljs-number">1</span>),(<span class="hljs-number">4</span>,<span class="hljs-number">5</span>,<span class="hljs-number">3</span>),(<span class="hljs-number">4</span>,<span class="hljs-number">6</span>,<span class="hljs-number">2</span>),(<span class="hljs-number">5</span>,<span class="hljs-number">6</span>,<span class="hljs-number">5</span>)] <span class="hljs-comment">#注意此处不能直接由邻接矩阵生成图</span><br>G = nx.DiGraph()<br><span class="hljs-keyword">for</span> k <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(<span class="hljs-built_in">len</span>(L)):<br>    G.add_edge(L[k][<span class="hljs-number">0</span>]-<span class="hljs-number">1</span>,L[k][<span class="hljs-number">1</span>]-<span class="hljs-number">1</span>,capacity=L[k][<span class="hljs-number">2</span>])<br>value,flow_dict = nx.maximum_flow(G,<span class="hljs-number">0</span>,<span class="hljs-number">5</span>)<span class="hljs-comment">#求解网络最大流问题</span><br>dict_temp = &#123;&#125;<br><span class="hljs-keyword">for</span> i,item <span class="hljs-keyword">in</span> flow_dict.items():<br>    <span class="hljs-keyword">for</span> j,weight <span class="hljs-keyword">in</span> item.items():<br>        dict_temp[(i,j)] = weight <span class="hljs-comment">#改变字典结构</span><br>plt.figure(dpi=<span class="hljs-number">500</span>)<br>node_labels=<span class="hljs-built_in">dict</span>(<span class="hljs-built_in">zip</span>(<span class="hljs-built_in">range</span>(<span class="hljs-number">6</span>),[<span class="hljs-string">&quot;V&quot;</span>+<span class="hljs-built_in">str</span>(i) <span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(<span class="hljs-number">1</span>,<span class="hljs-number">7</span>)])) <span class="hljs-comment">#构造用于顶点标记的字典</span><br>pos = nx.circular_layout(G)<span class="hljs-comment">#设置布局</span><br>path_edges = [key <span class="hljs-keyword">for</span> key,item <span class="hljs-keyword">in</span> dict_temp.items() <span class="hljs-keyword">if</span> item !=<span class="hljs-number">0</span>]<br>nx.draw_networkx(G,pos,node_size=<span class="hljs-number">270</span>,labels=node_labels) <span class="hljs-comment">#绘制图</span><br>nx.draw_networkx_edge_labels(G,pos,font_size=<span class="hljs-number">10</span>,edge_labels=dict_temp)<span class="hljs-comment">#标记权重</span><br>nx.draw_networkx_edges(G,pos,edgelist=path_edges,edge_color=<span class="hljs-string">&quot;r&quot;</span>,width=<span class="hljs-number">3</span>)<span class="hljs-comment">#标记路径</span><br>plt.savefig(<span class="hljs-string">&quot;figure7.png&quot;</span>)<br>plt.show()<br><span class="hljs-built_in">print</span>(<span class="hljs-string">&quot;最大流量为&#123;&#125;&quot;</span>.<span class="hljs-built_in">format</span>(value))<br></code></pre></td></tr></table></figure><p><img src="https://drive.imgod.me/api/v3/file/get/62006/figure7.png?sign=tSIBnFIF9FXdB31V-_-PGIFYern-ojPIvahjcvD_LQk%3D%3A0"></p>]]></content>
    
    
    <categories>
      
      <category>数学建模</category>
      
      <category>图论</category>
      
    </categories>
    
    
    <tags>
      
      <tag>数学建模</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>匹配问题</title>
    <link href="/posts/26899.html"/>
    <url>/posts/26899.html</url>
    
    <content type="html"><![CDATA[<hr><div class="note note-success">            <p>数学建模 图论 Python</p>          </div><h3 id="匹配问题">匹配问题</h3><p>定义：在图<span class="math inline">\(G=(V,E)\)</span>中，若<span class="math inline">\(M\subset E,\forall e_i,e_j\inM,e_i,e_j\)</span>无公共端点<span class="math inline">\((i\nej)\)</span>，则称<span class="math inline">\(M\)</span>为图<span class="math inline">\(G\)</span>中的一个对集；<span class="math inline">\(M\)</span>中一条边的两个端点叫做在对集<span class="math inline">\(M\)</span>中相配；<span class="math inline">\(M\)</span>中的端点称为被<span class="math inline">\(M\)</span>许配；<span class="math inline">\(G\)</span>中每一个端点都被<span class="math inline">\(M\)</span>许配则称<span class="math inline">\(M\)</span>为完美对集。<span class="math inline">\(G\)</span>中已经没有<span class="math inline">\(\vert M^\prime\vert&gt;\vertM\vert\)</span>的对集<span class="math inline">\(M^{\prime}\)</span>，则称<span class="math inline">\(M\)</span>为最大对集；</p><p>定理：若图<span class="math inline">\(G\)</span>是<span class="math inline">\(k\)</span>次正则二分图（每个顶点皆为<span class="math inline">\(k\)</span>度的二分图），则<span class="math inline">\(G\)</span>有完美对集。</p><p>人员分配问题：工作人员<span class="math inline">\(x_1,x_2,\cdots,x_n\)</span>去做<span class="math inline">\(n\)</span>件工作<span class="math inline">\(y_1,y_2,\cdots,y_n\)</span>,每个人适合做其中一件或几件，问能否每人都有一份适合的工作？如果不能，最多几人可以有适合的工作？</p><p>这个问题的模型是:<span class="math inline">\(G=(V,E)\)</span>是二分图，顶点集<span class="math inline">\(V=X\bigcupY,X=\{x_1,x_2,\dots,x_n\}，Y=\{y_1,y_2,\dots,y_n\}\)</span>,当且仅当<span class="math inline">\(x_i\)</span>适合做工作<span class="math inline">\(y_i\)</span>时，<span class="math inline">\(x_iy_i\in E\)</span>,求<span class="math inline">\(G\)</span>中最大对集。</p><p>最优分配问题：在人员分配问题中，工作人员适合做的各项工作效益未必一致，需要制定一个分配方案，使公司总效益最大。</p><p>这个问题的数学模型是：在人员分配问题的模型中，图<span class="math inline">\(G=(V,E,W)\)</span>为赋权图，每条边加了权<span class="math inline">\(w(x_iy_j)\ge0\)</span>,表示<span class="math inline">\(x_i\)</span>干<span class="math inline">\(y_i\)</span>工作的效益，求赋权图<span class="math inline">\(G\)</span>的权最大的完美对集</p><p>例：假设分配5个人做5项工作，每个人做不同工作的效益由邻接矩阵 <span class="math display">\[W = (W_{ij})_{5\times5}=\begin{bmatrix}        3 &amp;5&amp;5&amp;4&amp;1 \\         2&amp;2&amp;0&amp;2&amp;2\\         2&amp;4&amp;4&amp;1&amp;0\\         0&amp;2&amp;2&amp;1&amp;0\\         1&amp;2&amp;1&amp;3&amp;3    \end{bmatrix}\]</span> 表示，即<span class="math inline">\(w_{ij}(i,j=1,2,3,4,5)\)</span>表示第<span class="math inline">\(i\)</span>个人做第<span class="math inline">\(j\)</span>项工作的效益，试求使效益达到最大的分配方案。</p><p>解 构造赋权图<span class="math inline">\(G=(V,E,\widetilde{W})\)</span>,顶点集<span class="math inline">\(V=\{v_1,v_2,\cdots,v_{10}\}\)</span>，<span class="math inline">\(v_1,v_2,\dots,v_5\)</span>表示5个人，<span class="math inline">\(v_6,v_7,\dots,v_{10}\)</span>表示5项工作，邻接矩阵为<span class="math display">\[\widetilde{W} = \begin{bmatrix}                    O&amp;W\\                    O&amp;O                 \end{bmatrix}_{10\times10}\]</span> 则问题归结为求赋权图的权最大的完美对集。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">import</span> numpy <span class="hljs-keyword">as</span> np<br><span class="hljs-keyword">import</span> networkx <span class="hljs-keyword">as</span> nx<br><span class="hljs-keyword">from</span> networkx.algorithms.matching <span class="hljs-keyword">import</span> max_weight_matching<br><span class="hljs-keyword">import</span> seaborn <span class="hljs-keyword">as</span> sns<br><span class="hljs-keyword">import</span> matplotlib.pyplot <span class="hljs-keyword">as</span> plt<br><span class="hljs-keyword">import</span> pandas <span class="hljs-keyword">as</span> pd<br>sns.set_theme(style=<span class="hljs-string">&quot;dark&quot;</span>)<span class="hljs-comment">#用来设置主题背景</span><br>plt.rcParams[<span class="hljs-string">&quot;font.sans-serif&quot;</span>] = [<span class="hljs-string">&quot;SimHei&quot;</span>] <span class="hljs-comment">#用来正常显示中文标签</span><br>plt.rcParams[<span class="hljs-string">&quot;axes.unicode_minus&quot;</span>] = <span class="hljs-literal">False</span> <span class="hljs-comment">#用来正常显示负号</span><br>A = np.array([[<span class="hljs-number">3</span>,<span class="hljs-number">5</span>,<span class="hljs-number">5</span>,<span class="hljs-number">4</span>,<span class="hljs-number">1</span>]<br>             ,[<span class="hljs-number">2</span>,<span class="hljs-number">2</span>,<span class="hljs-number">0</span>,<span class="hljs-number">2</span>,<span class="hljs-number">2</span>]<br>             ,[<span class="hljs-number">2</span>,<span class="hljs-number">4</span>,<span class="hljs-number">4</span>,<span class="hljs-number">1</span>,<span class="hljs-number">0</span>]<br>             ,[<span class="hljs-number">0</span>,<span class="hljs-number">2</span>,<span class="hljs-number">2</span>,<span class="hljs-number">1</span>,<span class="hljs-number">0</span>]<br>             ,[<span class="hljs-number">1</span>,<span class="hljs-number">2</span>,<span class="hljs-number">1</span>,<span class="hljs-number">3</span>,<span class="hljs-number">3</span>]])<br>W = np.zeros((<span class="hljs-number">10</span>,<span class="hljs-number">10</span>))<br>W[<span class="hljs-number">0</span>:<span class="hljs-number">5</span>,<span class="hljs-number">5</span>:] = A<span class="hljs-comment">#创建邻接矩阵</span><br>G = nx.Graph(W)<span class="hljs-comment">#创建无向图</span><br>s = max_weight_matching(G)<br>p = <span class="hljs-built_in">list</span>(s)<br>plt.figure(dpi=<span class="hljs-number">500</span>)<br>node_labels=<span class="hljs-built_in">dict</span>(<span class="hljs-built_in">zip</span>(<span class="hljs-built_in">range</span>(<span class="hljs-number">10</span>),[<span class="hljs-string">&quot;V&quot;</span>+<span class="hljs-built_in">str</span>(i) <span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(<span class="hljs-number">1</span>,<span class="hljs-number">11</span>)])) <span class="hljs-comment">#构造用于顶点标记的字典</span><br>pos = nx.circular_layout(G)<span class="hljs-comment">#设置布局</span><br>w = nx.get_edge_attributes(G,<span class="hljs-string">&quot;weight&quot;</span>) <span class="hljs-comment">#获取边的权重</span><br>nx.draw_networkx(G,pos,node_size=<span class="hljs-number">270</span>,labels=node_labels) <span class="hljs-comment">#绘制图</span><br>nx.draw_networkx_edge_labels(G,pos,font_size=<span class="hljs-number">10</span>,edge_labels=w)<span class="hljs-comment">#标记权重</span><br>path_edges=p<span class="hljs-comment">#标记路径的元组组成的列表</span><br>nx.draw_networkx_edges(G,pos,edgelist=path_edges,edge_color=<span class="hljs-string">&quot;r&quot;</span>,width=<span class="hljs-number">3</span>)<span class="hljs-comment">#标记路径</span><br>plt.savefig(<span class="hljs-string">&quot;figure5.png&quot;</span>)<br>plt.show()<br>x = [<span class="hljs-built_in">sorted</span>([i[<span class="hljs-number">0</span>],i[<span class="hljs-number">1</span>]]) <span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> s] <br>df = pd.DataFrame(np.array(x),columns=[<span class="hljs-string">&quot;worker&quot;</span>,<span class="hljs-string">&quot;task&quot;</span>])<br>temp = [W[df.loc[i,<span class="hljs-string">&quot;worker&quot;</span>],df.loc[i,<span class="hljs-string">&quot;task&quot;</span>]] <span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(df.shape[<span class="hljs-number">0</span>])]<br>benefit = [W[df.loc[i,<span class="hljs-string">&quot;worker&quot;</span>],df.loc[i,<span class="hljs-string">&quot;task&quot;</span>]] <span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(df.shape[<span class="hljs-number">0</span>])]<br>df[<span class="hljs-string">&quot;benefit&quot;</span>]  = benefit<br>df[<span class="hljs-string">&quot;worker&quot;</span>] = df[<span class="hljs-string">&quot;worker&quot;</span>]+<span class="hljs-number">1</span><br>df[<span class="hljs-string">&quot;task&quot;</span>] = df[<span class="hljs-string">&quot;task&quot;</span>]-<span class="hljs-number">4</span><br><span class="hljs-built_in">print</span>(<span class="hljs-string">&quot;总的效益&#123;&#125;&quot;</span>.<span class="hljs-built_in">format</span>(df[<span class="hljs-string">&quot;benefit&quot;</span>].<span class="hljs-built_in">sum</span>()))<br>df.head(<span class="hljs-number">10</span>)<br></code></pre></td></tr></table></figure><figure class="highlight"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs">总的效益15.0<br></code></pre></td></tr></table></figure><p><img src="https://drive.imgod.me/api/v3/file/get/62001/figure5.png?sign=BtppWO4epWUcHze3yRDxGKDs13KhKvHIVFZ1O-QS4-Y%3D%3A0"></p><p><img src="https://drive.imgod.me/api/v3/file/get/62002/QQ%E6%88%AA%E5%9B%BE20220628101703.png?sign=vPKfZD_0WYJsdwvRUcNLQPr2MyTvtjtOU1TIQgxRXjo%3D%3A0"></p>]]></content>
    
    
    <categories>
      
      <category>数学建模</category>
      
      <category>图论</category>
      
    </categories>
    
    
    <tags>
      
      <tag>数学建模</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>最小生成树</title>
    <link href="/posts/57313.html"/>
    <url>/posts/57313.html</url>
    
    <content type="html"><![CDATA[<hr><div class="note note-success">            <p>数学建模 图论 Python</p>          </div><h3 id="最小生成树算法及其networkx实现">最小生成树算法及其networkx实现</h3><p>树是图论中非常重要的一类图，它非常类似于自然界的树，结构简单、应用广泛，最小生成树问题则是其中经典的问题之一。在实际应用中，许多问题的图论模型都是最小生成树，如通信网络建设、有线电缆铺设、加工设备分组等。关键词：连通，无圈，最短。</p><h3 id="基本概念">基本概念</h3><p>定义：连通的无圈图称为树。</p><p>定理：设<span class="math inline">\(G\)</span>是具有<span class="math inline">\(n\)</span>个顶点<span class="math inline">\(m\)</span>条边的图，则下列命题等价：</p><p>（1）图<span class="math inline">\(G\)</span>是树；</p><p>（2）图<span class="math inline">\(G\)</span>中任意两个不同顶点之间存在唯一的路；</p><p>（3）图<span class="math inline">\(G\)</span>连通，删除任一条边均不连通；</p><p>（4）图<span class="math inline">\(G\)</span>连通，且<span class="math inline">\(n=m+1\)</span>；</p><p>（5）图<span class="math inline">\(G\)</span>无圈，添加任一条边可得唯一的圈；</p><p>（6）图<span class="math inline">\(G\)</span>无圈，且<span class="math inline">\(n=m+1\)</span>.</p><p>定义：若图<span class="math inline">\(G\)</span>的生成子图<span class="math inline">\(H\)</span>是树，则称<span class="math inline">\(H\)</span>为<span class="math inline">\(G\)</span>的生成树。一个图的生成树往往不唯一。</p><p>定理：连通图的生成树一定存在。</p><p>定义：在赋权图<span class="math inline">\(G\)</span>中，边权之和最小的生成树称为<span class="math inline">\(G\)</span>的最小生成树。</p><h3 id="最小生成树算法">最小生成树算法</h3><p>构造连通图最小生成树的算法有Kruskal算法和Prim算法。均可以在networkx中实现。</p><p>例：已知8口井，相互之间的距离如下表，已知1号油井离海岸线最近，为5nmil。问从海岸经一号油井铺设管道将各油井连接起来，应如何铺设使油管长度最短。</p><p><img src="https://drive.imgod.me/api/v3/file/get/61997/QQ%E6%88%AA%E5%9B%BE20220627191701.png?sign=NwhSbk0-PlOFJlM5PfxCTKCgD-TQs53UdwnVkUffd4A%3D%3A0"></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">import</span> numpy <span class="hljs-keyword">as</span> np<br><span class="hljs-keyword">import</span> networkx <span class="hljs-keyword">as</span> nx<br><span class="hljs-keyword">import</span> seaborn <span class="hljs-keyword">as</span> sns<br><span class="hljs-keyword">import</span> matplotlib.pyplot <span class="hljs-keyword">as</span> plt<br>sns.set_theme(style=<span class="hljs-string">&quot;dark&quot;</span>)<span class="hljs-comment">#用来设置主题背景</span><br>plt.rcParams[<span class="hljs-string">&quot;font.sans-serif&quot;</span>] = [<span class="hljs-string">&quot;SimHei&quot;</span>] <span class="hljs-comment">#用来正常显示中文标签</span><br>plt.rcParams[<span class="hljs-string">&quot;axes.unicode_minus&quot;</span>] = <span class="hljs-literal">False</span> <span class="hljs-comment">#用来正常显示负号</span><br>W_input = np.array([[<span class="hljs-number">0</span>,<span class="hljs-number">1.3</span>,<span class="hljs-number">2.1</span>,<span class="hljs-number">0.9</span>,<span class="hljs-number">0.7</span>,<span class="hljs-number">1.8</span>,<span class="hljs-number">2.0</span>,<span class="hljs-number">1.5</span>]<br>            ,[<span class="hljs-number">0</span>,<span class="hljs-number">0</span>,<span class="hljs-number">0.9</span>,<span class="hljs-number">1.8</span>,<span class="hljs-number">1.2</span>,<span class="hljs-number">2.6</span>,<span class="hljs-number">2.3</span>,<span class="hljs-number">1.1</span>]<br>            ,[<span class="hljs-number">0</span>,<span class="hljs-number">0</span>,<span class="hljs-number">0</span>,<span class="hljs-number">2.6</span>,<span class="hljs-number">1.7</span>,<span class="hljs-number">2.5</span>,<span class="hljs-number">1.9</span>,<span class="hljs-number">1.0</span>]<br>            ,[<span class="hljs-number">0</span>,<span class="hljs-number">0</span>,<span class="hljs-number">0</span>,<span class="hljs-number">0</span>,<span class="hljs-number">0.7</span>,<span class="hljs-number">1.6</span>,<span class="hljs-number">1.5</span>,<span class="hljs-number">0.9</span>]<br>            ,[<span class="hljs-number">0</span>,<span class="hljs-number">0</span>,<span class="hljs-number">0</span>,<span class="hljs-number">0</span>,<span class="hljs-number">0</span>,<span class="hljs-number">0.9</span>,<span class="hljs-number">1.1</span>,<span class="hljs-number">0.8</span>]<br>            ,[<span class="hljs-number">0</span>,<span class="hljs-number">0</span>,<span class="hljs-number">0</span>,<span class="hljs-number">0</span>,<span class="hljs-number">0</span>,<span class="hljs-number">0</span>,<span class="hljs-number">0.6</span>,<span class="hljs-number">1.0</span>]<br>            ,[<span class="hljs-number">0</span>,<span class="hljs-number">0</span>,<span class="hljs-number">0</span>,<span class="hljs-number">0</span>,<span class="hljs-number">0</span>,<span class="hljs-number">0</span>,<span class="hljs-number">0</span>,<span class="hljs-number">0.5</span>]<br>             ,[<span class="hljs-number">0</span>,<span class="hljs-number">0</span>,<span class="hljs-number">0</span>,<span class="hljs-number">0</span>,<span class="hljs-number">0</span>,<span class="hljs-number">0</span>,<span class="hljs-number">0</span>,<span class="hljs-number">0</span>]])<br>W = W_input.T+W_input <span class="hljs-comment">#生成邻接矩阵</span><br>G  = nx.Graph(W) <span class="hljs-comment">#创建无向图</span><br>T = nx.minimum_spanning_tree(G) <span class="hljs-comment">#根据图G生成最小生成树</span><br>D = nx.to_numpy_matrix(T) <span class="hljs-comment">#获取最小生成树的邻接矩阵</span><br>plt.figure(dpi=<span class="hljs-number">500</span>)<br>node_labels = <span class="hljs-built_in">dict</span>(<span class="hljs-built_in">zip</span>(<span class="hljs-built_in">range</span>(<span class="hljs-number">8</span>),<span class="hljs-built_in">range</span>(<span class="hljs-number">1</span>,<span class="hljs-number">9</span>))) <span class="hljs-comment">#顶点标签</span><br>pos = nx.shell_layout(T)<span class="hljs-comment">#设置布局</span><br>w = nx.get_edge_attributes(T,<span class="hljs-string">&quot;weight&quot;</span>) <span class="hljs-comment">#获取边的权重</span><br>nx.draw_networkx(T,pos,node_size=<span class="hljs-number">270</span>,labels=node_labels) <span class="hljs-comment">#绘制图</span><br>nx.draw_networkx_edge_labels(T,pos,font_size=<span class="hljs-number">10</span>,edge_labels=w)<span class="hljs-comment">#标记权重</span><br>plt.savefig(<span class="hljs-string">&quot;figure4.png&quot;</span>)<br>plt.show()<br></code></pre></td></tr></table></figure><p>结果如下：</p><p><img src="https://drive.imgod.me/api/v3/file/get/61998/figure4.png?sign=pznKdZ39N6Ar0fpWKSJM5NXvt2t6ZvjY-SviJfb3S4c%3D%3A0"></p>]]></content>
    
    
    <categories>
      
      <category>数学建模</category>
      
      <category>图论</category>
      
    </categories>
    
    
    <tags>
      
      <tag>数学建模</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>最短路径及其应用</title>
    <link href="/posts/24890.html"/>
    <url>/posts/24890.html</url>
    
    <content type="html"><![CDATA[<hr><div class="note note-success">            <p>数学建模 图论 Python</p>          </div><h2 id="最短路算法及其python实现">最短路算法及其Python实现</h2><p>最短路径问题是图论中非常经典的问题之一，旨在寻找图中两顶点之间的最短路径。作为一个基本工具，实际应用中许多优化问题，如管道铺设、线路安排、工区布局、设备更新等。都可被归结为最短路径问题来解决。</p><p>定义1：设图<span class="math inline">\(G\)</span>是赋权图，<span class="math inline">\(\Gamma\)</span>为<span class="math inline">\(G\)</span>中的一条路，则称<span class="math inline">\(\Gamma\)</span>的各边权之和为路<span class="math inline">\(\Gamma\)</span>的长度。</p><p>对于<span class="math inline">\(G\)</span>的两个顶点<span class="math inline">\(u_0\)</span>和<span class="math inline">\(v_0\)</span>，从<span class="math inline">\(u_0\)</span>到<span class="math inline">\(v_0\)</span>的路不止一条，其中最短的一条称为从<span class="math inline">\(u_0\)</span>到<span class="math inline">\(v_0\)</span>的最短路；最短路的长称为从<span class="math inline">\(u_0\)</span>到<span class="math inline">\(v_0\)</span>的距离，记为<span class="math inline">\(d(u_0,v_0)\)</span>。</p><p>求最短路的算法有Dijkstra标号算法和Floyd算法，但Dijkstra标号算法只适应于边权为非负的情形，最短路径的问题也可以归结到<span class="math inline">\(0-1\)</span>规划问题。</p><h3 id="设备更新问题">设备更新问题</h3><p>某种工程设备的役龄为4年，每年年初都面临着是否更新的问题；若卖旧买新，就需要支付一定的购置费用；若继续使用，则要支付更多的维护费用，且使用年限越长维护费用就越多。若役龄期间每年的年初购置价格，当年维护费用及其年末剩余净值如下表所示。请为该设备制定一个4年役龄期内的更新计划，使总的支付费用最少。</p><table><thead><tr class="header"><th style="text-align: center;">年份</th><th>1</th><th>2</th><th>3</th><th>4</th></tr></thead><tbody><tr class="odd"><td style="text-align: center;">年初购置价格/万元</td><td>25</td><td>26</td><td>28</td><td>31</td></tr><tr class="even"><td style="text-align: center;">当年维护费用/万元</td><td>10</td><td>14</td><td>18</td><td>26</td></tr><tr class="odd"><td style="text-align: center;">年末剩余净值/万元</td><td>20</td><td>16</td><td>13</td><td>11</td></tr></tbody></table><p>解： 可以把该问题进行数学抽象</p><p>构造赋权有向图<span class="math inline">\(D=(V,A,W)\)</span>，其中顶点集<span class="math inline">\(V=\{v_1,v_2,v_3,v_4,v_5\},where\quadv_i(i=1,2,3,4)\text{表示第i年初},v_5\text{表示第5年初(第4年末)}.\)</span>,<span class="math inline">\(A\)</span>表示弧集，邻接矩阵<span class="math inline">\(W=(w_{ij})_{5\times5}\)</span>，这里<span class="math inline">\(w_{ij}\)</span>表示第<span class="math inline">\(i\)</span>年初购进机器第<span class="math inline">\(j\)</span>年初卖掉这个过程一共支付的费用，计算公式为<span class="math display">\[w_{ij}=p_i+\sum_{k=1}^{j-i}a_k-r_{j-i}\]</span> 其中<span class="math inline">\(p_i\)</span>为第<span class="math inline">\(i\)</span>年年初的购置价格,<span class="math inline">\(a_k\)</span>表示从购入开始计算使用到第k年的费用，<span class="math inline">\(r_i\)</span>表示使用<span class="math inline">\(i\)</span>年旧设备的出售价格。则邻接矩阵为： <span class="math display">\[W = \begin{bmatrix}            0&amp;15&amp;33&amp;54&amp;82\\            \infty&amp;0&amp;16&amp;34&amp;55\\            \infty&amp;\infty&amp;0&amp;18&amp;36\\            \infty&amp;\infty&amp;\infty&amp;0&amp;21\\            \infty&amp;\infty&amp;\infty&amp;\infty&amp;0            \end{bmatrix}\nonumber\]</span> 经计算得：</p><figure class="highlight clean"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs clean">最短路径为：<br><span class="hljs-number">1</span>-&gt;<span class="hljs-number">2</span>-&gt;<span class="hljs-number">3</span>-&gt;<span class="hljs-number">5</span><br>最短距离为<span class="hljs-number">67</span><br></code></pre></td></tr></table></figure><p><img src="https://s2.loli.net/2022/06/26/l4HTiCy5cR62zW8.png" style="zoom: 50%;"></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br></pre></td><td class="code"><pre><code class="hljs python">W = np.array([[<span class="hljs-number">0</span>,<span class="hljs-number">15</span>,<span class="hljs-number">33</span>,<span class="hljs-number">54</span>,<span class="hljs-number">82</span>]<br>              ,[<span class="hljs-number">0</span>,<span class="hljs-number">0</span>,<span class="hljs-number">16</span>,<span class="hljs-number">34</span>,<span class="hljs-number">55</span>]<br>              ,[<span class="hljs-number">0</span>,<span class="hljs-number">0</span>,<span class="hljs-number">0</span> ,<span class="hljs-number">18</span>,<span class="hljs-number">36</span>]<br>              ,[<span class="hljs-number">0</span>,<span class="hljs-number">0</span>,<span class="hljs-number">0</span> ,<span class="hljs-number">0</span> , <span class="hljs-number">21</span> ]<br>              ,[<span class="hljs-number">0</span>,<span class="hljs-number">0</span>,<span class="hljs-number">0</span> ,<span class="hljs-number">0</span> , <span class="hljs-number">0</span> ]])<br><span class="hljs-string">&#x27;&#x27;&#x27;注意：在利用networkx库函数计算时，如果两个顶点之间没有边，对应的邻接矩阵元素为0，而不是np.inf&#x27;&#x27;&#x27;</span><br>G=nx.DiGraph(W)<span class="hljs-comment">#创建有向图</span><br>p = nx.dijkstra_path(G,source=<span class="hljs-number">0</span>,target=<span class="hljs-number">4</span>,weight=<span class="hljs-string">&quot;weight&quot;</span>)<span class="hljs-comment">#求最短路径</span><br><span class="hljs-string">&quot;&quot;&quot;param G:图</span><br><span class="hljs-string">   param source:起点</span><br><span class="hljs-string">   param target:终点</span><br><span class="hljs-string">   param weight:用边权作为路长&quot;&quot;&quot;</span><br><span class="hljs-built_in">print</span>(<span class="hljs-string">&quot;最短路径为：&quot;</span>)<br><span class="hljs-built_in">print</span>(<span class="hljs-string">&quot;-&gt;&quot;</span>.join([<span class="hljs-built_in">str</span>(i+<span class="hljs-number">1</span>) <span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> p]))<br>d = nx.dijkstra_path_length(G,source=<span class="hljs-number">0</span>,target=<span class="hljs-number">4</span>,weight=<span class="hljs-string">&quot;weight&quot;</span>)<span class="hljs-comment">#求最短距离</span><br><span class="hljs-built_in">print</span>(<span class="hljs-string">&quot;最短距离为&#123;&#125;&quot;</span>.<span class="hljs-built_in">format</span>(d))<br>plt.figure(dpi=<span class="hljs-number">500</span>)<br>node_labels=<span class="hljs-built_in">dict</span>(<span class="hljs-built_in">zip</span>(<span class="hljs-built_in">range</span>(<span class="hljs-number">5</span>),[<span class="hljs-string">&quot;V&quot;</span>+<span class="hljs-built_in">str</span>(i) <span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(<span class="hljs-number">1</span>,<span class="hljs-number">6</span>)])) <span class="hljs-comment">#构造用于顶点标记的字典</span><br>pos = nx.shell_layout(G)<span class="hljs-comment">#设置布局</span><br>w = nx.get_edge_attributes(G,<span class="hljs-string">&quot;weight&quot;</span>) <span class="hljs-comment">#获取边的权重</span><br>nx.draw_networkx(G,pos,node_size=<span class="hljs-number">270</span>,labels=node_labels) <span class="hljs-comment">#绘制图</span><br>nx.draw_networkx_edge_labels(G,pos,font_size=<span class="hljs-number">10</span>,edge_labels=w)<span class="hljs-comment">#标记权重</span><br>path_edges=<span class="hljs-built_in">list</span>(<span class="hljs-built_in">zip</span>(p,p[<span class="hljs-number">1</span>:]))<span class="hljs-comment">#标记路径的元组组成的列表</span><br>nx.draw_networkx_edges(G,pos,edgelist=path_edges,edge_color=<span class="hljs-string">&quot;r&quot;</span>,width=<span class="hljs-number">3</span>)<span class="hljs-comment">#标记路径</span><br>plt.savefig(<span class="hljs-string">&quot;figure2.png&quot;</span>)<br>plt.show()<br></code></pre></td></tr></table></figure><h3 id="重心问题">重心问题</h3><p>有些公共服务设施（例如邮局，学校等）的选址，要求设施到所有服务对象点的距离总和最小。一般要考虑人口密度问题，或者全体被服务对象来往的总路程最短。</p><p>某矿区有六个矿点，如下图所示，已知各产矿点每天的产煤量为<span class="math inline">\(q_i(i=1,2,3,4,5,6)t,\)</span>,现在要从这六个矿点选一个作为矿场。问在那个产矿点，才能使各矿点所产的矿石运到选矿厂所在地的总运力<span class="math inline">\((t\cdot km)\)</span>最小。</p><p><img src="https://drive.imgod.me/api/v3/file/get/61808/figure3.png?sign=4h_GOqbwtj4VVuzNQR-NVKtZ2LoCeR7rOVKRgHyJZds%3D%3A0" style="zoom:50%;"></p><p>解：令<span class="math inline">\(d_{ij}(i,j=1,2,\cdots,6)\)</span>表示顶点<span class="math inline">\(v_i\)</span>和顶点<span class="math inline">\(v_j\)</span>之间的距离。若选矿厂设在<span class="math inline">\(m_i\)</span>，并且各产矿点到选矿厂的总运力为<span class="math inline">\(m_i\)</span>,则确定选矿厂的位置就转化为求<span class="math inline">\(m_k\)</span>，使得 <span class="math display">\[m_k = \min_{1\le i \le6} m_i\]</span>由于各产矿点到选矿厂的总运力依赖于任意两顶点之间的距离，即任意两顶点之间的最短距离，先用Floyd计算出所有顶点对之间的最短距离，然后计算出顶点<span class="math inline">\(v_i\)</span>作为设立选矿厂时各自到<span class="math inline">\(v_i\)</span>的总运力 <span class="math display">\[m_i = \sum_{j=1}^{6}q_jd_{ij},\quad i = 1,2,\cdots,6\]</span></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br></pre></td><td class="code"><pre><code class="hljs python">W = np.array([[<span class="hljs-number">0</span>,<span class="hljs-number">20</span>,<span class="hljs-number">0</span>,<span class="hljs-number">0</span>,<span class="hljs-number">15</span>,<span class="hljs-number">0</span>]<br>            ,[<span class="hljs-number">20</span>,<span class="hljs-number">0</span>,<span class="hljs-number">20</span>,<span class="hljs-number">40</span>,<span class="hljs-number">25</span>,<span class="hljs-number">0</span>]<br>            ,[<span class="hljs-number">0</span>,<span class="hljs-number">20</span>,<span class="hljs-number">0</span>,<span class="hljs-number">30</span>,<span class="hljs-number">10</span>,<span class="hljs-number">0</span>]<br>            ,[<span class="hljs-number">0</span>,<span class="hljs-number">40</span>,<span class="hljs-number">30</span>,<span class="hljs-number">0</span>,<span class="hljs-number">0</span>,<span class="hljs-number">0</span>]<br>            ,[<span class="hljs-number">15</span>,<span class="hljs-number">25</span>,<span class="hljs-number">10</span>,<span class="hljs-number">0</span>,<span class="hljs-number">0</span>,<span class="hljs-number">15</span>]<br>            ,[<span class="hljs-number">0</span>,<span class="hljs-number">0</span>,<span class="hljs-number">0</span>,<span class="hljs-number">0</span>,<span class="hljs-number">15</span>,<span class="hljs-number">0</span>]])<br><span class="hljs-comment">#绘制无向加权图</span><br><span class="hljs-keyword">import</span> numpy <span class="hljs-keyword">as</span> np<br><span class="hljs-keyword">import</span> networkx <span class="hljs-keyword">as</span> nx<br><span class="hljs-keyword">import</span> seaborn <span class="hljs-keyword">as</span> sns<br><span class="hljs-keyword">import</span> matplotlib.pyplot <span class="hljs-keyword">as</span> plt<br><span class="hljs-keyword">import</span> pandas <span class="hljs-keyword">as</span> pd<br>sns.set_theme(style=<span class="hljs-string">&quot;dark&quot;</span>)<span class="hljs-comment">#用来设置主题背景</span><br>plt.rcParams[<span class="hljs-string">&quot;font.sans-serif&quot;</span>] = [<span class="hljs-string">&quot;SimHei&quot;</span>] <span class="hljs-comment">#用来正常显示中文标签</span><br>plt.rcParams[<span class="hljs-string">&quot;axes.unicode_minus&quot;</span>] = <span class="hljs-literal">False</span> <span class="hljs-comment">#用来正常显示负号</span><br>G = nx.Graph(W)<span class="hljs-comment">#创建无向图类</span><br>plt.figure(dpi=<span class="hljs-number">500</span>)<br>node_labels=<span class="hljs-built_in">dict</span>(<span class="hljs-built_in">zip</span>(<span class="hljs-built_in">range</span>(<span class="hljs-number">6</span>),[<span class="hljs-string">&quot;v1(80)&quot;</span>,<span class="hljs-string">&quot;v2(90)&quot;</span>,<span class="hljs-string">&quot;v3(30)&quot;</span>,<span class="hljs-string">&quot;v4(20)&quot;</span>,<span class="hljs-string">&quot;v5(60)&quot;</span>,<span class="hljs-string">&quot;v6(10)&quot;</span>])) <span class="hljs-comment">#构造用于顶点标记的字典</span><br>pos = nx.shell_layout(G)<span class="hljs-comment">#设置布局</span><br>w = nx.get_edge_attributes(G,<span class="hljs-string">&quot;weight&quot;</span>) <span class="hljs-comment">#获取边的权重</span><br>nx.draw_networkx(G,pos,node_size=<span class="hljs-number">270</span>,labels=node_labels,font_size=<span class="hljs-number">5</span>) <span class="hljs-comment">#绘制图</span><br>nx.draw_networkx_edge_labels(G,pos,font_size=<span class="hljs-number">10</span>,edge_labels=w)<span class="hljs-comment">#标记权重</span><br>plt.savefig(<span class="hljs-string">&quot;figure3.png&quot;</span>)<br>plt.show()<br>d = nx.shortest_path_length(G,weight=<span class="hljs-string">&quot;weight&quot;</span>) <span class="hljs-comment">#计算各个点之间的最短路径</span><br>s = <span class="hljs-built_in">dict</span>(d) <span class="hljs-comment">#将其转化为字典</span><br>res = np.zeros((<span class="hljs-number">6</span>,<span class="hljs-number">6</span>))<br><span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(<span class="hljs-number">6</span>):<br>    <span class="hljs-keyword">for</span> j <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(<span class="hljs-number">6</span>):<br>        res[i][j] = s[i][j]<span class="hljs-comment">#构建最短路径矩阵</span><br>df = pd.DataFrame(res,columns=[<span class="hljs-number">1</span>,<span class="hljs-number">2</span>,<span class="hljs-number">3</span>,<span class="hljs-number">4</span>,<span class="hljs-number">5</span>,<span class="hljs-number">6</span>],index=[<span class="hljs-number">1</span>,<span class="hljs-number">2</span>,<span class="hljs-number">3</span>,<span class="hljs-number">4</span>,<span class="hljs-number">5</span>,<span class="hljs-number">6</span>])<br>df.head(<span class="hljs-number">10</span>)<br></code></pre></td></tr></table></figure><p>结果如下：</p><p><img src="https://drive.imgod.me/api/v3/file/get/61809/dsafasdfasdf.png?sign=_QGe0dW7S17pNT5pPBQKAehOaIoBxn-pkOQ5epMQYAg%3D%3A0"></p>]]></content>
    
    
    <categories>
      
      <category>数学建模</category>
      
      <category>图论</category>
      
    </categories>
    
    
    <tags>
      
      <tag>数学建模</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>图论基础及绘制(python)</title>
    <link href="/posts/18665.html"/>
    <url>/posts/18665.html</url>
    
    <content type="html"><![CDATA[<div class="note note-success">            <p>数学建模 图论 Python</p>          </div><h2 id="图的基础理论">图的基础理论</h2><h3 id="图的基本概念">图的基本概念</h3><p>定义1：图是一些点和这些点之间的连线组成的。定义为<span class="math inline">\(G=(V,E)\)</span>,<span class="math inline">\(V\)</span>是顶点(vertex)的非空有限集合，称为顶点集,<span class="math inline">\(E\)</span>是边(edge)的集合，称为边集。边一般用<span class="math inline">\((v_i,v_j)\)</span>表示，其中<span class="math inline">\(v_i,v_j\in V\)</span>,用<span class="math inline">\(\vert V \vert\)</span>表示图中顶点的个数，<span class="math inline">\(\vert E\vert\)</span>表示边的条数。</p><h3 id="有向图和无向图">有向图和无向图</h3><p>定义2：图的边有方向称为有向图，没有方向称为弧。有向图的弧的起点称为弧头，弧的终点称为弧尾。有向图一般记为<span class="math inline">\(D=(V,A)\)</span>,其中<span class="math inline">\(V\)</span>为顶点集,<span class="math inline">\(A\)</span>为弧集。</p><h3 id="简单图和完全图">简单图和完全图</h3><p>定义3：设<span class="math inline">\(e=(u,v)\)</span>是图<span class="math inline">\(G\)</span>的一条边,则称<span class="math inline">\(u,v\)</span>是<span class="math inline">\(e\)</span>的端点，并称<span class="math inline">\(u,v\)</span>相邻，边<span class="math inline">\(e\)</span>与顶点<span class="math inline">\(u或(v)\)</span>相关联。若两条边<span class="math inline">\(e_i,e_j\)</span>有共同的端点，则称<span class="math inline">\(e_i,e_j\)</span>相邻，称有相同端点的两条边为重边。称两端点相同的边为环。称不与任何边相关联的顶点为孤立点。</p><p>定义4：无环且无重边的图称为简单图</p><p>定义5：任意两顶点均相邻的简单图称为完全图，含有<span class="math inline">\(n\)</span>个顶点的完全图记为<span class="math inline">\(K_n\)</span></p><h3 id="赋权图">赋权图</h3><p>定义6：如果图<span class="math inline">\(G\)</span>的每一条边<span class="math inline">\(e\)</span>都附有一个实数<span class="math inline">\(w(e)\)</span>，则称图<span class="math inline">\(G\)</span>为赋权图,实数<span class="math inline">\(w(e)\)</span>称为边<span class="math inline">\(e\)</span>的权</p><h3 id="顶点的度">顶点的度</h3><p>定义7：（1）在无向图中与顶点<span class="math inline">\(v\)</span>相关联的边(环算两次)的数目称为<span class="math inline">\(v\)</span>的度,记作<span class="math inline">\(d(v)\)</span></p><p>​ （2）在有向图中，从顶点<span class="math inline">\(v\)</span>引出的弧的数目称为<span class="math inline">\(v\)</span>的出度，记作<span class="math inline">\(d^{+}(v)\)</span>,从顶点<span class="math inline">\(v\)</span>引入弧的数目称为弧的入度，记作<span class="math inline">\(d^{-}(v)\)</span>， <span class="math inline">\(d(v)=d^{+}(v)+d^{-}(v)\)</span>称为<span class="math inline">\(v\)</span>的度</p><pre><code class="hljs">                度为奇数的顶点称为奇顶点，度为偶数的顶点称为偶顶点。</code></pre><p>定理1：给定图<span class="math inline">\(G=(V,E)\)</span>,所有顶点的度数之和是边数的2倍，即<span class="math display">\[\sum_{v\in V}d(v) = 2\vert E\vert\]</span> 推论：任何图中奇顶点的数目总为偶数</p><h3 id="子图">子图</h3><p>定义8：设<span class="math inline">\(G_1=(V_1,E_1)\)</span>v与<span class="math inline">\(G_2=(V_2,E_2)\)</span>是两个图,并且满足<span class="math inline">\(V_1\subset V_2,E_1\subset E_2\)</span>，则称<span class="math inline">\(G_1\)</span>是<span class="math inline">\(G_2\)</span>的子图。如果<span class="math inline">\(G_1\)</span>是<span class="math inline">\(G_2\)</span>的子图，且<span class="math inline">\(V_1=V_2\)</span>，则称<span class="math inline">\(G_1\)</span>是<span class="math inline">\(G_2\)</span>的生成子图。</p><h3 id="道路与回路">道路与回路</h3><p>设<span class="math inline">\(W=v_0e_1v_1e_2\cdotse_kv_k,\,where\quad e_i\in E,v_j\in V\)</span>，<span class="math inline">\(e_i\)</span>与<span class="math inline">\(v_{i-1}\)</span>和<span class="math inline">\(v_i\)</span>相关联，称<span class="math inline">\(W\)</span>是图<span class="math inline">\(G\)</span>的一条道路，简称路，<span class="math inline">\(k\)</span>为路长，<span class="math inline">\(v_0\)</span>为起点,<span class="math inline">\(v_k\)</span>为终点；各边相异的道路称为迹(trail);各顶点相异的道路称为轨道(path),记为<span class="math inline">\(P(v_0,v_k)\)</span>；起点和终点相同的道路称为回路；起点和终点重合的轨道称为圈。称以两顶点<span class="math inline">\(u,v\)</span>分别为起点和终点的最短轨道之长为顶点<span class="math inline">\(u,v\)</span>的距离。</p><h3 id="连通图和非连通图">连通图和非连通图</h3><p>在无向图<span class="math inline">\(G\)</span>中，如果从顶点<span class="math inline">\(u\)</span>到顶点<span class="math inline">\(v\)</span>存在道路，则称顶点<span class="math inline">\(u\)</span>和顶点<span class="math inline">\(v\)</span>是连通的。如果图<span class="math inline">\(G\)</span>中任意两个顶点都是连通的，则称图<span class="math inline">\(G\)</span>是联通图，否则称为非连通图。</p><h2 id="图的表示">图的表示</h2><p>以下均假设图<span class="math inline">\(G=(V,E)\)</span>为简单图，其中<span class="math inline">\(V=\{v_1,v_2,\cdots,v_n\},E=\{e_1,e_2,\cdots,e_m\}\)</span></p><ul><li>关联矩阵</li></ul><p>对于无向图<span class="math inline">\(G\)</span>，其关联矩阵<span class="math inline">\(M=(M_{ij})_{n\times m}\)</span>,其中 <span class="math display">\[m_{ij} = \begin{cases}1,\quad &amp;v_i\text{与}e_j\text{相关联}\\                    0，\quad &amp;v_i\text{与}e_j\text{不关联}          \end{cases}\]</span> 对有向图<span class="math inline">\(G\)</span>,其关联矩阵<span class="math inline">\(M=(M_{ij})_{n\times m}\)</span>，其中 <span class="math display">\[m_{ij} = \begin{cases}1,\quad &amp;v_i\text{是}e_j\text{起点}\\                    -1，\quad &amp;v_i\text{是}e_j\text{终点}\\                    0,\quad &amp;v_i\text{与}e_j\text{不关联}          \end{cases}\]</span></p><ul><li>邻接矩阵</li></ul><p>对于无向非赋权图<span class="math inline">\(G\)</span>，其邻接矩阵<span class="math inline">\(W=(w_{ij})_{n\times n}\)</span>其中 <span class="math display">\[w_{ij} = \begin{cases}1,\quad &amp;v_i\text{与}v_j\text{相邻}\\                    0，\quad &amp;v_i\text{与}v_j\text{不相邻}          \end{cases}\]</span> 对于有向非赋权图<span class="math inline">\(G\)</span>,其邻接矩阵<span class="math inline">\(W=(w_{ij})_{n\times n}\)</span>其中 <span class="math display">\[w_{ij} = \begin{cases}1,\quad &amp;(v_i,v_j)\in A\\                    0，\quad &amp;(v_i,v_j)\notin A          \end{cases}\]</span> 对于无向赋权图，其邻接矩阵<span class="math inline">\(W=(w_{ij})_{n\times n}\)</span>其中 <span class="math display">\[w_{ij} =\begin{cases}\text{顶点}v_i\text{顶点}v_j\text{之间边的权},\quad&amp;(v_i,v_j)\in E\\                    0(\text{或}\infty)，\quad&amp;v_i,v_j\text{之间无边}          \end{cases}\]</span></p><h2 id="绘制图">绘制图</h2><h3 id="绘制无向加权图">绘制无向加权图</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-comment">#绘制无向加权图</span><br><span class="hljs-keyword">import</span> numpy <span class="hljs-keyword">as</span> np<br><span class="hljs-keyword">import</span> networkx <span class="hljs-keyword">as</span> nx<br><span class="hljs-keyword">import</span> seaborn <span class="hljs-keyword">as</span> sns<br>sns.set_theme(style=<span class="hljs-string">&quot;dark&quot;</span>)<span class="hljs-comment">#用来设置主题背景</span><br>plt.rcParams[<span class="hljs-string">&quot;font.sans-serif&quot;</span>] = [<span class="hljs-string">&quot;SimHei&quot;</span>] <span class="hljs-comment">#用来正常显示中文标签</span><br>plt.rcParams[<span class="hljs-string">&quot;axes.unicode_minus&quot;</span>] = <span class="hljs-literal">False</span> <span class="hljs-comment">#用来正常显示负号</span><br>A = np.array([[<span class="hljs-number">0</span>,<span class="hljs-number">9</span>,<span class="hljs-number">2</span>,<span class="hljs-number">4</span>,<span class="hljs-number">7</span>]<br>             ,[<span class="hljs-number">9</span>,<span class="hljs-number">0</span>,<span class="hljs-number">3</span>,<span class="hljs-number">4</span>,<span class="hljs-number">0</span>]<br>             ,[<span class="hljs-number">2</span>,<span class="hljs-number">3</span>,<span class="hljs-number">0</span>,<span class="hljs-number">8</span>,<span class="hljs-number">4</span>]<br>             ,[<span class="hljs-number">4</span>,<span class="hljs-number">4</span>,<span class="hljs-number">8</span>,<span class="hljs-number">0</span>,<span class="hljs-number">6</span>]<br>             ,[<span class="hljs-number">7</span>,<span class="hljs-number">0</span>,<span class="hljs-number">4</span>,<span class="hljs-number">6</span>,<span class="hljs-number">0</span>]]) <span class="hljs-comment">#输入邻接矩阵</span><br>i,j = np.nonzero(A) <span class="hljs-comment">#提取顶点编号</span><br>w = A[i,j] <span class="hljs-comment">#提取A非零元素</span><br>edges = <span class="hljs-built_in">list</span>(<span class="hljs-built_in">zip</span>(i,j,w)) <span class="hljs-comment">#构建边list</span><br>G = nx.Graph()<span class="hljs-comment">#创建无向图类</span><br>G.add_weighted_edges_from(edges) <span class="hljs-comment">#添加带权边</span><br>node_labels = <span class="hljs-built_in">dict</span>(<span class="hljs-built_in">zip</span>(<span class="hljs-built_in">range</span>(<span class="hljs-number">5</span>),[<span class="hljs-built_in">str</span>(i+<span class="hljs-number">1</span>) <span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(<span class="hljs-number">5</span>)]))<span class="hljs-comment">#顶点标签</span><br>pos = nx.shell_layout(G) <span class="hljs-comment">#图形布局</span><br>nx.draw_networkx(G,pos,node_size=<span class="hljs-number">260</span>,labels=node_labels) <span class="hljs-comment">#绘制图</span><br>w = nx.get_edge_attributes(G,<span class="hljs-string">&quot;weight&quot;</span>)<span class="hljs-comment">#获取边的权重字典</span><br>nx.draw_networkx_edge_labels(G,pos,font_size=<span class="hljs-number">12</span>,edge_labels=w)<span class="hljs-comment">#标记权重</span><br>plt.show()<br></code></pre></td></tr></table></figure><p><img src="https://s2.loli.net/2022/06/26/IOyV2s3AqZ6pXrW.png"></p>]]></content>
    
    
    <categories>
      
      <category>数学建模</category>
      
      <category>图论</category>
      
    </categories>
    
    
  </entry>
  
  
  
  <entry>
    <title>逻辑回归</title>
    <link href="/posts/60504.html"/>
    <url>/posts/60504.html</url>
    
    <content type="html"><![CDATA[<div class="note note-success">            <p>机器学习 逻辑回归</p>          </div><h2 id="广义线性模型generalized-linear-model">广义线性模型（Generalizedlinear model）</h2><p>设<span class="math inline">\(y=\hat{w}^{T}\cdot\hat{x},where\,\hat{w}=(w_1,w_2,\dots,w_n,b)^{T}\,\hat{x}=(x_1,x_2,\dots,x_n,1)^{T}\)</span>,令<span class="math inline">\(g(y)=\hat{w}^{T}\cdot\hat{x}\)</span>，其中<span class="math inline">\(y=g(x)\)</span>为连续可微函数。则该模型为广义线性模型，该模型的提出是为了解决线性模型由于简单而带有的局限性。若令<span class="math inline">\(y=g(x)=ln(x)\)</span>，则该模型可表示为<span class="math inline">\(ln(y)=\hat{w}^{T}\cdot\hat{x} \iffy=\exp(\hat{w}^{T}\cdot\hat{x})\)</span>，该模型被称为对数线性模型(logistlinear model).</p><h2 id="对数几率模型与逻辑回归">对数几率模型与逻辑回归</h2><ul><li>几率(odd)</li></ul><p>几率不是概率，而是一个事件发生与不发生的概率的比值。假设某事件A发生的概率为p，则该事件不发生的概率为1-p，该事件的几率为：<span class="math inline">\(odd(A)=\frac{p}{1-p}\)</span>.在几率的基础上取（自然底数的）对数，则构成该事件的对数几率（logit）：<span class="math inline">\(logit(A)=\ln\frac{p}{1-p}\)</span></p><ul><li>对数几率模型</li></ul><p>如果我们将对数几率看成是一个函数，并将其作为联系函数，即<span class="math inline">\(g(y)=\ln\frac{y}{1-y}\)</span>.则该广义线性模型为：<span class="math display">\[\ln\frac{y}{1-y}=\hat{w}^{T}\cdot\hat{x} \iffy=\frac{1}{1+\exp(-\hat{w}^{T}\cdot\hat{x})}\quad where\quady=\frac{1}{1+exp(-z)}被称为Sigmoid函数\]</span></p><ul><li>Sigmoid函数及其导数</li></ul><p><span class="math inline">\(Sigmoid(x)=\frac{1}{1+\exp(-x)},Sigmoid^{\prime}(x)=(1-Sigmoid(x))Sigmoid(x)\)</span>，其图像如下：</p><p><img src="https://s2.loli.net/2022/06/26/NOwe82Qgz5tlvPj.png"></p><h2 id="逻辑回归模型输出结果与模型可解释性">逻辑回归模型输出结果与模型可解释性</h2><ul><li>连续型输出结果转化为分类预测结果</li></ul><p>对于逻辑回归输出的(0,1)之间的连续型数值，我们只需要确定一个“阈值”，就可以将其转化为二分类的类别判别结果。通常来说，这个阈值是0.5，即以0.5为界，调整模型输出结果：</p><p><span class="math display">\[\begin{equation}y_{cla}=\left\{\begin{aligned}0, y&lt;0.5 \\1, y≥0.5\end{aligned}\right.\end{equation}\]</span></p><p>而有时候逻辑回归当<span class="math inline">\(f1\_score\)</span>等作为分类评价指标可以将阈值进行调整。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-comment">#借助sklearn中的Logisticregression来构建带有阈值移动的评估器</span><br><span class="hljs-keyword">from</span> sklearn.linear_model <span class="hljs-keyword">import</span> LogisticRegression<br><span class="hljs-keyword">from</span> sklearn.base <span class="hljs-keyword">import</span> BaseEstimator,TransformerMixin<br><span class="hljs-keyword">class</span> <span class="hljs-title class_">logistic_threshold</span>(BaseEstimator,TransformerMixin):<br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">__init__</span>(<span class="hljs-params">self,penalty=<span class="hljs-string">&quot;l2&quot;</span>,C=<span class="hljs-number">1.0</span>,solver=<span class="hljs-string">&quot;lbfgs&quot;</span>,max_iter=<span class="hljs-built_in">int</span>(<span class="hljs-params"><span class="hljs-number">1e8</span></span>),l1_ratio=<span class="hljs-literal">None</span>,class_weight=<span class="hljs-literal">None</span>,thr=<span class="hljs-number">0.5</span></span>):<br>        self.penalty = penalty<br>        self.C = C<br>        self.solver = solver<br>        self.max_iter = max_iter<br>        self.l1_ratio = l1_ratio<br>        self.class_weight = class_weight<br>        self.thr = thr<br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">fit</span>(<span class="hljs-params">self,X,y</span>):<br>        clf =      LogisticRegression(slef.penalty,self.C,self.solver,self.max_iter,self.l1_ratio,self.class_weight).fit(X,y)<br>        self.coef_ = clf.coef_<br>        self.clf = clf<br>        <span class="hljs-keyword">return</span> self<br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">predict</span>(<span class="hljs-params">self,X</span>):<br>        res = (self.clf.predict_proba(X)[:,<span class="hljs-number">1</span>]&gt;self.thr)*<span class="hljs-number">1</span><br>        <span class="hljs-keyword">return</span> res<br></code></pre></td></tr></table></figure><ul><li>逻辑回归输出结果(y)是否是概率</li></ul><p>决定y是否是概率的核心因素，不是模型本身，而是建模流程。  逻辑斯蒂本身也有对应的概率分布，因此输入的自变量其实是可以视作随机变量的，但前提是需要满足一定的分布要求。如果逻辑回归的建模流程遵照数理统计方法的一般建模流程，即自变量的分布（或者转化之后的分布）满足一定要求（通过检验），则最终模型输出结果就是严格意义上的概率取值。而如果是遵照机器学习建模流程进行建模，在为对自变量进行假设检验下进行模型构建，则由于自变量分布不一定满足条件，因此输出结果不一定为严格意义上的概率。</p><p>而我们基本都采用机器学习建模流程进行逻辑回归的构建，因此对于模型输出结果y，其实并不一定是严格意义上的概率。不过在目前大多数使用场景中，由于大家希望能够用到模型本身的可解释性，因此还是会将模型结果解读为1发生的概率。尽管这并不是一个严谨的做法，但在机器学习整体的“实证”倾向下，只要业务方接受这种做法、并且能够一定程度指导业务，我们就可以将其解读为概率。我们将逻辑回归输出结果看成近似概率值。</p><h2 id="sklearn中的逻辑回归">sklearn中的逻辑回归</h2><ul><li>正则化(Regularization)</li></ul><p><img src="https://s2.loli.net/2022/06/26/oq5lQmuFOhEkDZP.png"></p><p>上述为sklearn官方解释可以看出sklearn中是默认进行正则化，每个式子的前面部分为结构风险项（正则化项）,后面部分为损失函数经验风险项。当我们不想进行正则化的时候可以控制C很大。</p><table><thead><tr class="header"><th>参数</th><th>解释</th></tr></thead><tbody><tr class="odd"><td>penalty</td><td>正则化项</td></tr><tr class="even"><td>dual</td><td>是否求解对偶问题*</td></tr><tr class="odd"><td>tol</td><td>迭代停止条件：两轮迭代损失值差值小于tol时，停止迭代</td></tr><tr class="even"><td>C</td><td>经验风险和结构风险在损失函数中的权重</td></tr><tr class="odd"><td>fit_intercept</td><td>线性方程中是否包含截距项</td></tr><tr class="even"><td>intercept_scaling</td><td>相当于此前讨论的特征最后一列全为1的列，当使用liblinear求解参数时用于捕获截距</td></tr><tr class="odd"><td>class_weight</td><td>各类样本权重*</td></tr><tr class="even"><td>random_state</td><td>随机数种子</td></tr><tr class="odd"><td>solver</td><td>损失函数求解方法*</td></tr><tr class="even"><td>max_iter</td><td>求解参数时最大迭代次数，迭代过程满足max_iter或tol其一即停止迭代</td></tr><tr class="odd"><td>multi_class</td><td>多分类问题时求解方法*</td></tr><tr class="even"><td>verbose</td><td>是否输出任务进程</td></tr><tr class="odd"><td>warm_start</td><td>是否使用上次训练结果作为本次运行初始参数</td></tr><tr class="even"><td>l1_ratio</td><td>当采用弹性网正则化时，<span class="math inline">\(l1\)</span>正则项权重，就是损失函数中的<span class="math inline">\(\rho\)</span></td></tr></tbody></table><ul><li>dual：是否求解对偶问题</li></ul><p>  对偶问题是约束条件相反、求解方向也相反的问题，当数据集过小而特征较多时，求解对偶问题能一定程度降低运算复杂度，其他情况建议保留默认参数取值。</p><ul><li>class_weight:各类样本权重</li></ul><p>  class_weight其实代表各类样本在进行损失函数计算时的数值权重，例如假设一个二分类问题，0、1两类的样本比例是2:1，此时可以输入一个字典类型对象用于说明两类样本在进行损失值计算时的权重，例如输入:{0:1,1:3}，则代表1类样本的每一条数据在进行损失函数值的计算时都会在原始数值上*3。而当我们将该参数选为<code>balanced</code>时，则会自动将这个比例调整为真实样本比例的反比，以达到平衡的效果。</p><ul><li>solver：损失函数求解方法</li></ul><p>  其实除了最小二乘法和梯度下降以外，还有非常多的关于损失函数的求解方法，而选择损失函数的参数，就是solver参数。</p><p>  而当前损失函数到底采用何种优化方法进行求解，其实最终目的是希望能够更快（计算效率更高）更好（准确性更高）的来进行求解，而硬性的约束条件是损失函数的形态，此外则是用户自行选择的空间。下面为官方给出的solver列表</p><p><img src="https://s2.loli.net/2022/06/26/gAFjBUWPho7C8nG.png"></p><ul><li>multi_class：选用何种方法进行多分类问题求解</li></ul><p>可选OVR和MVM，当然默认情况是auto，此时模型会优先根据惩罚项和solver选择OVR还是MVM，但一般来说，MVM效果会好于OVR。</p><h2 id="利用极大似然估计进行参数估计">利用极大似然估计进行参数估计</h2><p>逻辑回归模型如下： <span class="math display">\[y = \frac{1}{1+\exp(-\hat{w}^{T}\cdot\hat{x})}\quad\hat{w}^{T}=(w_1,w_2,\dots,w_n,b)^{T}\,,\hat{x}=(x_1,x_2,\dots,x_n,1)^{T}\\\]</span> 固定一组<span class="math inline">\(\hat{w}^{T}\)</span>和<span class="math inline">\(\hat{x}\)</span>得:</p><p><span class="math display">\[p(y=1\vert\hat{w}^{T},\hat{x}) =\frac{1}{1+\exp(-\hat{w}^{T}\cdot\hat{x})} \quadp(y=1\vert\hat{w}^{T},\hat{x}) =\frac{1}{1+\exp(-\hat{w}^{T}\cdot\hat{x})}\\\]</span></p><p>令<span class="math inline">\(p_1(\hat{w}^{T},\hat{x})=p(y=1\vert\hat{w}^{T},\hat{x}),p_0(\hat{w}^{T},\hat{x})=p(y=0\vert\hat{w}^{T},\hat{x})\)</span></p><p>得：<span class="math inline">\(p(y=y_i)=p_1^{y_i}(\hat{w}^{T},\hat{x})\cdotp_0^{1-y_i}(\hat{w}^{T},\hat{x})\)</span></p><p>则似然函数为<span class="math inline">\(L(y_i;\hat{w}^{T},\hat{x})=\prod_{i=1}^{n}p(y=y_i)=\prod_{i=1}^{n}p_1^{y_i}(\hat{w}^{T},\hat{x})\cdotp_0^{1-y_i}(\hat{w}^{T},\hat{x})\)</span></p><p>进而<span class="math inline">\(\ln L=\sum_{i=1}^{n}(\lnp_1^{y_i}(\hat{w}^{T},\hat{x})+\lnp_0^{1-y_i}(\hat{w}^{T},\hat{x}))=\sum_{i=1}^{n}(y_i\lnp_1(\hat{w}^{T},\hat{x})+(1-y_i)\lnp_0(\hat{w}^{T},\hat{x}))\)</span></p><p>通过一系列数学过程可以证明，通过极大似然估计构建的损失函数是凸函数，此时我们可以采用导数为0联立方程组的方式进行求解，这也是极大似然估计对参数求解的一般方法。但这种方法会涉及大量的导数运算、方程组求解等，并不适用于大规模甚至是超大规模数值运算，因此，在机器学习领域，我们通常会采用一些更加通用的优化方法对逻辑回归的损失函数进行求解，通常来说是牛顿法或者梯度下降算法，其中，梯度下降算法是机器学习中最为通用的求解损失函数的优化算法.</p><p>为了方便求最小值将其转化为: <span class="math display">\[\ln L=-\sum_{i=1}^{n}(y_i\ln p_1(\hat{w}^{T},\hat{x})+(1-y_i)\lnp_0(\hat{w}^{T},\hat{x}))\]</span></p><h2 id="熵相对熵与交叉熵">熵、相对熵与交叉熵</h2><p>###熵</p><p>通常我们用熵（entropy）来表示随机变量不确定性的度量，或者说系统混乱程度、信息混乱程度。熵的计算公式如下：<span class="math display">\[entrop(X) = -\sum_{i=1}^{n}p(x_i)log(x_i)\]</span>可以证明，熵的计算结果在[0,1]之间，并且熵值越大，系统越混乱、信息越混乱。</p><h3 id="相对熵和交叉熵">相对熵和交叉熵</h3><p>相对熵也被称为Kullback-Leibler散度（KL散度）或者信息散度（informationdivergence）。通常用来衡量两个随机变量分布的差异性。假设对同一个随机变量X，有两个单独的概率分布P(x)和Q(x)，当X是离散变量时，我们可以通过如下相对熵计算公式来衡量二者差异：<span class="math display">\[D_{KL}(P\vert\vert Q) = \sum_{i=1}^{n}P(x_i)log(\frac{P(x_i)}{Q(x_i)})\]</span> 和信息熵类似，相对熵越小，代表Q(x)和P(x)越接近。</p><p>从交叉熵的计算公式不难看出，这其实是一种非对称性度量，也就是<span class="math inline">\(D_{KL}(P\vert\vert Q)\ne D_{KL}(Q\vert\vertP)\)</span>。从本质上来说，相对熵刻画的是用概率分布Q来刻画概率分布P的困难程度，而在机器学习领域，我们一般令Q为模型输出结果，而P为数据集标签真实结果，以此来判断模型输出结果是否足够接近真实情况。</p><ul><li>Q为拟合分布P为真实分布，也被称为前向KL散度（forward KLdivergence）。</li></ul><p><span class="math display">\[\begin{split}D_{KL}(P\vert\vert Q) &amp;=\sum_{i=1}^{n}P(x_i)log(\frac{P(x_i)}{Q(x_i)})\\&amp;=\sum_{i=1}^{n}P(x_i)log(P(x_i))-\sum_{i=1}^{n}P(x_i)log(Q(x_i))\\&amp;=-entropy(P(X))+cross\_entropy(P,Q)\end{split}\]</span></p><p>对于给定数据集，其信息熵是确定的。因此，如果我们希望P、Q二者分布尽可能接近，我们就需要尽可能减少相对熵，但由于相对熵=交叉熵-信息熵，因此我们只能力求减少交叉熵。当然，也正因如此，交叉熵可以作为衡量模型输出分布是否接近真实分布的重要度量方法。</p><p>简单总结上述过程要点：</p><ul><li>我们用相对熵<span class="math inline">\(𝐷_{𝐾𝐿}(𝑃||𝑄)\,D_{KL}(P||Q)\)</span>来表示模型拟合分布Q和数据真实分布P之间的差距，相对熵越小拟合效果越好；</li><li>根据计算公式(6),相对熵=交叉熵-信息熵；</li><li>对于给定数据集，信息熵是确定的，因此我们只能通过尽可能减小交叉熵来降低相对熵；</li></ul><p>根据吉布斯不等式，相对熵的取值恒大于等于零，当预测分布和真实分布完全一致时相对熵取值为0，此时交叉熵等于数据信息熵，此外只要二者分布不一致，交叉熵的取值都将大于信息熵。</p><h3 id="二分类交叉熵损失函数">二分类交叉熵损失函数</h3><p><span class="math display">\[binaryCE(\hat{w}) =-\sum_{i=1}^{n}(y_ilog(p_1(\hat{w}^{T},\hat{x}))+(1-y_i)log(p_0(\hat{w}^{T},\hat{x})))\]</span></p><h2 id="逻辑回归应用">逻辑回归应用</h2><p>该数据集为Telco Customer Churn 电信用户流失预测案例</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">import</span> pandas <span class="hljs-keyword">as</span> pd<br><span class="hljs-keyword">import</span> numpy <span class="hljs-keyword">as</span> np<br><span class="hljs-keyword">import</span> matplotlib.pyplot <span class="hljs-keyword">as</span> plt<br><span class="hljs-keyword">import</span> seaborn <span class="hljs-keyword">as</span> sns<br>sns.set_theme(style=<span class="hljs-string">&quot;darkgrid&quot;</span>)<span class="hljs-comment">#用来设置主题背景</span><br>plt.rcParams[<span class="hljs-string">&quot;font.sans-serif&quot;</span>] = [<span class="hljs-string">&quot;SimHei&quot;</span>] <span class="hljs-comment">#用来正常显示中文标签</span><br>plt.rcParams[<span class="hljs-string">&quot;axes.unicode_minus&quot;</span>] = <span class="hljs-literal">False</span> <span class="hljs-comment">#用来正常显示负号</span><br><span class="hljs-comment"># Read data</span><br>tcc = pd.read_csv(<span class="hljs-string">&#x27;WA_Fn-UseC_-Telco-Customer-Churn.csv&#x27;</span>)<br><span class="hljs-comment"># 标注连续/离散字段</span><br><span class="hljs-comment"># 离散字段</span><br>category_cols = [<span class="hljs-string">&#x27;gender&#x27;</span>, <span class="hljs-string">&#x27;SeniorCitizen&#x27;</span>, <span class="hljs-string">&#x27;Partner&#x27;</span>, <span class="hljs-string">&#x27;Dependents&#x27;</span>,<br>               <span class="hljs-string">&#x27;PhoneService&#x27;</span>, <span class="hljs-string">&#x27;MultipleLines&#x27;</span>, <span class="hljs-string">&#x27;InternetService&#x27;</span>, <span class="hljs-string">&#x27;OnlineSecurity&#x27;</span>, <span class="hljs-string">&#x27;OnlineBackup&#x27;</span>, <br>                <span class="hljs-string">&#x27;DeviceProtection&#x27;</span>, <span class="hljs-string">&#x27;TechSupport&#x27;</span>, <span class="hljs-string">&#x27;StreamingTV&#x27;</span>, <span class="hljs-string">&#x27;StreamingMovies&#x27;</span>, <span class="hljs-string">&#x27;Contract&#x27;</span>, <span class="hljs-string">&#x27;PaperlessBilling&#x27;</span>,<br>                <span class="hljs-string">&#x27;PaymentMethod&#x27;</span>]<br><br><span class="hljs-comment"># 连续字段</span><br>numeric_cols = [<span class="hljs-string">&#x27;tenure&#x27;</span>, <span class="hljs-string">&#x27;MonthlyCharges&#x27;</span>, <span class="hljs-string">&#x27;TotalCharges&#x27;</span>]<br><br><span class="hljs-comment"># 标签</span><br>target = <span class="hljs-string">&#x27;Churn&#x27;</span><br><br><span class="hljs-comment"># ID列</span><br>ID_col = <span class="hljs-string">&#x27;customerID&#x27;</span><br><br><span class="hljs-comment"># 验证是否划分能完全</span><br><span class="hljs-keyword">assert</span> <span class="hljs-built_in">len</span>(category_cols) + <span class="hljs-built_in">len</span>(numeric_cols) + <span class="hljs-number">2</span> == tcc.shape[<span class="hljs-number">1</span>]<br><span class="hljs-comment">#Verify whether the ID column is duplicate</span><br>tcc[ID_col].nunique() == tcc.shape[<span class="hljs-number">0</span>]<br><span class="hljs-comment">#Verify whether have the explict missing values</span><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">missing</span>(<span class="hljs-params">df</span>):<br>    <span class="hljs-string">&#x27;&#x27;&#x27;</span><br><span class="hljs-string">    Caculate the proportion of the missing value</span><br><span class="hljs-string">    </span><br><span class="hljs-string">    &#x27;&#x27;&#x27;</span><br>    missing_number = df.isnull().<span class="hljs-built_in">sum</span>().sort_values(ascending=<span class="hljs-literal">False</span>) <span class="hljs-comment">#decending</span><br>    missing_per = (df.isnull().<span class="hljs-built_in">sum</span>()/df.count()).sort_values(ascending=<span class="hljs-literal">False</span>) <span class="hljs-comment">#decending</span><br>    missing_df = pd.concat([missing_number,missing_per],axis=<span class="hljs-number">1</span>,keys=[<span class="hljs-string">&quot;Missing_number&quot;</span>,<span class="hljs-string">&quot;Missing_per&quot;</span>])<br>    <span class="hljs-keyword">return</span> missing_df<br><span class="hljs-comment">#Verify whether have the discrete explict missing values</span><br><span class="hljs-keyword">for</span> feature <span class="hljs-keyword">in</span> category_cols:<br>    <span class="hljs-built_in">print</span>(<span class="hljs-string">&quot;&#123;&#125;:&#123;&#125;&quot;</span>.<span class="hljs-built_in">format</span>(feature,tcc[feature].unique()))<br> <span class="hljs-comment">#Verify whether have the continuous explict missing values</span><br>tcc[numeric_cols].astype(<span class="hljs-built_in">float</span>)<br><span class="hljs-keyword">def</span> <span class="hljs-title function_">find_index</span>(<span class="hljs-params">data_col,value</span>):<br>    <span class="hljs-string">&quot;&quot;&quot;</span><br><span class="hljs-string">    Verify the first occurance of the given value in the given column,return -1 if there is none.</span><br><span class="hljs-string">    param data_col:given column</span><br><span class="hljs-string">    param value:given value</span><br><span class="hljs-string">    &quot;&quot;&quot;</span><br>    val_lst = [value]<br>    <span class="hljs-keyword">if</span> data_col.isin(val_lst).<span class="hljs-built_in">sum</span>() == <span class="hljs-number">0</span>:<br>        <span class="hljs-keyword">return</span> -<span class="hljs-number">1</span><br>    <span class="hljs-keyword">else</span>:<br>        res = data_col.isin(val_lst).idxmax()<br>    <span class="hljs-keyword">return</span> res<br><span class="hljs-keyword">for</span> feature <span class="hljs-keyword">in</span> numeric_cols:<br>    <span class="hljs-built_in">print</span>(find_index(tcc[feature],<span class="hljs-string">&quot; &quot;</span>))<br>tcc[<span class="hljs-string">&quot;TotalCharges&quot;</span>] = tcc[<span class="hljs-string">&quot;TotalCharges&quot;</span>].apply(<span class="hljs-keyword">lambda</span> x:x <span class="hljs-keyword">if</span> x!=<span class="hljs-string">&quot; &quot;</span><span class="hljs-keyword">else</span> np.nan).astype(<span class="hljs-built_in">float</span>)<br>tcc[<span class="hljs-string">&quot;MonthlyCharges&quot;</span>] = tcc[<span class="hljs-string">&quot;MonthlyCharges&quot;</span>].astype(<span class="hljs-built_in">float</span>)<br>tcc[<span class="hljs-string">&quot;TotalCharges&quot;</span>]=tcc[<span class="hljs-string">&quot;TotalCharges&quot;</span>].fillna(<span class="hljs-number">0</span>)<br><span class="hljs-comment">#Outlier detection</span><br>plt.figure(figsize=(<span class="hljs-number">16</span>, <span class="hljs-number">6</span>), dpi=<span class="hljs-number">200</span>)<br>plt.subplot(<span class="hljs-number">121</span>)<br>plt.boxplot(tcc[<span class="hljs-string">&#x27;MonthlyCharges&#x27;</span>])<br>plt.xlabel(<span class="hljs-string">&#x27;MonthlyCharges&#x27;</span>)<br>plt.subplot(<span class="hljs-number">122</span>)<br>plt.boxplot(tcc[<span class="hljs-string">&#x27;TotalCharges&#x27;</span>])<br>plt.xlabel(<span class="hljs-string">&#x27;TotalCharges&#x27;</span>)<br>tcc[target].replace(to_replace=<span class="hljs-string">&quot;Yes&quot;</span>,value=<span class="hljs-number">1</span>,inplace=<span class="hljs-literal">True</span>)<br>tcc[target].replace(to_replace=<span class="hljs-string">&quot;No&quot;</span>,value=<span class="hljs-number">0</span>,inplace=<span class="hljs-literal">True</span>)<br><span class="hljs-keyword">from</span> sklearn.model_selection <span class="hljs-keyword">import</span> train_test_split<br>train,test = train_test_split(tcc,random_state=<span class="hljs-number">666</span>,test_size=<span class="hljs-number">0.3</span>)<br>X_train = train.drop(columns=[ID_col,target]).copy()<br>y_train = train[target].copy()<br>X_test = test.drop(columns=[ID_col,target]).copy()<br>y_test = test[target].copy()<br><span class="hljs-keyword">from</span> sklearn.preprocessing <span class="hljs-keyword">import</span> OneHotEncoder,KBinsDiscretizer,StandardScaler<br><span class="hljs-keyword">from</span> sklearn.compose <span class="hljs-keyword">import</span> ColumnTransformer<br><span class="hljs-keyword">from</span> sklearn.pipeline <span class="hljs-keyword">import</span> make_pipeline<br><span class="hljs-keyword">from</span> sklearn.linear_model <span class="hljs-keyword">import</span> LogisticRegression<br><span class="hljs-keyword">from</span> sklearn.model_selection <span class="hljs-keyword">import</span> GridSearchCV<br>logistic_pre = ColumnTransformer([(<span class="hljs-string">&quot;cat&quot;</span>,OneHotEncoder(drop=<span class="hljs-string">&quot;if_binary&quot;</span>),category_cols),(<span class="hljs-string">&quot;num&quot;</span>,<span class="hljs-string">&quot;passthrough&quot;</span>,numeric_cols)])<br>logistic_model = LogisticRegression(max_iter=<span class="hljs-built_in">int</span>(<span class="hljs-number">1e8</span>))<br>logistic_pipe = make_pipeline(logistic_pre,logistic_model)<br>num_sel = [<span class="hljs-string">&quot;passthrough&quot;</span>,StandardScaler(),KBinsDiscretizer(n_bins=<span class="hljs-number">3</span>,encode=<span class="hljs-string">&quot;ordinal&quot;</span>,strategy=<span class="hljs-string">&quot;kmeans&quot;</span>)]<br>logistic_param = [&#123;<span class="hljs-string">&quot;columntransformer__num&quot;</span>:num_sel<br>                   ,<span class="hljs-string">&quot;logisticregression__penalty&quot;</span>:[<span class="hljs-string">&quot;l1&quot;</span>]<br>                   ,<span class="hljs-string">&quot;logisticregression__C&quot;</span>:np.arange(<span class="hljs-number">0.1</span>,<span class="hljs-number">2.1</span>,<span class="hljs-number">0.1</span>).tolist()<br>                   ,<span class="hljs-string">&quot;logisticregression__solver&quot;</span>:[<span class="hljs-string">&quot;saga&quot;</span>]&#125;<br>                 ,&#123;<span class="hljs-string">&quot;columntransformer__num&quot;</span>:num_sel<br>                   ,<span class="hljs-string">&quot;logisticregression__penalty&quot;</span>:[<span class="hljs-string">&quot;l2&quot;</span>]<br>                   ,<span class="hljs-string">&quot;logisticregression__C&quot;</span>:np.arange(<span class="hljs-number">0.1</span>,<span class="hljs-number">2.1</span>,<span class="hljs-number">0.1</span>).tolist()<br>                   ,<span class="hljs-string">&quot;logisticregression__solver&quot;</span>:[<span class="hljs-string">&#x27;lbfgs&#x27;</span>, <span class="hljs-string">&#x27;newton-cg&#x27;</span>, <span class="hljs-string">&#x27;sag&#x27;</span>, <span class="hljs-string">&#x27;saga&#x27;</span>]&#125;]<br>logistic_search = GridSearchCV(estimator=logistic_pipe,param_grid=logistic_param,n_jobs=-<span class="hljs-number">1</span>)<br><span class="hljs-keyword">import</span> time<br>s = time.time()<br>logistic_search.fit(X_train,y_train)<br><span class="hljs-built_in">print</span>(<span class="hljs-string">&quot;&#123;&#125;&quot;</span>.<span class="hljs-built_in">format</span>(time.time()-s))<br></code></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">class</span> <span class="hljs-title class_">logit_threshold</span>(BaseEstimator, TransformerMixin):<br>    <br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">__init__</span>(<span class="hljs-params">self, penalty=<span class="hljs-string">&#x27;l2&#x27;</span>, C=<span class="hljs-number">1.0</span>, max_iter=<span class="hljs-number">1e8</span>, solver=<span class="hljs-string">&#x27;lbfgs&#x27;</span>, l1_ratio=<span class="hljs-literal">None</span>, class_weight=<span class="hljs-literal">None</span>, thr=<span class="hljs-number">0.5</span></span>):<br>        self.penalty = penalty<br>        self.C = C<br>        self.max_iter = max_iter<br>        self.solver = solver<br>        self.l1_ratio = l1_ratio<br>        self.thr = thr<br>        self.class_weight = class_weight<br>        <br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">fit</span>(<span class="hljs-params">self, X, y</span>):<br>        clf = LogisticRegression(penalty = self.penalty, <br>                                 C = self.C, <br>                                 solver = self.solver, <br>                                 l1_ratio = self.l1_ratio,<br>                                 class_weight=self.class_weight, <br>                                 max_iter=self.max_iter)<br>        clf.fit(X, y)<br>        self.coef_ = clf.coef_<br>        self.clf = clf<br>        <span class="hljs-keyword">return</span> self<br>        <br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">predict</span>(<span class="hljs-params">self, X</span>):<br>        res = (self.clf.predict_proba(X)[:, <span class="hljs-number">1</span>]&gt;=self.thr) * <span class="hljs-number">1</span><br>        <span class="hljs-keyword">return</span> res<br> <span class="hljs-comment"># 设置转化器流</span><br>logistic_pre = ColumnTransformer([<br>    (<span class="hljs-string">&#x27;cat&#x27;</span>, preprocessing.OneHotEncoder(drop=<span class="hljs-string">&#x27;if_binary&#x27;</span>), category_cols), <br>    (<span class="hljs-string">&#x27;num&#x27;</span>, <span class="hljs-string">&#x27;passthrough&#x27;</span>, numeric_cols)<br>])<br><br>num_pre = [<span class="hljs-string">&#x27;passthrough&#x27;</span>, preprocessing.StandardScaler(), preprocessing.KBinsDiscretizer(n_bins=<span class="hljs-number">3</span>, encode=<span class="hljs-string">&#x27;ordinal&#x27;</span>, strategy=<span class="hljs-string">&#x27;kmeans&#x27;</span>)]<br><br><span class="hljs-comment"># 实例化逻辑回归评估器</span><br>logistic_model = logit_threshold(max_iter=<span class="hljs-built_in">int</span>(<span class="hljs-number">1e8</span>))<br><br><span class="hljs-comment"># 设置机器学习流</span><br>logistic_pipe = make_pipeline(logistic_pre, logistic_model)<br><br><span class="hljs-comment"># 设置超参数空间</span><br>logistic_param = [<br>    &#123;<span class="hljs-string">&#x27;columntransformer__num&#x27;</span>:num_pre, <span class="hljs-string">&#x27;logit_threshold__thr&#x27;</span>: np.arange(<span class="hljs-number">0.1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">0.1</span>).tolist(), <span class="hljs-string">&#x27;logit_threshold__penalty&#x27;</span>: [<span class="hljs-string">&#x27;l1&#x27;</span>], <span class="hljs-string">&#x27;logit_threshold__C&#x27;</span>: np.arange(<span class="hljs-number">0.1</span>, <span class="hljs-number">1.1</span>, <span class="hljs-number">0.1</span>).tolist(), <span class="hljs-string">&#x27;logit_threshold__solver&#x27;</span>: [<span class="hljs-string">&#x27;saga&#x27;</span>]&#125;, <br>    &#123;<span class="hljs-string">&#x27;columntransformer__num&#x27;</span>:num_pre, <span class="hljs-string">&#x27;logit_threshold__thr&#x27;</span>: np.arange(<span class="hljs-number">0.1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">0.1</span>).tolist(), <span class="hljs-string">&#x27;logit_threshold__penalty&#x27;</span>: [<span class="hljs-string">&#x27;l2&#x27;</span>], <span class="hljs-string">&#x27;logit_threshold__C&#x27;</span>: np.arange(<span class="hljs-number">0.1</span>, <span class="hljs-number">1.1</span>, <span class="hljs-number">0.1</span>).tolist(), <span class="hljs-string">&#x27;logit_threshold__solver&#x27;</span>: [<span class="hljs-string">&#x27;lbfgs&#x27;</span>, <span class="hljs-string">&#x27;newton-cg&#x27;</span>, <span class="hljs-string">&#x27;sag&#x27;</span>, <span class="hljs-string">&#x27;saga&#x27;</span>]&#125;, <br>]<br><br><span class="hljs-comment"># 实例化网格搜索评估器</span><br>logistic_search_f1 = GridSearchCV(estimator = logistic_pipe,<br>                                  param_grid = logistic_param,<br>                                  scoring=<span class="hljs-string">&#x27;f1&#x27;</span>,<br>                                  n_jobs = <span class="hljs-number">12</span>)<br><br>s = time.time()<br>logistic_search_f1.fit(X_train, y_train)<br><span class="hljs-built_in">print</span>(time.time()-s, <span class="hljs-string">&quot;s&quot;</span>)<br></code></pre></td></tr></table></figure><h2 id="逻辑回归模型解释">逻辑回归模型解释</h2><p>对于逻辑回归的模型解释，核心是需要观察线性方程中自变量的系数，通过系数大小可以判断特征重要性，并且系数的具体数值也能表示因变量如何伴随自变量变化而变化。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-comment">#查看逻辑回归系数</span><br>coe = logistic_search.best_estimator_.named_steps[<span class="hljs-string">&#x27;logit_threshold&#x27;</span>].coef_<br>coe = coe.flatten()<br>coe<br><span class="hljs-comment"># 定位独热编码转化器</span><br>tf = logistic_search.best_estimator_.named_steps[<span class="hljs-string">&#x27;columntransformer&#x27;</span>].named_transformers_[<span class="hljs-string">&#x27;cat&#x27;</span>]<br>tf<br><span class="hljs-keyword">def</span> <span class="hljs-title function_">cate_colName</span>(<span class="hljs-params">Transformer, category_cols, drop=<span class="hljs-string">&#x27;if_binary&#x27;</span></span>):<br>    <span class="hljs-string">&quot;&quot;&quot;</span><br><span class="hljs-string">    离散字段独热编码后字段名创建函数</span><br><span class="hljs-string">    </span><br><span class="hljs-string">    :param Transformer: 独热编码转化器</span><br><span class="hljs-string">    :param category_cols: 输入转化器的离散变量</span><br><span class="hljs-string">    :param drop: 独热编码转化器的drop参数</span><br><span class="hljs-string">    &quot;&quot;&quot;</span><br>    <br>    cate_cols_new = []<br>    col_value = Transformer.categories_<br>    <br>    <span class="hljs-keyword">for</span> i, j <span class="hljs-keyword">in</span> <span class="hljs-built_in">enumerate</span>(category_cols):<br>        <span class="hljs-keyword">if</span> (drop == <span class="hljs-string">&#x27;if_binary&#x27;</span>) &amp; (<span class="hljs-built_in">len</span>(col_value[i]) == <span class="hljs-number">2</span>):<br>            cate_cols_new.append(j)<br>        <span class="hljs-keyword">else</span>:<br>            <span class="hljs-keyword">for</span> f <span class="hljs-keyword">in</span> col_value[i]:<br>                feature_name = j + <span class="hljs-string">&#x27;_&#x27;</span> + f<br>                cate_cols_new.append(feature_name)<br>    <span class="hljs-keyword">return</span>(cate_cols_new)<br><span class="hljs-comment"># 转化后离散变量列名称</span><br>category_cols_new = cate_colName(tf, category_cols)<br><br><span class="hljs-comment"># 所有字段名称</span><br>cols_new = category_cols_new + numeric_cols<br><br><span class="hljs-comment"># 查看特征名称数量和特征系数数量是否一致</span><br><span class="hljs-keyword">assert</span> <span class="hljs-built_in">len</span>(cols_new) == <span class="hljs-built_in">len</span>(coe)<br></code></pre></td></tr></table></figure><p>对于<span class="math inline">\(\ln\frac{y}{1-y}=\hat{w}^{T}\cdot\hat{x}=w_1x_1+w_2x_2+\dots+w_nx_n+b\)</span>而言每个<span class="math inline">\(x_i\)</span>的变化会不同程度的影响对数几率的变化。</p><p>以<span class="math inline">\(\ln\frac{y}{1-y}=2x_1-x_2\)</span>为例<span class="math inline">\(x_1\)</span>每增长1,<span class="math inline">\(y\)</span>判别为正例的对数几率就增加2，概率就增加0.4</p><p>此外，还可以根据系数来判别特征重要性。</p>]]></content>
    
    
    <categories>
      
      <category>machine learning</category>
      
    </categories>
    
    
    <tags>
      
      <tag>machine learning</tag>
      
    </tags>
    
  </entry>
  
  
  
  
</search>
